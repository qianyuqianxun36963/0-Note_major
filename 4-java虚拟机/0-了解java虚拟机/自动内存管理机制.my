<h1>第二部分 自动内存管理机制</h1>

<h2><br />
第2章 Java内存区域与内存溢出异常</h2>

<p><br />
Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的&ldquo;高墙&rdquo;，墙外面的人想<br />
进去，墙里面的人却想出来。</p>

<h3>2.1 概述</h3>

<p>对于从事C、 C++程序开发的开发人员来说，在内存管理领域，他们既是拥有最高权力<br />
的&ldquo;皇帝&rdquo;又是从事最基础工作的&ldquo;劳动人民&rdquo;&mdash;&mdash;既拥有每一个对象的&ldquo;所有权&rdquo;，又担负着每<br />
一个对象生命开始到终结的维护责任。<br />
对于Java程序员来说，在虚拟机自动内存管理机制的帮助下，不再需要为每一个new操<br />
作去写配对的delete/free代码，不容易出现内存泄漏和内存溢出问题，由虚拟机管理内存这<br />
一切看起来都很美好。 不过，也正是因为Java程序员把内存控制的权力交给了Java虚拟机，<br />
一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那么排查错误<br />
将会成为一项异常艰难的工作。<br />
本章是第二部分的第1章，笔者将从概念上介绍Java虚拟机内存的各个区域，讲解这些<br />
区域的作用、 服务对象以及其中可能产生的问题，这是翻越虚拟机内存管理这堵围墙的第一<br />
步。</p>

<h3>2.2 运行时数据区域</h3>

<p>Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区<br />
域。 这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而<br />
存在，有些区域则依赖用户线程的启动和结束而建立和销毁。 根据《 Java虚拟机规范（Java<br />
SE 7版）》 的规定，Java虚拟机所管理的内存将会包括以下几个运行时数据区域，如图2-1所<br />
示。</p>

<h4>线程私有</h4>

<h4>2.2.1 程序计数器(PC寄存器)</h4>

<p>Java 虚拟机可以支持多条线程同时执行（可参考《 Java 语言规范》第 17 章），每一条 Java<br />
虚拟机线程都有自己的 PC（ Program Counter）寄存器。在任意时刻，一条 Java 虚拟机线程<br />
只会执行一个方法的代码，这个正在被线程执行的方法称为该线程的当前方法（ Current<br />
Method， &sect;2.6）。如果这个方法不是 native 的，那 PC 寄存器就保存 Java 虚拟机正在执行的<br />
字节码指令的地址，如果该方法是 native 的，那 PC 寄存器的值是 undefined。 PC 寄存器的容<br />
量至少应当能保存一个 returnAddress 类型的数据或者一个与平台相关的本地指针的值。<br />
&nbsp;</p>

<p>程序计数器（Program Counter Register）是一块较小的内存空间，它可以看作是当前线<br />
程所执行的字节码的行号指示器。 在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能<br />
会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选<br />
取下一条需要执行的字节码指令，分支、 循环、 跳转、 异常处理、 线程恢复等基础功能都需要依赖这个计数器来完成。<br />
由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，<br />
在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）都只会执行一条线<br />
程中的指令。 因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立<br />
的程序计数器，各条线程之间计数器互不影响，独立存储，我们称这类内存区域为&ldquo;线程私<br />
有&rdquo;的内存。<br />
如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指<br />
令的地址；如果正在执行的是Native方法，这个计数器值则为空（Undefined）。 此内存区域<br />
是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。</p>

<h4>2.2.2 Java虚拟机栈</h4>

<p>与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的<br />
生命周期与线程相同。 虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时<br />
都会创建一个栈帧（Stack Frame[1]）用于存储局部变量表、 操作数栈、 动态链接、 方法出口<br />
等信息。 每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出<br />
栈的过程。<br />
经常有人把Java内存区分为堆内存（Heap）和栈内存（Stack），这种分法比较粗<br />
糙，Java内存区域的划分实际上远比这复杂。 这种划分方式的流行只能说明大多数程序员最<br />
关注的、 与对象内存分配关系最密切的内存区域是这两块。 其中所指的&ldquo;堆&rdquo;笔者在后面会专<br />
门讲述，而所指的&ldquo;栈&rdquo;就是现在讲的虚拟机栈，或者说是虚拟机栈中局部变量表部分。<br />
局部变量表存放了编译期可知的各种基本数据类型（boolean、 byte、 char、 short、 int、<br />
float、 long、 double）、 对象引用（reference类型，它不等同于对象本身，可能是一个指向对<br />
象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和<br />
returnAddress类型（指向了一条字节码指令的地址）。<br />
其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据<br />
类型只占用1个。 局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这<br />
个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变<br />
量表的大小。<br />
在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚<br />
拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（当前大部<br />
分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），如<br />
果扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。<br />
[1]栈帧是方法运行时的基础数据结构，在本书的第8章中会对帧进行详细讲解。</p>

<h4>2.2.3 本地方法栈</h4>

<p>本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用是非常相似的，它们之间<br />
的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚<br />
拟机使用到的Native方法服务。 在虚拟机规范中对本地方法栈中方法使用的语言、 使用方式<br />
与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。 甚至有的虚拟机（譬如<br />
Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。 与虚拟机栈一样，本地方法<br />
栈区域也会抛出StackOverflowError和OutOfMemoryError异常。</p>

<h4>线程共享</h4>

<h4>2.2.4 Java堆</h4>

<p>对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。<br />
Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。 此内存区域的唯一目的就<br />
是存放对象实例，几乎所有的对象实例都在这里分配内存。 这一点在Java虚拟机规范中的描<br />
述是：所有的对象实例以及数组都要在堆上分配[1]，但是随着JIT编译器的发展与逃逸分析技<br />
术逐渐成熟，栈上分配、 标量替换[2]优化技术将会导致一些微妙的变化发生，所有的对象都<br />
分配在堆上也渐渐变得不是那么&ldquo;绝对&rdquo;了。<br />
Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做&ldquo;GC堆&rdquo;（Garbage<br />
Collected Heap，幸好国内没翻译成&ldquo;垃圾堆&rdquo;）。 从内存回收的角度来看，由于现在收集器基<br />
本都采用分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有<br />
Eden空间、 From Survivor空间、 To Survivor空间等。 从内存分配的角度来看，线程共享的<br />
Java堆中可能划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer,TLAB）。 不<br />
过无论如何划分，都与存放内容无关，无论哪个区域，存储的都仍然是对象实例，进一步划<br />
分的目的是为了更好地回收内存，或者更快地分配内存。 在本章中，我们仅仅针对内存区域<br />
的作用进行讨论，Java堆中的上述各个区域的分配、 回收等细节将是第3章的主题。<br />
根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上<br />
是连续的即可，就像我们的磁盘空间一样。 在实现时，既可以实现成固定大小的，也可以是<br />
可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。 如<br />
果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异<br />
常。<br />
[1]Java虚拟机规范中的原文：The heap is the runtime data area from which memory for all class<br />
instances and arrays is allocated。<br />
[2]逃逸分析与标量替换的相关内容，参见第11章相关内容。</p>

<h4>2.2.5 方法区</h4>

<p>方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚<br />
拟机加载的类信息、 常量、 静态变量、 即时编译器编译后的代码等数据。 虽然Java虚拟机规<br />
范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应<br />
该是与Java堆区分开来。<br />
对于习惯在HotSpot虚拟机上开发、 部署程序的开发者来说，很多人都更愿意把方法区<br />
称为&ldquo;永久代&rdquo;（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的<br />
设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已，这样<br />
HotSpot的垃圾收集器可以像管理Java堆一样管理这部分内存，能够省去专门为方法区编写内<br />
存管理代码的工作。 对于其他虚拟机（如BEA JRockit、 IBM J9等）来说是不存在永久代的概<br />
念的。 原则上，如何实现方法区属于虚拟机实现细节，不受虚拟机规范约束，但使用永久代<br />
来实现方法区，现在看来并不是一个好主意，因为这样更容易遇到内存溢出问题（永久代<br />
有-XX：MaxPermSize的上限，J9和JRockit只要没有触碰到进程可用内存的上限，例如32位系<br />
统中的4GB，就不会出现问题），而且有极少数方法（例如String.intern（））会因这个原因<br />
导致不同虚拟机下有不同的表现。 因此，对于HotSpot虚拟机，根据官方发布的路线图信<br />
息，现在也有放弃永久代并逐步改为采用Native Memory来实现方法区的规划了[1]，在目前已<br />
经发布的JDK 1.7的HotSpot中，已经把原本放在永久代的字符串常量池移出。<br />
Java虚拟机规范对方法区的限制非常宽松，除了和Java堆一样不需要连续的内存和可以<br />
选择固定大小或者可扩展外，还可以选择不实现垃圾收集。 相对而言，垃圾收集行为在这个<br />
区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样&ldquo;永久&rdquo;存在了。 这区<br />
域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说，这个区域的回<br />
收&ldquo;成绩&rdquo;比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确<br />
实是必要的。 在Sun公司的BUG列表中，曾出现过的若干个严重的BUG就是由于低版本的<br />
HotSpot虚拟机对此区域未完全回收而导致内存泄漏。<br />
根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出<br />
OutOfMemoryError异常。<br />
[1]JEP 122-Remove the Permanent Generation：http://openjdk.java.net/jeps/122。</p>

<h4>2.2.6 运行时常量池</h4>

<p>运行时常量池（Runtime Constant Pool）是方法区的一部分。 Class文件中除了有类的版<br />
本、 字段、 方法、 接口等描述信息外，还有一项信息是常量池（Constant Pool Table），用于<br />
存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常<br />
量池中存放。<br />
Java虚拟机对Class文件每一部分（自然也包括常量池）的格式都有严格规定，每一个字<br />
节用于存储哪种数据都必须符合规范上的要求才会被虚拟机认可、 装载和执行，但对于运行<br />
时常量池，Java虚拟机规范没有做任何细节的要求，不同的提供商实现的虚拟机可以按照自<br />
己的需要来实现这个内存区域。 不过，一般来说，除了保存Class文件中描述的符号引用外，<br />
还会把翻译出来的直接引用也存储在运行时常量池中[1]。<br />
运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不<br />
要求常量一定只有编译期才能产生，也就是并非预置入Class文件中常量池的内容才能进入方<br />
法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较<br />
多的便是String类的intern（）方法。<br />
既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申<br />
请到内存时会抛出OutOfMemoryError异常。<br />
[1]关于Class文件格式和符号引用等概念可参见第6章。<br />
2.2.7 直接内存<br />
直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规<br />
范中定义的内存区域。 但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError<br />
异常出现，所以我们放到这里一起讲解。<br />
在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓<br />
冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储<br />
在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。 这样能在一些场景中显著<br />
提高性能，因为避免了在Java堆和Native堆中来回复制数据。<br />
显然，本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，肯定还是<br />
会受到本机总内存（包括RAM以及SWAP区或者分页文件）大小以及处理器寻址空间的限<br />
制。 服务器管理员在配置虚拟机参数时，会根据实际内存设置-Xmx等参数信息，但经常忽略<br />
直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制），<br />
从而导致动态扩展时出现OutOfMemoryError异常。<br />
2.3 HotSpot虚拟机对象探秘<br />
介绍完Java虚拟机的运行时数据区之后，我们大致知道了虚拟机内存的概况，读者了解<br />
了内存中放了些什么后，也许就会想更进一步了解这些虚拟机内存中的数据的其他细节，譬<br />
如它们是如何创建、 如何布局以及如何访问的。 对于这样涉及细节的问题，必须把讨论范围<br />
限定在具体的虚拟机和集中在某一个内存区域上才有意义。 基于实用优先的原则，笔者以常<br />
用的虚拟机HotSpot和常用的内存区域Java堆为例，深入探讨HotSpot虚拟机在Java堆中对象分<br />
配、 布局和访问的全过程。<br />
2.3.1 对象的创建<br />
Java是一门面向对象的编程语言，在Java程序运行过程中无时无刻都有对象被创建出<br />
来。 在语言层面上，创建对象（例如克隆、 反序列化）通常仅仅是一个new关键字而已，而<br />
在虚拟机中，对象（文中讨论的对象限于普通Java对象，不包括数组和Class对象等）的创建<br />
又是怎样一个过程呢？<br />
虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一<br />
个类的符号引用，并且检查这个符号引用代表的类是否已被加载、 解析和初始化过。 如果没<br />
有，那必须先执行相应的类加载过程，本书第7章将探讨这部分内容的细节。<br />
在类加载检查通过后，接下来虚拟机将为新生对象分配内存。 对象所需内存的大小在类<br />
加载完成后便可完全确定（如何确定将在2.3.2节中介绍），为对象分配空间的任务等同于把<br />
一块确定大小的内存从Java堆中划分出来。 假设Java堆中内存是绝对规整的，所有用过的内<br />
存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配<br />
内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称<br />
为&ldquo;指针碰撞&rdquo;（Bump the Pointer）。 如果Java堆中的内存并不是规整的，已使用的内存和空<br />
闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记<br />
录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，<br />
并更新列表上的记录，这种分配方式称为&ldquo;空闲列表&rdquo;（Free List）。 选择哪种分配方式由<br />
Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决<br />
定。 因此，在使用Serial、 ParNew等带Compact过程的收集器时，系统采用的分配算法是指针<br />
碰撞，而使用CMS这种基于Mark-Sweep算法的收集器时，通常采用空闲列表。<br />
除如何划分可用空间之外，还有另外一个需要考虑的问题是对象创建在虚拟机中是非常<br />
频繁的行为，即使是仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的，<br />
可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来<br />
分配内存的情况。 解决这个问题有两种方案，一种是对分配内存空间的动作进行同步处理<br />
&mdash;&mdash;实际上虚拟机采用CAS配上失败重试的方式保证更新操作的原子性；另一种是把内存分<br />
配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内<br />
存，称为本地线程分配缓冲（Thread Local Allocation Buffer,TLAB）。 哪个线程要分配内<br />
存，就在哪个线程的TLAB上分配，只有TLAB用完并分配新的TLAB时，才需要同步锁定。<br />
虚拟机是否使用TLAB，可以通过-XX：+/-UseTLAB参数来设定。<br />
内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），<br />
如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行。 这一步操作保证了对象的实<br />
例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应<br />
的零值。<br />
接下来，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、 如何才能找<br />
到类的元数据信息、 对象的哈希码、 对象的GC分代年龄等信息。 这些信息存放在对象的对<br />
象头（Object Header）之中。 根据虚拟机当前的运行状态的不同，如是否启用偏向锁等，对<br />
象头会有不同的设置方式。 关于对象头的具体内容，稍后再做详细介绍。<br />
在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从Java程<br />
序的视角来看，对象创建才刚刚开始&mdash;&mdash;＜init＞方法还没有执行，所有的字段都还为零。<br />
所以，一般来说（由字节码中是否跟随invokespecial指令所决定），执行new指令之后会接着<br />
执行＜init＞方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完<br />
全产生出来。<br />
下面的代码清单2-1是HotSpot虚拟机bytecodeInterpreter.cpp中的代码片段（这个解释器实<br />
现很少有机会实际使用，因为大部分平台上都使用模板解释器；当代码通过JIT编译器执行<br />
时差异就更大了。 不过，这段代码用于了解HotSpot的运作过程是没有什么问题的）。<br />
代码清单2-1 HotSpot解释器的代码片段<br />
//确保常量池中存放的是已解释的类<br />
if（！constants-＞tag_at（index）.is_unresolved_klass（））{<br />
//断言确保是klassOop和instanceKlassOop（这部分下一节介绍）<br />
oop entry=（klassOop）*constants-＞obj_at_addr（index）；<br />
assert（entry-＞is_klass（），&quot;Should be resolved klass&quot;）；<br />
klassOop k_entry=（klassOop）entry；<br />
assert（k_entry-＞klass_part（）-＞oop_is_instance（），&quot;Should be instanceKlass&quot;）；<br />
instanceKlass * ik=（instanceKlass*）k_entry-＞klass_part（）；<br />
//确保对象所属类型已经经过初始化阶段<br />
if（ik-＞is_initialized（）＆＆ik-＞can_be_fastpath_allocated（））<br />
{/<br />
/取对象长度<br />
size_t obj_size=ik-＞size_helper（）；<br />
oop result=NULL；<br />
//记录是否需要将对象所有字段置零值<br />
bool need_zero=！ZeroTLAB；<br />
//是否在TLAB中分配对象<br />
if（UseTLAB）{<br />
result=（oop）THREAD-＞tlab（）.allocate（obj_size）；<br />
}i<br />
f（result==NULL）{<br />
need_zero=true；<br />
//直接在eden中分配对象<br />
retry：<br />
HeapWord * compare_to=*Universe：heap（）-＞top_addr（）；<br />
HeapWord * new_top=compare_to+obj_size；<br />
/*cmpxchg是x86中的CAS指令，这里是一个C++方法，通过CAS方式分配空间，如果并发失败，<br />
转到retry中重试，直至成功分配为止*/<br />
if（new_top＜=*Universe：heap（）-＞end_addr（））{<br />
if（Atomic：cmpxchg_ptr（new_top,Universe：heap（）-＞top_addr（），compare_to）！=compare_to）{<br />
goto retry；<br />
}r<br />
esult=（oop）compare_to；<br />
}}i<br />
f（result！=NULL）{<br />
//如果需要，则为对象初始化零值<br />
if（need_zero）{<br />
HeapWord * to_zero=（HeapWord*）result+sizeof（oopDesc）/oopSize；<br />
obj_size-=sizeof（oopDesc）/oopSize；<br />
if（obj_size＞0）{<br />
memset（to_zero，0，obj_size * HeapWordSize）；<br />
}}/<br />
/根据是否启用偏向锁来设置对象头信息<br />
if（UseBiasedLocking）{<br />
result-＞set_mark（ik-＞prototype_header（））；<br />
}else{<br />
result-＞set_mark（markOopDesc：prototype（））；<br />
}r<br />
esult-＞set_klass_gap（0）；<br />
result-＞set_klass（k_entry）；<br />
//将对象引用入栈，继续执行下一条指令<br />
SET_STACK_OBJECT（result，0）；<br />
UPDATE_PC_AND_TOS_AND_CONTINUE（3，1）；<br />
}}}<br />
2.3.2 对象的内存布局<br />
在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、<br />
实例数据（Instance Data）和对齐填充（Padding）。<br />
HotSpot虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据，<br />
如哈希码（HashCode）、 GC分代年龄、 锁状态标志、 线程持有的锁、 偏向线程ID、 偏向时<br />
间戳等，这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和<br />
64bit，官方称它为&ldquo;Mark Word&rdquo;。 对象需要存储的运行时数据很多，其实已经超出了32位、<br />
64位Bitmap结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额外存储<br />
成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的<br />
空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。 例如，在32位的<br />
HotSpot虚拟机中，如果对象处于未被锁定的状态下，那么Mark Word的32bit空间中的25bit用<br />
于存储对象哈希码，4bit用于存储对象分代年龄，2bit用于存储锁标志位，1bit固定为0，而在<br />
其他状态（轻量级锁定、 重量级锁定、 GC标记、 可偏向）下对象的存储内容见表2-1。<br />
对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指<br />
针来确定这个对象是哪个类的实例。 并不是所有的虚拟机实现都必须在对象数据上保留类型<br />
指针，换句话说，查找对象的元数据信息并不一定要经过对象本身，这点将在2.3.3节讨论。<br />
另外，如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因<br />
为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中<br />
却无法确定数组的大小。<br />
代码清单2-2为HotSpot虚拟机markOop.cpp中的代码（注释）片段，它描述了32bit下Mark<br />
Word的存储状态。<br />
代码清单2-2 markOop.cpp片段<br />
//Bit-format of an object header（most significant first,big endian layout below）：<br />
//32 bits：<br />
//--------<br />
//hash：25------------＞|age：4 biased_lock：1 lock：2（normal object）<br />
//JavaThread*：23 epoch：2 age：4 biased_lock：1 lock：2（biased object）<br />
//size：32------------------------------------------＞|（CMS free block）<br />
//PromotedObject*：29----------＞|promo_bits：3-----＞|（CMS promoted object）<br />
接下来的实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类<br />
型的字段内容。 无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。 这部分<br />
的存储顺序会受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在Java源码中定义顺<br />
序的影响。 HotSpot虚拟机默认的分配策略为longs/doubles、 ints、 shorts/chars、<br />
bytes/booleans、 oops（Ordinary Object Pointers），从分配策略中可以看出，相同宽度的字段<br />
总是被分配到一起。 在满足这个前提条件的情况下，在父类中定义的变量会出现在子类之<br />
前。 如果CompactFields参数值为true（默认为true），那么子类之中较窄的变量也可能会插入<br />
到父类变量的空隙之中。<br />
第三部分对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。<br />
由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说，<br />
就是对象的大小必须是8字节的整数倍。 而对象头部分正好是8字节的倍数（1倍或者2倍），<br />
因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。<br />
2.3.3 对象的访问定位<br />
建立对象是为了使用对象，我们的Java程序需要通过栈上的reference数据来操作堆上的<br />
具体对象。 由于reference类型在Java虚拟机规范中只规定了一个指向对象的引用，并没有定<br />
义这个引用应该通过何种方式去定位、 访问堆中的对象的具体位置，所以对象访问方式也是<br />
取决于虚拟机实现而定的。 目前主流的访问方式有使用句柄和直接指针两种。<br />
如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，reference中<br />
存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信<br />
息，如图2-2所示。<br />
图 2-2 通过句柄访问对象<br />
如果使用直接指针访问，那么Java堆对象的布局中就必须考虑如何放置访问类型数据的<br />
相关信息，而reference中存储的直接就是对象地址，如图2-3所示。<br />
图 2-3 通过直接指针访问对象<br />
这两种对象访问方式各有优势，使用句柄来访问的最大好处就是reference中存储的是稳<br />
定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中<br />
的实例数据指针，而reference本身不需要修改。<br />
使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，<br />
由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成<br />
本。 就本书讨论的主要虚拟机Sun HotSpot而言，它是使用第二种方式进行对象访问的，但从<br />
整个软件开发的范围来看，各种语言和框架使用句柄来访问的情况也十分常见。<br />
2.4 实战：OutOfMemoryError异常<br />
在Java虚拟机规范的描述中，除了程序计数器外，虚拟机内存的其他几个运行时区域都<br />
有发生OutOfMemoryError（下文称OOM）异常的可能，本节将通过若干实例来验证异常发生<br />
的场景（代码清单2-3～代码清单2-9的几段简单代码），并且会初步介绍几个与内存相关的<br />
最基本的虚拟机参数。<br />
本节内容的目的有两个：第一，通过代码验证Java虚拟机规范中描述的各个运行时区域<br />
存储的内容；第二，希望读者在工作中遇到实际的内存溢出异常时，能根据异常的信息快速<br />
判断是哪个区域的内存溢出，知道什么样的代码可能会导致这些区域内存溢出，以及出现这<br />
些异常后该如何处理。<br />
下文代码的开头都注释了执行时所需要设置的虚拟机启动参数（注释中&ldquo;VM Args&rdquo;后面<br />
跟着的参数），这些参数对实验的结果有直接影响，读者调试代码的时候千万不要忽略。 如<br />
果读者使用控制台命令来执行程序，那直接跟在Java命令之后书写就可以。 如果读者使用<br />
Eclipse IDE，则可以参考图2-4在Debug/Run页签中的设置。<br />
图 2-4 在Eclipse的Debug页签中设置虚拟机参数<br />
下文的代码都是基于Sun公司的HotSpot虚拟机运行的，对于不同公司的不同版本的虚拟<br />
机，参数和程序运行的结果可能会有所差别。<br />
2.4.1 Java堆溢出<br />
Java堆用于存储对象实例，只要不断地创建对象，并且保证GC Roots到对象之间有可达<br />
路径来避免垃圾回收机制清除这些对象，那么在对象数量到达最大堆的容量限制后就会产生<br />
内存溢出异常。<br />
代码清单2-3中代码限制Java堆的大小为20MB，不可扩展（将堆的最小值-Xms参数与最<br />
大值-Xmx参数设置为一样即可避免堆自动扩展），通过参数-XX：<br />
+HeapDumpOnOutOfMemoryError可以让虚拟机在出现内存溢出异常时Dump出当前的内存堆<br />
转储快照以便事后进行分析[1]。<br />
代码清单2-3 Java堆内存溢出异常测试<br />
/**<br />
*VM Args：-Xms20m-Xmx20m-XX：+HeapDumpOnOutOfMemoryError<br />
*@author zzm<br />
*/<br />
public class HeapOOM{<br />
static class OOMObject{<br />
}p<br />
ublic static void main（String[]args）{<br />
List＜OOMObject＞list=new ArrayList＜OOMObject＞（）；<br />
while（true）{<br />
list.add（new OOMObject（））；<br />
}}} 运<br />
行结果：<br />
java.lang.OutOfMemoryError：Java heap space<br />
Dumping heap to java_pid3404.hprof&hellip;&hellip;<br />
Heap dump file created[22045981 bytes in 0.663 secs]<br />
Java堆内存的OOM异常是实际应用中常见的内存溢出异常情况。 当出现Java堆内存溢出<br />
时，异常堆栈信息&ldquo;java.lang.OutOfMemoryError&rdquo;会跟着进一步提示&ldquo;Java heap space&rdquo;。<br />
要解决这个区域的异常，一般的手段是先通过内存映像分析工具（如Eclipse Memory<br />
Analyzer）对Dump出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，也<br />
就是要先分清楚到底是出现了内存泄漏（Memory Leak）还是内存溢出（Memory<br />
Overflow）。 图2-5显示了使用Eclipse Memory Analyzer打开的堆转储快照文件。<br />
图 2-5 使用Eclipse Memory Analyzer打开的堆转储快照文件<br />
如果是内存泄露，可进一步通过工具查看泄露对象到GC Roots的引用链。 于是就能找到<br />
泄露对象是通过怎样的路径与GC Roots相关联并导致垃圾收集器无法自动回收它们的。 掌握<br />
了泄露对象的类型信息及GC Roots引用链的信息，就可以比较准确地定位出泄露代码的位<br />
置。<br />
如果不存在泄露，换句话说，就是内存中的对象确实都还必须存活着，那就应当检查虚<br />
拟机的堆参数（-Xmx与-Xms），与机器物理内存对比看是否还可以调大，从代码上检查是<br />
否存在某些对象生命周期过长、 持有状态时间过长的情况，尝试减少程序运行期的内存消<br />
耗。<br />
以上是处理Java堆内存问题的简单思路，处理这些问题所需要的知识、 工具与经验是后<br />
面3章的主题。<br />
[1]关于堆转储快照文件分析方面的内容，可参见第4章。<br />
2.4.2 虚拟机栈和本地方法栈溢出<br />
由于在HotSpot虚拟机中并不区分虚拟机栈和本地方法栈，因此，对于HotSpot来说，虽<br />
然-Xoss参数（设置本地方法栈大小）存在，但实际上是无效的，栈容量只由-Xss参数设定。<br />
关于虚拟机栈和本地方法栈，在Java虚拟机规范中描述了两种异常：<br />
如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常。<br />
如果虚拟机在扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。<br />
这里把异常分成两种情况，看似更加严谨，但却存在着一些互相重叠的地方：当栈空间<br />
无法继续分配时，到底是内存太小，还是已使用的栈空间太大，其本质上只是对同一件事情<br />
的两种描述而已。<br />
在笔者的实验中，将实验范围限制于单线程中的操作，尝试了下面两种方法均无法让虚<br />
拟机产生OutOfMemoryError异常，尝试的结果都是获得StackOverflowError异常，测试代码如<br />
代码清单2-4所示。<br />
使用-Xss参数减少栈内存容量。 结果：抛出StackOverflowError异常，异常出现时输出的<br />
堆栈深度相应缩小。<br />
定义了大量的本地变量，增大此方法帧中本地变量表的长度。 结果：抛出<br />
StackOverflowError异常时输出的堆栈深度相应缩小。<br />
代码清单2-4 虚拟机栈和本地方法栈OOM测试（仅作为第1点测试程序）<br />
/**<br />
*VM Args：-Xss128k<br />
*@author zzm<br />
*/<br />
public class JavaVMStackSOF{<br />
private int stackLength=1；<br />
public void stackLeak（）{<br />
stackLength++；<br />
stackLeak（）；<br />
}p<br />
ublic static void main（String[]args）throws Throwable{<br />
JavaVMStackSOF oom=new JavaVMStackSOF（）；<br />
try{<br />
oom.stackLeak（）；<br />
}catch（Throwable e）{<br />
System.out.println（&quot;stack length：&quot;+oom.stackLength）；<br />
throw e；<br />
}}} 运<br />
行结果：<br />
stack length：2402<br />
Exception in thread&quot;main&quot;java.lang.StackOverflowError<br />
at org.fenixsoft.oom.VMStackSOF.leak（VMStackSOF.java：20）<br />
at org.fenixsoft.oom.VMStackSOF.leak（VMStackSOF.java：21）<br />
at org.fenixsoft.oom.VMStackSOF.leak（VMStackSOF.java：21）<br />
&hellip;&hellip;后续异常堆栈信息省略<br />
实验结果表明：在单个线程下，无论是由于栈帧太大还是虚拟机栈容量太小，当内存无<br />
法分配的时候，虚拟机抛出的都是StackOverflowError异常。<br />
如果测试时不限于单线程，通过不断地建立线程的方式倒是可以产生内存溢出异常，如<br />
代码清单2-5所示。 但是这样产生的内存溢出异常与栈空间是否足够大并不存在任何联系，<br />
或者准确地说，在这种情况下，为每个线程的栈分配的内存越大，反而越容易产生内存溢出<br />
异常。<br />
其实原因不难理解，操作系统分配给每个进程的内存是有限制的，譬如32位的Windows<br />
限制为2GB。 虚拟机提供了参数来控制Java堆和方法区的这两部分内存的最大值。 剩余的内<br />
存为2GB（操作系统限制）减去Xmx（最大堆容量），再减去MaxPermSize（最大方法区容<br />
量），程序计数器消耗内存很小，可以忽略掉。 如果虚拟机进程本身耗费的内存不计算在<br />
内，剩下的内存就由虚拟机栈和本地方法栈&ldquo;瓜分&rdquo;了。 每个线程分配到的栈容量越大，可以<br />
建立的线程数量自然就越少，建立线程时就越容易把剩下的内存耗尽。<br />
这一点读者需要在开发多线程的应用时特别注意，出现StackOverflowError异常时有错误<br />
堆栈可以阅读，相对来说，比较容易找到问题的所在。 而且，如果使用虚拟机默认参数，栈<br />
深度在大多数情况下（因为每个方法压入栈的帧大小并不是一样的，所以只能说在大多数情<br />
况下）达到1000～2000完全没有问题，对于正常的方法调用（包括递归），这个深度应该完<br />
全够用了。 但是，如果是建立过多线程导致的内存溢出，在不能减少线程数或者更换64位虚<br />
拟机的情况下，就只能通过减少最大堆和减少栈容量来换取更多的线程。 如果没有这方面的<br />
处理经验，这种通过&ldquo;减少内存&rdquo;的手段来解决内存溢出的方式会比较难以想到。<br />
代码清单2-5 创建线程导致内存溢出异常<br />
/**<br />
*VM Args：-Xss2M（这时候不妨设置大些）<br />
*@author zzm<br />
*/<br />
public class JavaVMStackOOM{<br />
private void dontStop（）{<br />
while（true）{<br />
}}p<br />
ublic void stackLeakByThread（）{<br />
while（true）{<br />
Thread thread=new Thread（new Runnable（）{<br />
@Override<br />
public void run（）{<br />
dontStop（）；<br />
}}<br />
）；<br />
thread.start（）；<br />
}}p<br />
ublic static void main（String[]args）throws Throwable{<br />
JavaVMStackOOM oom=new JavaVMStackOOM（）；<br />
oom.stackLeakByThread（）；<br />
}} 注<br />
意 特别提示一下，如果读者要尝试运行上面这段代码，记得要先保存当前的工作。<br />
由于在Windows平台的虚拟机中，Java的线程是映射到操作系统的内核线程上的[1]，因此上述<br />
代码执行时有较大的风险，可能会导致操作系统假死。<br />
运行结果：<br />
Exception in thread&quot;main&quot;java.lang.OutOfMemoryError：unable to create new native thread<br />
[1]关于虚拟机线程实现方面的内容可以参考本书第12章。<br />
2.4.3 方法区和运行时常量池溢出<br />
由于运行时常量池是方法区的一部分，因此这两个区域的溢出测试就放在一起进行。 前<br />
面提到JDK 1.7开始逐步&ldquo;去永久代&rdquo;的事情，在此就以测试代码观察一下这件事对程序的实际<br />
影响。<br />
String.intern（）是一个Native方法，它的作用是：如果字符串常量池中已经包含一个等<br />
于此String对象的字符串，则返回代表池中这个字符串的String对象；否则，将此String对象包<br />
含的字符串添加到常量池中，并且返回此String对象的引用。 在JDK 1.6及之前的版本中，由<br />
于常量池分配在永久代内，我们可以通过-XX：PermSize和-XX：MaxPermSize限制方法区大<br />
小，从而间接限制其中常量池的容量，如代码清单2-6所示。<br />
代码清单2-6 运行时常量池导致的内存溢出异常<br />
/**<br />
*VM Args：-XX：PermSize=10M-XX：MaxPermSize=10M<br />
*@author zzm<br />
*/<br />
public class RuntimeConstantPoolOOM{<br />
public static void main（String[]args）{<br />
//使用List保持着常量池引用，避免Full GC回收常量池行为<br />
List＜String＞list=new ArrayList＜String＞（）；<br />
//10MB的PermSize在integer范围内足够产生OOM了<br />
int i=0；<br />
while（true）{<br />
list.add（String.valueOf（i++）.intern（））；<br />
}}} 运<br />
行结果：<br />
Exception in thread&quot;main&quot;java.lang.OutOfMemoryError：PermGen space<br />
at java.lang.String.intern（Native Method）<br />
at org.fenixsoft.oom.RuntimeConstantPoolOOM.main（RuntimeConstantPoolOOM.java：18）<br />
从运行结果中可以看到，运行时常量池溢出，在OutOfMemoryError后面跟随的提示信息<br />
是&ldquo;PermGen space&rdquo;，说明运行时常量池属于方法区（HotSpot虚拟机中的永久代）的一部<br />
分。<br />
而使用JDK 1.7运行这段程序就不会得到相同的结果，while循环将一直进行下去。 关于<br />
这个字符串常量池的实现问题，还可以引申出一个更有意思的影响，如代码清单2-7所示。<br />
代码清单2-7 String.intern（）返回引用的测试<br />
public class RuntimeConstantPoolOOM{<br />
public static void main（String[]args）{<br />
public static void main（String[]args）{<br />
String str1=new StringBuilder（&quot;计算机&quot;）.append（&quot;软件&quot;）.toString（）；<br />
System.out.println（str1.intern（）==str1）；<br />
String str2=new StringBuilder（&quot;ja&quot;）.append（&quot;va&quot;）.toString（）；<br />
System.out.println（str2.intern（）==str2）；<br />
}}} 这<br />
段代码在JDK 1.6中运行，会得到两个false，而在JDK 1.7中运行，会得到一个true和一<br />
个false。 产生差异的原因是：在JDK 1.6中，intern（）方法会把首次遇到的字符串实例复制<br />
到永久代中，返回的也是永久代中这个字符串实例的引用，而由StringBuilder创建的字符串<br />
实例在Java堆上，所以必然不是同一个引用，将返回false。 而JDK 1.7（以及部分其他虚拟<br />
机，例如JRockit）的intern（）实现不会再复制实例，只是在常量池中记录首次出现的实例<br />
引用，因此intern（）返回的引用和由StringBuilder创建的那个字符串实例是同一个。 对str2比<br />
较返回false是因为&ldquo;java&rdquo;这个字符串在执行StringBuilder.toString（）之前已经出现过，字符串<br />
常量池中已经有它的引用了，不符合&ldquo;首次出现&rdquo;的原则，而&ldquo;计算机软件&rdquo;这个字符串则是首<br />
次出现的，因此返回true。<br />
方法区用于存放Class的相关信息，如类名、 访问修饰符、 常量池、 字段描述、 方法描述<br />
等。 对于这些区域的测试，基本的思路是运行时产生大量的类去填满方法区，直到溢出。 虽<br />
然直接使用Java SE API也可以动态产生类（如反射时的GeneratedConstructorAccessor和动态<br />
代理等），但在本次实验中操作起来比较麻烦。 在代码清单2-8中，笔者借助CGLib[1]直接操<br />
作字节码运行时生成了大量的动态类。<br />
值得特别注意的是，我们在这个例子中模拟的场景并非纯粹是一个实验，这样的应用经<br />
常会出现在实际应用中：当前的很多主流框架，如Spring、 Hibernate，在对类进行增强时，<br />
都会使用到CGLib这类字节码技术，增强的类越多，就需要越大的方法区来保证动态生成的<br />
Class可以加载入内存。 另外，JVM上的动态语言（例如Groovy等）通常都会持续创建类来实<br />
现语言的动态性，随着这类语言的流行，也越来越容易遇到与代码清单2-8相似的溢出场<br />
景。<br />
代码清单2-8 借助CGLib使方法区出现内存溢出异常<br />
/**<br />
*VM Args：-XX：PermSize=10M-XX：MaxPermSize=10M<br />
*@author zzm<br />
*/<br />
public class JavaMethodAreaOOM{<br />
public static void main（String[]args）{<br />
while（true）{<br />
Enhancer enhancer=new Enhancer（）；<br />
enhancer.setSuperclass（OOMObject.class）；<br />
enhancer.setUseCache（false）；<br />
enhancer.setCallback（new MethodInterceptor（）{<br />
public Object intercept（Object obj,Method method,Object[]args,MethodProxy proxy）throws Throwable{<br />
return proxy.invokeSuper（obj,args）；<br />
}}<br />
）；<br />
enhancer.create（）；<br />
}}s<br />
tatic class OOMObject{<br />
}} 运<br />
行结果：<br />
Caused by：java.lang.OutOfMemoryError：PermGen space<br />
at java.lang.ClassLoader.defineClass1（Native Method）<br />
at java.lang.ClassLoader.defineClassCond（ClassLoader.java：632）<br />
at java.lang.ClassLoader.defineClass（ClassLoader.java：616）<br />
&hellip;&hellip;8 more<br />
方法区溢出也是一种常见的内存溢出异常，一个类要被垃圾收集器回收掉，判定条件是<br />
比较苛刻的。 在经常动态生成大量Class的应用中，需要特别注意类的回收状况。 这类场景除<br />
了上面提到的程序使用了CGLib字节码增强和动态语言之外，常见的还有：大量JSP或动态产<br />
生JSP文件的应用（JSP第一次运行时需要编译为Java类）、 基于OSGi的应用（即使是同一个<br />
类文件，被不同的加载器加载也会视为不同的类）等。<br />
[1]CGLib开源项目：http://cglib.sourceforge.net/。<br />
2.4.4 本机直接内存溢出<br />
DirectMemory容量可通过-XX：MaxDirectMemorySize指定，如果不指定，则默认与Java<br />
堆最大值（-Xmx指定）一样，代码清单2-9越过了DirectByteBuffer类，直接通过反射获取<br />
Unsafe实例进行内存分配（Unsafe类的getUnsafe（）方法限制了只有引导类加载器才会返回<br />
实例，也就是设计者希望只有rt.jar中的类才能使用Unsafe的功能）。 因为，虽然使用<br />
DirectByteBuffer分配内存也会抛出内存溢出异常，但它抛出异常时并没有真正向操作系统申<br />
请分配内存，而是通过计算得知内存无法分配，于是手动抛出异常，真正申请分配内存的方<br />
法是unsafe.allocateMemory（）。<br />
代码清单2-9 使用unsafe分配本机内存<br />
/**<br />
*VM Args：-Xmx20M-XX：MaxDirectMemorySize=10M<br />
*@author zzm<br />
*/<br />
public class DirectMemoryOOM{<br />
private static final int_1MB=1024*1024；<br />
public static void main（String[]args）throws Exception{<br />
Field unsafeField=Unsafe.class.getDeclaredFields（）[0]；<br />
unsafeField.setAccessible（true）；<br />
Unsafe unsafe=（Unsafe）unsafeField.get（null）；<br />
while（true）{<br />
unsafe.allocateMemory（_1MB）；<br />
}}} 运<br />
行结果：<br />
Exception in thread&quot;main&quot;java.lang.OutOfMemoryError<br />
at sun.misc.Unsafe.allocateMemory（Native Method）<br />
at org.fenixsoft.oom.DMOOM.main（DMOOM.java：20）<br />
由DirectMemory导致的内存溢出，一个明显的特征是在Heap Dump文件中不会看见明显<br />
的异常，如果读者发现OOM之后Dump文件很小，而程序中又直接或间接使用了NIO，那就<br />
可以考虑检查一下是不是这方面的原因。<br />
2.5 本章小结<br />
通过本章的学习，我们明白了虚拟机中的内存是如何划分的，哪部分区域、 什么样的代<br />
码和操作可能导致内存溢出异常。 虽然Java有垃圾收集机制，但内存溢出异常离我们仍然并<br />
不遥远，本章只是讲解了各个区域出现内存溢出异常的原因，第3章将详细讲解Java垃圾收<br />
集机制为了避免内存溢出异常的出现都做了哪些努力。</p>

<h2><br />
第3章 垃圾收集器与内存分配策略</h2>

<p><br />
Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的&ldquo;高墙&rdquo;，墙外面的人想<br />
进去，墙里面的人却想出来。<br />
3.1 概述<br />
说起垃圾收集（Garbage Collection,GC），大部分人都把这项技术当做Java语言的伴生产<br />
物。 事实上，GC的历史比Java久远，1960年诞生于MIT的Lisp是第一门真正使用内存动态分<br />
配和垃圾收集技术的语言。 当Lisp还在胚胎时期时，人们就在思考GC需要完成的3件事情：<br />
哪些内存需要回收？<br />
什么时候回收？<br />
如何回收？<br />
经过半个多世纪的发展，目前内存的动态分配与内存回收技术已经相当成熟，一切看起<br />
来都进入了&ldquo;自动化&rdquo;时代，那为什么我们还要去了解GC和内存分配呢？答案很简单：当需<br />
要排查各种内存溢出、 内存泄漏问题时，当垃圾收集成为系统达到更高并发量的瓶颈时，我<br />
们就需要对这些&ldquo;自动化&rdquo;的技术实施必要的监控和调节。<br />
把时间从半个多世纪以前拨回到现在，回到我们熟悉的Java语言。 第2章介绍了Java内存<br />
运行时区域的各个部分，其中程序计数器、 虚拟机栈、 本地方法栈3个区域随线程而生，随<br />
线程而灭；栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作。 每一个<br />
栈帧中分配多少内存基本上是在类结构确定下来时就已知的（尽管在运行期会由JIT编译器<br />
进行一些优化，但在本章基于概念模型的讨论中，大体上可以认为是编译期可知的），因此<br />
这几个区域的内存分配和回收都具备确定性，在这几个区域内就不需要过多考虑回收的问<br />
题，因为方法结束或者线程结束时，内存自然就跟随着回收了。 而Java堆和方法区则不一<br />
样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也<br />
可能不一样，我们只有在程序处于运行期间时才能知道会创建哪些对象，这部分内存的分配<br />
和回收都是动态的，垃圾收集器所关注的是这部分内存，本章后续讨论中的&ldquo;内存&rdquo;分配与回<br />
收也仅指这一部分内存。<br />
3.2 对象已死吗<br />
在堆里面存放着Java世界中几乎所有的对象实例，垃圾收集器在对堆进行回收前，第一<br />
件事情就是要确定这些对象之中哪些还&ldquo;存活&rdquo;着，哪些已经&ldquo;死去&rdquo;（即不可能再被任何途径<br />
使用的对象）。<br />
3.2.1 引用计数算法<br />
很多教科书判断对象是否存活的算法是这样的：给对象中添加一个引用计数器，每当有<br />
一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0<br />
的对象就是不可能再被使用的。 作者面试过很多的应届生和一些有多年工作经验的开发人<br />
员，他们对于这个问题给予的都是这个答案。<br />
客观地说，引用计数算法（Reference Counting）的实现简单，判定效率也很高，在大部<br />
分情况下它都是一个不错的算法，也有一些比较著名的应用案例，例如微软公司的<br />
COM（Component Object Model）技术、 使用ActionScript 3的FlashPlayer、 Python语言和在游<br />
戏脚本领域被广泛应用的Squirrel中都使用了引用计数算法进行内存管理。 但是，至少主流<br />
的Java虚拟机里面没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象<br />
之间相互循环引用的问题。<br />
举个简单的例子，请看代码清单3-1中的testGC（）方法：对象objA和objB都有字段<br />
instance，赋值令objA.instance=objB及objB.instance=objA，除此之外，这两个对象再无任何引<br />
用，实际上这两个对象已经不可能再被访问，但是它们因为互相引用着对方，导致它们的引<br />
用计数都不为0，于是引用计数算法无法通知GC收集器回收它们。<br />
代码清单3-1 引用计数算法的缺陷<br />
/**<br />
*testGC（）方法执行后，objA和objB会不会被GC呢？<br />
*@author zzm<br />
*/<br />
public class ReferenceCountingGC{<br />
public Object instance=null；<br />
private static final int_1MB=1024*1024；<br />
/**<br />
*这个成员属性的唯一意义就是占点内存，以便能在GC日志中看清楚是否被回收过<br />
*/<br />
private byte[]bigSize=new byte[2*_1MB]；<br />
public static void testGC（）{<br />
ReferenceCountingGC objA=new ReferenceCountingGC（）；<br />
ReferenceCountingGC objB=new ReferenceCountingGC（）；<br />
objA.instance=objB；<br />
objB.instance=objA；<br />
objA=null；<br />
objB=null；<br />
//假设在这行发生GC,objA和objB是否能被回收？<br />
System.gc（）；<br />
}} 运<br />
行结果：<br />
[F u l l G C（S y s t e m）[T e n u r e d：0 K-＞2 1 0 K（1 0 2 4 0 K），0.0 1 4 9 1 4 2 s e c s]4603K-＞210K（19456K），[Perm：2999K-＞<br />
2999K（21248K）]，0.0150007 secs][Times：user=0.01 sys=0.00，real=0.02 secs]<br />
Heap<br />
def new generation total 9216K,used 82K[0x00000000055e0000，0x0000000005fe0000，0x0000000005fe0000）<br />
Eden space 8192K，1%used[0x00000000055e0000，0x00000000055f4850，0x0000000005de0000）<br />
from space 1024K，0%used[0x0000000005de0000，0x0000000005de0000，0x0000000005ee0000）<br />
to space 1024K，0%used[0x0000000005ee0000，0x0000000005ee0000，0x0000000005fe0000）<br />
tenured generation total 10240K,used 210K[0x0000000005fe0000，0x00000000069e0000，0x00000000069e0000）<br />
the space 10240K，2%used[0x0000000005fe0000，0x0000000006014a18，0x0000000006014c00，0x00000000069e0000）<br />
compacting perm gen total 21248K,used 3016K[0x00000000069e0000，0x0000000007ea0000，0x000000000bde0000）<br />
the space 21248K，14%used[0x00000000069e0000，0x0000000006cd2398，0x0000000006cd2400，0x0000000007ea0000）<br />
No shared spaces configured.<br />
从运行结果中可以清楚看到，GC日志中包含&ldquo;4603K-＞210K&rdquo;，意味着虚拟机并没有因<br />
为这两个对象互相引用就不回收它们，这也从侧面说明虚拟机并不是通过引用计数算法来判<br />
断对象是否存活的。<br />
3.2.2 可达性分析算法<br />
在主流的商用程序语言（Java、 C#，甚至包括前面提到的古老的Lisp）的主流实现中，<br />
都是称通过可达性分析（Reachability Analysis）来判定对象是否存活的。 这个算法的基本思<br />
路就是通过一系列的称为&ldquo;GC Roots&rdquo;的对象作为起始点，从这些节点开始向下搜索，搜索所<br />
走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连<br />
（用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。 如<br />
图3-1所示，对象object 5、 object 6、 object 7虽然互相有关联，但是它们到GC Roots是不可达<br />
的，所以它们将会被判定为是可回收的对象。<br />
图 3-1 可达性分析算法判定对象是否可回收<br />
在Java语言中，可作为GC Roots的对象包括下面几种：<br />
虚拟机栈（栈帧中的本地变量表）中引用的对象。<br />
方法区中类静态属性引用的对象。<br />
方法区中常量引用的对象。<br />
本地方法栈中JNI（即一般说的Native方法）引用的对象。<br />
3.2.3 再谈引用<br />
无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象的引<br />
用链是否可达，判定对象是否存活都与&ldquo;引用&rdquo;有关。 在JDK 1.2以前，Java中的引用的定义很<br />
传统：如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块<br />
内存代表着一个引用。 这种定义很纯粹，但是太过狭隘，一个对象在这种定义下只有被引用<br />
或者没有被引用两种状态，对于如何描述一些&ldquo;食之无味，弃之可惜&rdquo;的对象就显得无能为<br />
力。 我们希望能描述这样一类对象：当内存空间还足够时，则能保留在内存之中；如果内存<br />
空间在进行垃圾收集后还是非常紧张，则可以抛弃这些对象。 很多系统的缓存功能都符合这<br />
样的应用场景。<br />
在JDK 1.2之后，Java对引用的概念进行了扩充，将引用分为强引用（Strong<br />
Reference）、 软引用（Soft Reference）、 弱引用（Weak Reference）、 虚引用（Phantom<br />
Reference）4种，这4种引用强度依次逐渐减弱。<br />
强引用就是指在程序代码之中普遍存在的，类似&ldquo;Object obj=new Object（）&rdquo;这类的引<br />
用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。<br />
软引用是用来描述一些还有用但并非必需的对象。 对于软引用关联着的对象，在系统将<br />
要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。 如果这次回<br />
收还没有足够的内存，才会抛出内存溢出异常。 在JDK 1.2之后，提供了SoftReference类来实<br />
现软引用。<br />
弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的<br />
对象只能生存到下一次垃圾收集发生之前。 当垃圾收集器工作时，无论当前内存是否足够，<br />
都会回收掉只被弱引用关联的对象。 在JDK 1.2之后，提供了WeakReference类来实现弱引<br />
用。<br />
虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。 一个对象是否有虚引<br />
用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。 为一<br />
个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。 在<br />
JDK 1.2之后，提供了PhantomReference类来实现虚引用。<br />
3.2.4 生存还是死亡<br />
即使在可达性分析算法中不可达的对象，也并非是&ldquo;非死不可&rdquo;的，这时候它们暂时处<br />
于&ldquo;缓刑&rdquo;阶段，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行可达<br />
性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，<br />
筛选的条件是此对象是否有必要执行finalize（）方法。 当对象没有覆盖finalize（）方法，或<br />
者finalize（）方法已经被虚拟机调用过，虚拟机将这两种情况都视为&ldquo;没有必要执行&rdquo;。<br />
如果这个对象被判定为有必要执行finalize（）方法，那么这个对象将会放置在一个叫做<br />
F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、 低优先级的Finalizer线程去执行<br />
它。 这里所谓的&ldquo;执行&rdquo;是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做<br />
的原因是，如果一个对象在finalize（）方法中执行缓慢，或者发生了死循环（更极端的情<br />
况），将很可能会导致F-Queue队列中其他对象永久处于等待，甚至导致整个内存回收系统<br />
崩溃。 finalize（）方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象<br />
进行第二次小规模的标记，如果对象要在finalize（）中成功拯救自己&mdash;&mdash;只要重新与引用链<br />
上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的<br />
成员变量，那在第二次标记时它将被移除出&ldquo;即将回收&rdquo;的集合；如果对象这时候还没有逃<br />
脱，那基本上它就真的被回收了。 从代码清单3-2中我们可以看到一个对象的finalize（）被<br />
执行，但是它仍然可以存活。<br />
代码清单3-2 一次对象自我拯救的演示<br />
/**<br />
*此代码演示了两点：<br />
*1.对象可以在被GC时自我拯救。<br />
*2.这种自救的机会只有一次，因为一个对象的finalize（）方法最多只会被系统自动调用一次<br />
*@author zzm<br />
*/<br />
public class FinalizeEscapeGC{<br />
public static FinalizeEscapeGC SAVE_HOOK=null；<br />
public void isAlive（）{<br />
System.out.println（&quot;yes,i am still alive：）&quot;）；<br />
}@<br />
Override<br />
protected void finalize（）throws Throwable{<br />
super.finalize（）；<br />
System.out.println（&quot;finalize mehtod executed！&quot;）；<br />
FinalizeEscapeGC.SAVE_HOOK=this；<br />
}p<br />
ublic static void main（String[]args）throws Throwable{<br />
SAVE_HOOK=new FinalizeEscapeGC（）；<br />
//对象第一次成功拯救自己<br />
SAVE_HOOK=null；<br />
System.gc（）；<br />
//因为finalize方法优先级很低，所以暂停0.5秒以等待它<br />
Thread.sleep（500）；<br />
if（SAVE_HOOK！=null）{<br />
SAVE_HOOK.isAlive（）；<br />
}else{<br />
System.out.println（&quot;no,i am dead：（&quot;）；<br />
}/<br />
/下面这段代码与上面的完全相同，但是这次自救却失败了<br />
SAVE_HOOK=null；<br />
System.gc（）；<br />
//因为finalize方法优先级很低，所以暂停0.5秒以等待它<br />
Thread.sleep（500）；<br />
if（SAVE_HOOK！=null）{<br />
SAVE_HOOK.isAlive（）；<br />
}else{<br />
System.out.println（&quot;no,i am dead：（&quot;）；<br />
}}} 运<br />
行结果：<br />
finalize mehtod executed！<br />
yes,i am still alive：）<br />
no,i am dead：（<br />
从代码清单3-2的运行结果可以看出，SAVE_HOOK对象的finalize（）方法确实被GC收<br />
集器触发过，并且在被收集前成功逃脱了。<br />
另外一个值得注意的地方是，代码中有两段完全一样的代码片段，执行结果却是一次逃<br />
脱成功，一次失败，这是因为任何一个对象的finalize（）方法都只会被系统自动调用一次，<br />
如果对象面临下一次回收，它的finalize（）方法不会被再次执行，因此第二段代码的自救行<br />
动失败了。<br />
需要特别说明的是，上面关于对象死亡时finalize（）方法的描述可能带有悲情的艺术色<br />
彩，笔者并不鼓励大家使用这种方法来拯救对象。 相反，笔者建议大家尽量避免使用它，因<br />
为它不是C/C++中的析构函数，而是Java刚诞生时为了使C/C++程序员更容易接受它所做出的<br />
一个妥协。 它的运行代价高昂，不确定性大，无法保证各个对象的调用顺序。 有些教材中描<br />
述它适合做&ldquo;关闭外部资源&rdquo;之类的工作，这完全是对这个方法用途的一种自我安慰。<br />
finalize（）能做的所有工作，使用try-finally或者其他方式都可以做得更好、 更及时，所以笔<br />
者建议大家完全可以忘掉Java语言中有这个方法的存在。<br />
3.2.5 回收方法区<br />
很多人认为方法区（或者HotSpot虚拟机中的永久代）是没有垃圾收集的，Java虚拟机规<br />
范中确实说过可以不要求虚拟机在方法区实现垃圾收集，而且在方法区中进行垃圾收集<br />
的&ldquo;性价比&rdquo;一般比较低：在堆中，尤其是在新生代中，常规应用进行一次垃圾收集一般可以<br />
回收70%～95%的空间，而永久代的垃圾收集效率远低于此。<br />
永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类。 回收废弃常量与回收<br />
Java堆中的对象非常类似。 以常量池中字面量的回收为例，假如一个字符串&ldquo;abc&rdquo;已经进入了<br />
常量池中，但是当前系统没有任何一个String对象是叫做&ldquo;abc&rdquo;的，换句话说，就是没有任何<br />
String对象引用常量池中的&ldquo;abc&rdquo;常量，也没有其他地方引用了这个字面量，如果这时发生内<br />
存回收，而且必要的话，这个&ldquo;abc&rdquo;常量就会被系统清理出常量池。 常量池中的其他类（接<br />
口）、 方法、 字段的符号引用也与此类似。<br />
判定一个常量是否是&ldquo;废弃常量&rdquo;比较简单，而要判定一个类是否是&ldquo;无用的类&rdquo;的条件则<br />
相对苛刻许多。 类需要同时满足下面3个条件才能算是&ldquo;无用的类&rdquo;：<br />
该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例。<br />
加载该类的ClassLoader已经被回收。<br />
该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该<br />
类的方法。<br />
虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是&ldquo;可以&rdquo;，而并不是<br />
和对象一样，不使用了就必然会回收。 是否对类进行回收，HotSpot虚拟机提供了-Xnoclassgc<br />
参数进行控制，还可以使用-verbose：class以及-XX：+TraceClassLoading、 -XX：<br />
+TraceClassUnLoading查看类加载和卸载信息，其中-verbose：class和-XX：<br />
+TraceClassLoading可以在Product版的虚拟机中使用，-XX：+TraceClassUnLoading参数需要<br />
FastDebug版的虚拟机支持。<br />
在大量使用反射、 动态代理、 CGLib等ByteCode框架、 动态生成JSP以及OSGi这类频繁<br />
自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。<br />
3.3 垃圾收集算法<br />
由于垃圾收集算法的实现涉及大量的程序细节，而且各个平台的虚拟机操作内存的方法<br />
又各不相同，因此本节不打算过多地讨论算法的实现，只是介绍几种算法的思想及其发展过<br />
程。<br />
3.3.1 标记-清除算法<br />
最基础的收集算法是&ldquo;标记-清除&rdquo;（Mark-Sweep）算法，如同它的名字一样，算法分<br />
为&ldquo;标记&rdquo;和&ldquo;清除&rdquo;两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有<br />
被标记的对象，它的标记过程其实在前一节讲述对象标记判定时已经介绍过了。 之所以说它<br />
是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到<br />
的。 它的主要不足有两个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是<br />
空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程<br />
序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾<br />
收集动作。 标记&mdash;清除算法的执行过程如图3-2所示。<br />
图 3-2 &ldquo;标记-清除&rdquo;算法示意图<br />
3.3.2 复制算法<br />
为了解决效率问题，一种称为&ldquo;复制&rdquo;（Copying）的收集算法出现了，它将可用内存按容<br />
量划分为大小相等的两块，每次只使用其中的一块。 当这一块的内存用完了，就将还存活着<br />
的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。 这样使得每次都是<br />
对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指<br />
针，按顺序分配内存即可，实现简单，运行高效。 只是这种算法的代价是将内存缩小为了原<br />
来的一半，未免太高了一点。 复制算法的执行过程如图3-3所示。<br />
图 3-3 复制算法示意图<br />
现在的商业虚拟机都采用这种收集算法来回收新生代，IBM公司的专门研究表明，新生<br />
代中的对象98%是&ldquo;朝生夕死&rdquo;的，所以并不需要按照1:1的比例来划分内存空间，而是将内存<br />
分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor[1]。<br />
当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最<br />
后清理掉Eden和刚才用过的Survivor空间。 HotSpot虚拟机默认Eden和Survivor的大小比例是<br />
8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%<br />
的内存会被&ldquo;浪费&rdquo;。 当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每<br />
次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里<br />
指老年代）进行分配担保（Handle Promotion）。<br />
内存的分配担保就好比我们去银行借款，如果我们信誉很好，在98%的情况下都能按时<br />
偿还，于是银行可能会默认我们下一次也能按时按量地偿还贷款，只需要有一个担保人能保<br />
证如果我不能还款时，可以从他的账户扣钱，那银行就认为没有风险了。 内存的分配担保也<br />
一样，如果另外一块Survivor空间没有足够空间存放上一次新生代收集下来的存活对象时，<br />
这些对象将直接通过分配担保机制进入老年代。 关于对新生代进行分配担保的内容，在本章<br />
稍后在讲解垃圾收集器执行规则时还会再详细讲解。<br />
[1]这里需要说明一下，在HotSpot中的这种分代方式从最初就是这种布局，与IBM的研究并<br />
没有什么实际联系。 本书列举IBM的研究只是为了说明这种分代布局的意义所在。<br />
3.3.3 标记-整理算法<br />
复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。 更关键的<br />
是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中<br />
所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。<br />
根据老年代的特点，有人提出了另外一种&ldquo;标记-整理&rdquo;（Mark-Compact）算法，标记过程<br />
仍然与&ldquo;标记-清除&rdquo;算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存<br />
活的对象都向一端移动，然后直接清理掉端边界以外的内存，&ldquo;标记-整理&rdquo;算法的示意图如<br />
图3-4所示。<br />
图 3-4 &ldquo;标记-整理&rdquo;算法示意图<br />
3.3.4 分代收集算法<br />
当前商业虚拟机的垃圾收集都采用&ldquo;分代收集&rdquo;（Generational Collection）算法，这种算<br />
法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。 一般是把Java堆<br />
分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。 在新生代<br />
中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付<br />
出少量存活对象的复制成本就可以完成收集。 而老年代中因为对象存活率高、 没有额外空间<br />
对它进行分配担保，就必须使用&ldquo;标记&mdash;清理&rdquo;或者&ldquo;标记&mdash;整理&rdquo;算法来进行回收。<br />
3.4 HotSpot的算法实现<br />
3.2 节和3.3节从理论上介绍了对象存活判定算法和垃圾收集算法，而在HotSpot虚拟机<br />
上实现这些算法时，必须对算法的执行效率有严格的考量，才能保证虚拟机高效运行。<br />
3.4.1 枚举根节点<br />
从可达性分析中从GC Roots节点找引用链这个操作为例，可作为GC Roots的节点主要在<br />
全局性的引用（例如常量或类静态属性）与执行上下文（例如栈帧中的本地变量表）中，现<br />
在很多应用仅仅方法区就有数百兆，如果要逐个检查这里面的引用，那么必然会消耗很多时<br />
间。<br />
另外，可达性分析对执行时间的敏感还体现在GC停顿上，因为这项分析工作必须在一<br />
个能确保一致性的快照中进行&mdash;&mdash;这里&ldquo;一致性&rdquo;的意思是指在整个分析期间整个执行系统看<br />
起来就像被冻结在某个时间点上，不可以出现分析过程中对象引用关系还在不断变化的情<br />
况，该点不满足的话分析结果准确性就无法得到保证。 这点是导致GC进行时必须停顿所有<br />
Java执行线程（Sun将这件事情称为&ldquo;Stop The World&rdquo;）的其中一个重要原因，即使是在号称<br />
（几乎）不会发生停顿的CMS收集器中，枚举根节点时也是必须要停顿的。<br />
由于目前的主流Java虚拟机使用的都是准确式GC（这个概念在第1章介绍Exact VM对<br />
Classic VM的改进时讲过），所以当执行系统停顿下来后，并不需要一个不漏地检查完所有<br />
执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。 在<br />
HotSpot的实现中，是使用一组称为OopMap的数据结构来达到这个目的的，在类加载完成的<br />
时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编译过程中，也<br />
会在特定的位置记录下栈和寄存器中哪些位置是引用。 这样，GC在扫描时就可以直接得知<br />
这些信息了。 下面的代码清单3-3是HotSpot Client VM生成的一段String.hashCode（）方法的<br />
本地代码，可以看到在0x026eb7a9处的call指令有OopMap记录，它指明了EBX寄存器和栈中<br />
偏移量为16的内存区域中各有一个普通对象指针（Ordinary Object Pointer）的引用，有效范<br />
围为从call指令开始直到0x026eb730（指令流的起始位置）+142（OopMap记录的偏移<br />
量）=0x026eb7be，即hlt指令为止。<br />
代码清单3-3 String.hashCode（）方法编译后的本地代码<br />
[Verified Entry Point]<br />
0x026eb730：mov%eax，-0x8000（%esp）<br />
&hellip;&hellip;<br />
；ImplicitNullCheckStub slow case<br />
0x026eb7a9：call 0x026e83e0<br />
；OopMap{ebx=Oop[16]=Oop off=142}<br />
；*caload<br />
；-java.lang.String：hashCode@48（line 1489）<br />
；{runtime_call}<br />
0x026eb7ae：push$0x83c5c18<br />
；{external_word}<br />
0x026eb7b3：call 0x026eb7b8<br />
0x026eb7b8：pusha<br />
0x026eb7b9：call 0x0822bec0；{runtime_call}<br />
0x026eb7be：hlt<br />
3.4.2 安全点<br />
在OopMap的协助下，HotSpot可以快速且准确地完成GC Roots枚举，但一个很现实的问<br />
题随之而来：可能导致引用关系变化，或者说OopMap内容变化的指令非常多，如果为每一<br />
条指令都生成对应的OopMap，那将会需要大量的额外空间，这样GC的空间成本将会变得很<br />
高。<br />
实际上，HotSpot也的确没有为每条指令都生成OopMap，前面已经提到，只是在&ldquo;特定的<br />
位置&rdquo;记录了这些信息，这些位置称为安全点（Safepoint），即程序执行时并非在所有地方都<br />
能停顿下来开始GC，只有在到达安全点时才能暂停。 Safepoint的选定既不能太少以致于让<br />
GC等待时间太长，也不能过于频繁以致于过分增大运行时的负荷。 所以，安全点的选定基<br />
本上是以程序&ldquo;是否具有让程序长时间执行的特征&rdquo;为标准进行选定的&mdash;&mdash;因为每条指令执行<br />
的时间都非常短暂，程序不太可能因为指令流长度太长这个原因而过长时间运行，&ldquo;长时间<br />
执行&rdquo;的最明显特征就是指令序列复用，例如方法调用、 循环跳转、 异常跳转等，所以具有<br />
这些功能的指令才会产生Safepoint。<br />
对于Sefepoint，另一个需要考虑的问题是如何在GC发生时让所有线程（这里不包括执行<br />
JNI调用的线程）都&ldquo;跑&rdquo;到最近的安全点上再停顿下来。 这里有两种方案可供选择：抢先式<br />
中断（Preemptive Suspension）和主动式中断（Voluntary Suspension），其中抢先式中断不需<br />
要线程的执行代码主动去配合，在GC发生时，首先把所有线程全部中断，如果发现有线程<br />
中断的地方不在安全点上，就恢复线程，让它&ldquo;跑&rdquo;到安全点上。 现在几乎没有虚拟机实现采<br />
用抢先式中断来暂停线程从而响应GC事件。<br />
而主动式中断的思想是当GC需要中断线程的时候，不直接对线程操作，仅仅简单地设<br />
置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。<br />
轮询标志的地方和安全点是重合的，另外再加上创建对象需要分配内存的地方。 下面代码清<br />
单3-4中的test指令是HotSpot生成的轮询指令，当需要暂停线程时，虚拟机把0x160100的内存<br />
页设置为不可读，线程执行到test指令时就会产生一个自陷异常信号，在预先注册的异常处<br />
理器中暂停线程实现等待，这样一条汇编指令便完成安全点轮询和触发线程中断。<br />
代码清单3-4 轮询指令<br />
0x01b6d627：call 0x01b2b210；OopMap{[60]=Oop off=460}<br />
；*invokeinterface size<br />
；-Client1：main@113（line 23）<br />
；{virtual_call}<br />
0x01b6d62c：nop<br />
；OopMap{[60]=Oop off=461}<br />
；*if_icmplt<br />
；-Client1：main@118（line 23）<br />
0x01b6d62d：test%eax，0x160100；{poll}<br />
0x01b6d633：mov 0x50（%esp），%esi<br />
0x01b6d637：cmp%eax，%esi<br />
3.4.3 安全区域<br />
使用Safepoint似乎已经完美地解决了如何进入GC的问题，但实际情况却并不一定。<br />
Safepoint机制保证了程序执行时，在不太长的时间内就会遇到可进入GC的Safepoint。 但是，<br />
程序&ldquo;不执行&rdquo;的时候呢？所谓的程序不执行就是没有分配CPU时间，典型的例子就是线程处<br />
于Sleep状态或者Blocked状态，这时候线程无法响应JVM的中断请求，&ldquo;走&rdquo;到安全的地方去<br />
中断挂起，JVM也显然不太可能等待线程重新被分配CPU时间。 对于这种情况，就需要安全<br />
区域（Safe Region）来解决。<br />
安全区域是指在一段代码片段之中，引用关系不会发生变化。 在这个区域中的任意地方<br />
开始GC都是安全的。 我们也可以把Safe Region看做是被扩展了的Safepoint。<br />
在线程执行到Safe Region中的代码时，首先标识自己已经进入了Safe Region，那样，当<br />
在这段时间里JVM要发起GC时，就不用管标识自己为Safe Region状态的线程了。 在线程要离<br />
开Safe Region时，它要检查系统是否已经完成了根节点枚举（或者是整个GC过程），如果完<br />
成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开Safe Region的信号为<br />
止。<br />
到此，笔者简要地介绍了HotSpot虚拟机如何去发起内存回收的问题，但是虚拟机如何<br />
具体地进行内存回收动作仍然未涉及，因为内存回收如何进行是由虚拟机所采用的GC收集<br />
器决定的，而通常虚拟机中往往不止有一种GC收集器。 下面继续来看HotSpot中有哪些GC收<br />
集器。<br />
3.5 垃圾收集器<br />
如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。 Java<br />
虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、 不同版本的虚<br />
拟机所提供的垃圾收集器都可能会有很大差别，并且一般都会提供参数供用户根据自己的应<br />
用特点和要求组合出各个年代所使用的收集器。 这里讨论的收集器基于JDK 1.7 Update 14之<br />
后的HotSpot虚拟机（在这个版本中正式提供了商用的G1收集器，之前G1仍处于实验状<br />
态），这个虚拟机包含的所有收集器如图3-5所示。<br />
图 3-5 HotSpot虚拟机的垃圾收集器[1]<br />
图3-5展示了7种作用于不同分代的收集器，如果两个收集器之间存在连线，就说明它们<br />
可以搭配使用。 虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。 接下<br />
来笔者将逐一介绍这些收集器的特性、 基本原理和使用场景，并重点分析CMS和G1这两款<br />
相对复杂的收集器，了解它们的部分运作细节。<br />
在介绍这些收集器各自的特性之前，我们先来明确一个观点：虽然我们是在对各个收集<br />
器进行比较，但并非为了挑选出一个最好的收集器。 因为直到现在为止还没有最好的收集器<br />
出现，更加没有万能的收集器，所以我们选择的只是对具体应用最合适的收集器。 这点不需<br />
要多加解释就能证明：如果有一种放之四海皆准、 任何场景下都适用的完美收集器存在，那<br />
HotSpot虚拟机就没必要实现那么多不同的收集器了。<br />
3.5.1 Serial收集器<br />
Serial收集器是最基本、 发展历史最悠久的收集器，曾经（在JDK 1.3.1之前）是虚拟机<br />
新生代收集的唯一选择。 大家看名字就会知道，这个收集器是一个单线程的收集器，但它<br />
的&ldquo;单线程&rdquo;的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，<br />
更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。 &ldquo;Stop<br />
The World&rdquo;这个名字也许听起来很酷，但这项工作实际上是由虚拟机在后台自动发起和自动<br />
完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说都是难<br />
以接受的。 读者不妨试想一下，要是你的计算机每运行一个小时就会暂停响应5分钟，你会<br />
有什么样的心情？图3-6示意了Serial/Serial Old收集器的运行过程。<br />
图 3-6 Serial/Serial Old收集器运行示意图<br />
对于&ldquo;Stop The World&rdquo;带给用户的不良体验，虚拟机的设计者们表示完全理解，但也表<br />
示非常委屈：&ldquo;你妈妈在给你打扫房间的时候，肯定也会让你老老实实地在椅子上或者房间<br />
外待着，如果她一边打扫，你一边乱扔纸屑，这房间还能打扫完？&rdquo;这确实是一个合情合理<br />
的矛盾，虽然垃圾收集这项工作听起来和打扫房间属于一个性质的，但实际上肯定还要比打<br />
扫房间复杂得多啊！<br />
从JDK 1.3开始，一直到现在最新的JDK 1.7，HotSpot虚拟机开发团队为消除或者减少工<br />
作线程因内存回收而导致停顿的努力一直在进行着，从Serial收集器到Parallel收集器，再到<br />
Concurrent Mark Sweep（CMS）乃至GC收集器的最前沿成果Garbage First（G1）收集器，我<br />
们看到了一个个越来越优秀（也越来越复杂）的收集器的出现，用户线程的停顿时间在不断<br />
缩短，但是仍然没有办法完全消除（这里暂不包括RTSJ中的收集器）。 寻找更优秀的垃圾收<br />
集器的工作仍在继续！<br />
写到这里，笔者似乎已经把Serial收集器描述成一个&ldquo;老而无用、 食之无味弃之可惜&rdquo;的<br />
鸡肋了，但实际上到现在为止，它依然是虚拟机运行在Client模式下的默认新生代收集器。<br />
它也有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比），对于限定单个<br />
CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最<br />
高的单线程收集效率。 在用户的桌面应用场景中，分配给虚拟机管理的内存一般来说不会很<br />
大，收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存，桌面应用基本上不会再<br />
大了），停顿时间完全可以控制在几十毫秒最多一百多毫秒以内，只要不是频繁发生，这点<br />
停顿是可以接受的。 所以，Serial收集器对于运行在Client模式下的虚拟机来说是一个很好的<br />
选择。<br />
[1]图片来源：http://blogs.sun.com/jonthecollector/entry/our_collectors。<br />
3.5.2 ParNew收集器<br />
ParNew收集器其实就是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之<br />
外，其余行为包括Serial收集器可用的所有控制参数（例如：-XX：SurvivorRatio、 -XX：<br />
PretenureSizeThreshold、 -XX：HandlePromotionFailure等）、 收集算法、 Stop The World、 对<br />
象分配规则、 回收策略等都与Serial收集器完全一样，在实现上，这两种收集器也共用了相<br />
当多的代码。 ParNew收集器的工作过程如图3-7所示。<br />
图 3-7 ParNew/Serial Old收集器运行示意图<br />
ParNew收集器除了多线程收集之外，其他与Serial收集器相比并没有太多创新之处，但<br />
它却是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但<br />
很重要的原因是，除了Serial收集器外，目前只有它能与CMS收集器配合工作。 在JDK 1.5时<br />
期，HotSpot推出了一款在强交互应用中几乎可认为有划时代意义的垃圾收集器&mdash;&mdash;CMS收<br />
集器（Concurrent Mark Sweep，本节稍后将详细介绍这款收集器），这款收集器是HotSpot虚<br />
拟机中第一款真正意义上的并发（Concurrent）收集器，它第一次实现了让垃圾收集线程与<br />
用户线程（基本上）同时工作，用前面那个例子的话来说，就是做到了在你的妈妈打扫房间<br />
的时候你还能一边往地上扔纸屑。<br />
不幸的是，CMS作为老年代的收集器，却无法与JDK 1.4.0中已经存在的新生代收集器<br />
Parallel Scavenge配合工作[1]，所以在JDK 1.5中使用CMS来收集老年代的时候，新生代只能选<br />
择ParNew或者Serial收集器中的一个。 ParNew收集器也是使用-XX：+UseConcMarkSweepGC<br />
选项后的默认新生代收集器，也可以使用-XX：+UseParNewGC选项来强制指定它。<br />
ParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果，甚至由于存在<br />
线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保<br />
证可以超越Serial收集器。 当然，随着可以使用的CPU的数量的增加，它对于GC时系统资源<br />
的有效利用还是很有好处的。 它默认开启的收集线程数与CPU的数量相同，在CPU非常多<br />
（譬如32个，现在CPU动辄就4核加超线程，服务器超过32个逻辑CPU的情况越来越多了）的<br />
环境下，可以使用-XX：ParallelGCThreads参数来限制垃圾收集的线程数。<br />
注意 从ParNew收集器开始，后面还会接触到几款并发和并行的收集器。 在大家可能<br />
产生疑惑之前，有必要先解释两个名词：并发和并行。 这两个名词都是并发编程中的概念，<br />
在谈论垃圾收集器的上下文语境中，它们可以解释如下。<br />
●并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状<br />
态。<br />
●并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能<br />
会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个CPU上。<br />
[1]Parallel Scavenge收集器及后面提到的G1收集器都没有使用传统的GC收集器代码框架，而<br />
另外独立实现，其余几种收集器则共用了部分的框架代码，详细内容可参考：<br />
http://blogs.sun.com/jonthecollector/entry/our_collectors。<br />
3.5.3 Parallel Scavenge收集器<br />
Parallel Scavenge收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行<br />
的多线程收集器&hellip;&hellip;看上去和ParNew都一样，那它有什么特别之处呢？<br />
Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点<br />
是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到<br />
一个可控制的吞吐量（Throughput）。 所谓吞吐量就是CPU用于运行用户代码的时间与CPU总<br />
消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚<br />
拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。<br />
停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高<br />
吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不<br />
需要太多交互的任务。<br />
Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集<br />
停顿时间的-XX：MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX：GCTimeRatio参<br />
数。<br />
MaxGCPauseMillis参数允许的值是一个大于0的毫秒数，收集器将尽可能地保证内存回<br />
收花费的时间不超过设定值。 不过大家不要认为如果把这个参数的值设置得稍小一点就能使<br />
得系统的垃圾收集速度变得更快，GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取<br />
的：系统把新生代调小一些，收集300MB新生代肯定比收集500MB快吧，这也直接导致垃圾<br />
收集发生得更频繁一些，原来10秒收集一次、 每次停顿100毫秒，现在变成5秒收集一次、 每<br />
次停顿70毫秒。 停顿时间的确在下降，但吞吐量也降下来了。<br />
GCTimeRatio参数的值应当是一个大于0且小于100的整数，也就是垃圾收集时间占总时<br />
间的比率，相当于是吞吐量的倒数。 如果把此参数设置为19，那允许的最大GC时间就占总<br />
时间的5%（即1/（1+19）），默认值为99，就是允许最大1%（即1/（1+99））的垃圾收集<br />
时间。<br />
由于与吞吐量关系密切，Parallel Scavenge收集器也经常称为&ldquo;吞吐量优先&rdquo;收集器。 除上<br />
述两个参数之外，Parallel Scavenge收集器还有一个参数-XX：+UseAdaptiveSizePolicy值得关<br />
注。 这是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、<br />
Eden与Survivor区的比例（-XX：SurvivorRatio）、 晋升老年代对象年龄（-XX：<br />
PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信<br />
息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC<br />
自适应的调节策略（GC Ergonomics）[1]。 如果读者对于收集器运作原来不太了解，手工优化<br />
存在困难的时候，使用Parallel Scavenge收集器配合自适应调节策略，把内存管理的调优任务<br />
交给虚拟机去完成将是一个不错的选择。 只需要把基本的内存数据设置好（如-Xmx设置最大<br />
堆），然后使用MaxGCPauseMillis参数（更关注最大停顿时间）或GCTimeRatio（更关注吞<br />
吐量）参数给虚拟机设立一个优化目标，那具体细节参数的调节工作就由虚拟机完成了。 自<br />
适应调节策略也是Parallel Scavenge收集器与ParNew收集器的一个重要区别。<br />
[1]官方介绍：http://download.oracle.com/javase/1.5.0/docs/guide/vm/gc-ergonomics.html。<br />
3.5.4 Serial Old收集器<br />
Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用&ldquo;标记-整<br />
理&rdquo;算法。 这个收集器的主要意义也是在于给Client模式下的虚拟机使用。 如果在Server模式<br />
下，那么它主要还有两大用途：一种用途是在JDK 1.5以及之前的版本中与Parallel Scavenge<br />
收集器搭配使用[1]，另一种用途就是作为CMS收集器的后备预案，在并发收集发生Concurrent<br />
Mode Failure时使用。 这两点都将在后面的内容中详细讲解。 Serial Old收集器的工作过程如<br />
图3-8所示。<br />
图 3-8 Serial/Serial Old收集器运行示意图<br />
[1]需要说明一下，Parallel Scavenge收集器架构中本身有PS MarkSweep收集器来进行老年代<br />
收集，并非直接使用了Serial Old收集器，但是这个PS MarkSweep收集器与Serial Old的实现<br />
非常接近，所以在官方的许多资料中都是直接以Serial Old代替PS MarkSweep进行讲解，这<br />
里笔者也采用这种方式。<br />
3.5.5 Parallel Old收集器<br />
Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和&ldquo;标记-整理&rdquo;算法。<br />
这个收集器是在JDK 1.6中才开始提供的，在此之前，新生代的Parallel Scavenge收集器一直<br />
处于比较尴尬的状态。 原因是，如果新生代选择了Parallel Scavenge收集器，老年代除了<br />
Serial Old（PS MarkSweep）收集器外别无选择（还记得上面说过Parallel Scavenge收集器无<br />
法与CMS收集器配合工作吗？）。 由于老年代Serial Old收集器在服务端应用性能上的&ldquo;拖<br />
累&rdquo;，使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果，由于<br />
单线程的老年代收集中无法充分利用服务器多CPU的处理能力，在老年代很大而且硬件比较<br />
高级的环境中，这种组合的吞吐量甚至还不一定有ParNew加CMS的组合&ldquo;给力&rdquo;。<br />
直到Parallel Old收集器出现后，&ldquo;吞吐量优先&rdquo;收集器终于有了比较名副其实的应用组<br />
合，在注重吞吐量以及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old<br />
收集器。 Parallel Old收集器的工作过程如图3-9所示。<br />
图 3-9 Parallel Scavenge/Parallel Old收集器运行示意图<br />
3.5.6 CMS收集器<br />
CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集<br />
器。 目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重<br />
视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。 CMS收集器就非常<br />
符合这类应用的需求。<br />
从名字（包含&ldquo;Mark Sweep&rdquo;）上就可以看出，CMS收集器是基于&ldquo;标记&mdash;清除&rdquo;算法实现<br />
的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为4个步骤，包括：<br />
初始标记（CMS initial mark）<br />
并发标记（CMS concurrent mark）<br />
重新标记（CMS remark）<br />
并发清除（CMS concurrent sweep）<br />
其中，初始标记、 重新标记这两个步骤仍然需要&ldquo;Stop The World&rdquo;。 初始标记仅仅只是<br />
标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC RootsTracing<br />
的过程，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变<br />
动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远<br />
比并发标记的时间短。<br />
由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起<br />
工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。 通<br />
过图3-10可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间。<br />
图 3-10 Concurrent Mark Sweep收集器运行示意图<br />
CMS是一款优秀的收集器，它的主要优点在名字上已经体现出来了：并发收集、 低停<br />
顿，Sun公司的一些官方文档中也称之为并发低停顿收集器（Concurrent Low Pause<br />
Collector）。 但是CMS还远达不到完美的程度，它有以下3个明显的缺点：<br />
CMS收集器对CPU资源非常敏感。 其实，面向并发设计的程序都对CPU资源比较敏感。<br />
在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资<br />
源）而导致应用程序变慢，总吞吐量会降低。 CMS默认启动的回收线程数是（CPU数量<br />
+3）/4，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且<br />
随着CPU数量的增加而下降。 但是当CPU不足4个（譬如2个）时，CMS对用户程序的影响就<br />
可能变得很大，如果本来CPU负载就比较大，还分出一半的运算能力去执行收集器线程，就<br />
可能导致用户程序的执行速度忽然降低了50%，其实也让人无法接受。 为了应付这种情况，<br />
虚拟机提供了一种称为&ldquo;增量式并发收集器&rdquo;（Incremental Concurrent Mark Sweep/i-CMS）的<br />
CMS收集器变种，所做的事情和单CPU年代PC机操作系统使用抢占式来模拟多任务机制的思<br />
想一样，就是在并发标记、 清理的时候让GC线程、 用户线程交替运行，尽量减少GC线程的<br />
独占资源的时间，这样整个垃圾收集的过程会更长，但对用户程序的影响就会显得少一些，<br />
也就是速度下降没有那么明显。 实践证明，增量时的CMS收集器效果很一般，在目前版本<br />
中，i-CMS已经被声明为&ldquo;deprecated&rdquo;，即不再提倡用户使用。<br />
CMS收集器无法处理浮动垃圾（Floating Garbage），可能出现&ldquo;Concurrent Mode<br />
Failure&rdquo;失败而导致另一次Full GC的产生。 由于CMS并发清理阶段用户线程还在运行着，伴<br />
随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法<br />
在当次收集中处理掉它们，只好留待下一次GC时再清理掉。 这一部分垃圾就称为&ldquo;浮动垃<br />
圾&rdquo;。 也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间<br />
给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进<br />
行收集，需要预留一部分空间提供并发收集时的程序运作使用。 在JDK 1.5的默认设置<br />
下，CMS收集器当老年代使用了68%的空间后就会被激活，这是一个偏保守的设置，如果在<br />
应用中老年代增长不是太快，可以适当调高参数-XX：CMSInitiatingOccupancyFraction的值来<br />
提高触发百分比，以便降低内存回收次数从而获取更好的性能，在JDK 1.6中，CMS收集器<br />
的启动阈值已经提升至92%。 要是CMS运行期间预留的内存无法满足程序需要，就会出现一<br />
次&ldquo;Concurrent Mode Failure&rdquo;失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器来<br />
重新进行老年代的垃圾收集，这样停顿时间就很长了。 所以说参数-XX：CM<br />
SInitiatingOccupancyFraction设置得太高很容易导致大量&ldquo;Concurrent Mode Failure&rdquo;失败，性能<br />
反而降低。<br />
还有最后一个缺点，在本节开头说过，CMS是一款基于&ldquo;标记&mdash;清除&rdquo;算法实现的收集<br />
器，如果读者对前面这种算法介绍还有印象的话，就可能想到这意味着收集结束时会有大量<br />
空间碎片产生。 空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有<br />
很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次Full<br />
GC。 为了解决这个问题，CMS收集器提供了一个-XX：+UseCMSCompactAtFullCollection开<br />
关参数（默认就是开启的），用于在CMS收集器顶不住要进行FullGC时开启内存碎片的合并<br />
整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长。<br />
虚拟机设计者还提供了另外一个参数-XX：CMSFullGCsBeforeCompaction，这个参数是用于<br />
设置执行多少次不压缩的Full GC后，跟着来一次带压缩的（默认值为0，表示每次进入Full<br />
GC时都进行碎片整理）。<br />
3.5.7 G1收集器<br />
G1（Garbage-First）收集器是当今收集器技术发展的最前沿成果之一，早在JDK 1.7刚刚<br />
确立项目目标，Sun公司给出的JDK 1.7 RoadMap里面，它就被视为JDK 1.7中HotSpot虚拟机<br />
的一个重要进化特征。 从JDK 6u14中开始就有Early Access版本的G1收集器供开发人员实<br />
验、 试用，由此开始G1收集器的&ldquo;Experimental&rdquo;状态持续了数年时间，直至JDK 7u4，Sun公<br />
司才认为它达到足够成熟的商用程度，移除了&ldquo;Experimental&rdquo;的标识。<br />
G1是一款面向服务端应用的垃圾收集器。 HotSpot开发团队赋予它的使命是（在比较长<br />
期的）未来可以替换掉JDK 1.5中发布的CMS收集器。 与其他GC收集器相比，G1具备如下特<br />
点。<br />
并行与并发：G1能充分利用多CPU、 多核环境下的硬件优势，使用多个CPU（CPU或者<br />
CPU核心）来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的<br />
GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。<br />
分代收集：与其他收集器一样，分代概念在G1中依然得以保留。 虽然G1可以不需要其<br />
他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已<br />
经存活了一段时间、 熬过多次GC的旧对象以获取更好的收集效果。<br />
空间整合：与CMS的&ldquo;标记&mdash;清理&rdquo;算法不同，G1从整体来看是基于&ldquo;标记&mdash;整理&rdquo;算法实<br />
现的收集器，从局部（两个Region之间）上来看是基于&ldquo;复制&rdquo;算法实现的，但无论如何，这<br />
两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。 这种<br />
特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一<br />
次GC。<br />
可预测的停顿：这是G1相对于CMS的另一大优势，降低停顿时间是G1和CMS共同的关<br />
注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一<br />
个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实<br />
时Java（RTSJ）的垃圾收集器的特征了。<br />
在G1之前的其他收集器进行收集的范围都是整个新生代或者老年代，而G1不再是这<br />
样。 使用G1收集器时，Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分<br />
为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和<br />
老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。<br />
G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java<br />
堆中进行全区域的垃圾收集。 G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的<br />
空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时<br />
间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。 这种使用Region划分<br />
内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高<br />
的收集效率。<br />
G1把内存&ldquo;化整为零&rdquo;的思路，理解起来似乎很容易，但其中的实现细节却远远没有想象<br />
中那样简单，否则也不会从2004年Sun实验室发表第一篇G1的论文开始直到今天（将近10年<br />
时间）才开发出G1的商用版。 笔者以一个细节为例：把Java堆分为多个Region后，垃圾收集<br />
是否就真的能以Region为单位进行了？听起来顺理成章，再仔细想想就很容易发现问题所<br />
在：Region不可能是孤立的。 一个对象分配在某个Region中，它并非只能被本Region中的其<br />
他对象引用，而是可以与整个Java堆任意的对象发生引用关系。 那在做可达性判定确定对象<br />
是否存活的时候，岂不是还得扫描整个Java堆才能保证准确性？这个问题其实并非在G1中才<br />
有，只是在G1中更加突出而已。 在以前的分代收集中，新生代的规模一般都比老年代要小许<br />
多，新生代的收集也比老年代要频繁许多，那回收新生代中的对象时也面临相同的问题，如<br />
果回收新生代时也不得不同时扫描老年代的话，那么Minor GC的效率可能下降不少。<br />
在G1收集器中，Region之间的对象引用以及其他收集器中的新生代与老年代之间的对象<br />
引用，虚拟机都是使用Remembered Set来避免全堆扫描的。 G1中每个Region都有一个与之对<br />
应的Remembered Set，虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个<br />
Write Barrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region之中（在分代<br />
的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过<br />
CardTable把相关引用信息记录到被引用对象所属的Region的Remembered Set之中。 当进行内<br />
存回收时，在GC根节点的枚举范围中加入Remembered Set即可保证不对全堆扫描也不会有遗<br />
漏。<br />
如果不计算维护Remembered Set的操作，G1收集器的运作大致可划分为以下几个步骤：<br />
初始标记（Initial Marking）<br />
并发标记（Concurrent Marking）<br />
最终标记（Final Marking）<br />
筛选回收（Live Data Counting and Evacuation）<br />
对CMS收集器运作过程熟悉的读者，一定已经发现G1的前几个步骤的运作过程和CMS<br />
有很多相似之处。 初始标记阶段仅仅只是标记一下GC Roots能直接关联到的对象，并且修改<br />
TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的<br />
Region中创建新对象，这阶段需要停顿线程，但耗时很短。 并发标记阶段是从GC Root开始<br />
对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执<br />
行。 而最终标记阶段则是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动<br />
的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Remembered Set Logs里面，最<br />
终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线<br />
程，但是可并行执行。 最后在筛选回收阶段首先对各个Region的回收价值和成本进行排序，<br />
根据用户所期望的GC停顿时间来制定回收计划，从Sun公司透露出来的信息来看，这个阶段<br />
其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控<br />
制的，而且停顿用户线程将大幅提高收集效率。 通过图3-11可以比较清楚地看到G1收集器的<br />
运作步骤中并发和需要停顿的阶段。<br />
图 3-11 G1收集器运行示意图<br />
由于目前G1成熟版本的发布时间还很短，G1收集器几乎可以说还没有经过实际应用的<br />
考验，网络上关于G1收集器的性能测试也非常贫乏，到目前为止，笔者还没有搜索到有关的<br />
生产环境下的性能测试报告。 强调&ldquo;生产环境下的测试报告&rdquo;是因为对于垃圾收集器来说，仅<br />
仅通过简单的Java代码写个Microbenchmark程序来创建、 移除Java对象，再用-XX：<br />
+PrintGCDetails等参数来查看GC日志是很难做到准确衡量其性能的。 因此，关于G1收集器的<br />
性能部分，笔者引用了Sun实验室的论文《 Garbage-First Garbage Collection》 中的一段测试数<br />
据。<br />
Sun给出的Benchmark的执行硬件为Sun V880服务器（8&times;750MHz UltraSPARC III CPU、<br />
32G内存、 Solaris 10操作系统）。 执行软件有两个，分别为SPECjbb（模拟商业数据库应<br />
用，堆中存活对象约为165MB，结果反映吐量和最长事务处理时间）和telco（模拟电话应答<br />
服务应用，堆中存活对象约为100MB，结果反映系统能支持的最大吞吐量）。 为了便于对<br />
比，还收集了一组使用ParNew+CMS收集器的测试数据。 所有测试都配置为与CPU数量相同<br />
的8条GC线程。<br />
在反应停顿时间的软实时目标（Soft Real-Time Goal）测试中，横向是两个测试软件的<br />
时间片段配置，单位是毫秒，以（X/Y）的形式表示，代表在Y毫秒内最大允许GC时间为X<br />
毫秒（对于CMS收集器，无法直接指定这个目标，通过调整分代大小的方式大致模拟）。 纵<br />
向是两个软件在对应配置和不同的Java堆容量下的测试结果，V%、 avgV%和wV%分别代表<br />
的含义如下。<br />
V%：表示测试过程中，软实时目标失败的概率，软实时目标失败即某个时间片段中实<br />
际GC时间超过了允许的最大GC时间。<br />
avgV%：表示在所有实际GC时间超标的时间片段里，实际GC时间超过最大GC时间的平<br />
均百分比（实际GC时间减去允许最大GC时间，再除以总时间片段）。<br />
wV%：表示在测试结果最差的时间片段里，实际GC时间占用执行时间的百分比。<br />
测试结果见表3-1。<br />
从表3-1所示的结果可见，对于telco来说，软实时目标失败的概率控制在0.5%～0.7%之<br />
间，SPECjbb就要差一些，但也控制在2%～5%之间，概率随着（X/Y）的比值减小而增加。<br />
另一方面，失败时超出允许GC时间的比值随着总时间片段增加而变小（分母变大了），在<br />
（100/200）、 512MB的配置下，G1收集器出现了某些时间片段下100%时间在进行GC的最坏<br />
情况。 而相比之下，CMS收集器的测试结果就要差很多，3种Java堆容量下都出现了100%时<br />
间进行GC的情况。<br />
在吞吐量测试中，测试数据取3次SPECjbb和15次telco的平均结果如图3-12所示。 在<br />
SPECjbb的应用下，各种配置下的G1收集器表现出了一致的行为，吞吐量看起来只与允许最<br />
大GC时间成正比关系，而在telco的应用中，不同配置对吞吐量的影响则显得很微弱。 与<br />
CMS收集器的吞吐量对比可以看到，在SPECjbb测试中，在堆容量超过768MB时，CMS收集<br />
器有5%～10%的优势，而在telco测试中，CMS的优势则要小一些，只有3%～4%左右。<br />
图 3-12 吞吐量测试结果<br />
在更大规模的生产环境下，笔者引用一段在StackOverflow.com上看到的经验与读者分<br />
享：&ldquo;我在一个真实的、 较大规模的应用程序中使用过G1：大约分配有60～70GB内存，存活<br />
对象大约在20～50GB之间。 服务器运行Linux操作系统，JDK版本为6u22。 G1与PS/PS Old相<br />
比，最大的好处是停顿时间更加可控、 可预测，如果我在PS中设置一个很低的最大允许GC<br />
时间，譬如期望50毫秒内完成GC（-XX：MaxGCPauseMillis=50），但在65GB的Java堆下有<br />
可能得到的直接结果是一次长达30秒至2分钟的漫长的Stop-The-World过程；而G1与CMS相<br />
比，虽然它们都立足于低停顿时间，CMS仍然是我现在的选择，但是随着Oracle对G1的持续<br />
改进，我相信G1会是最终的胜利者。 如果你现在采用的收集器没有出现问题，那就没有任何<br />
理由现在去选择G1，如果你的应用追求低停顿，那G1现在已经可以作为一个可尝试的选<br />
择，如果你的应用追求吞吐量，那G1并不会为你带来什么特别的好处&rdquo;。<br />
3.5.8 理解GC日志<br />
阅读GC日志是处理Java虚拟机内存问题的基础技能，它只是一些人为确定的规则，没有<br />
太多技术含量。 在本书的第1版中没有专门讲解如何阅读分析GC日志，为此作者收到许多读<br />
者来信，反映对此感到困惑，因此专门增加本节内容来讲解如何理解GC日志。<br />
每一种收集器的日志形式都是由它们自身的实现所决定的，换而言之，每个收集器的日<br />
志格式都可以不一样。 但虚拟机设计者为了方便用户阅读，将各个收集器的日志都维持一定<br />
的共性，例如以下两段典型的GC日志：<br />
33.125：[GC[DefNew：3324K-＞152K（3712K），0.0025925 secs]3324K-＞152K（11904K），0.0031680 secs]<br />
1 0 0.6 6 7：[F u l l G C[T e n u r e d：0 K-＞2 1 0 K（1 0 2 4 0 K），0.0 1 4 9 1 4 2 s e c s]4603K-＞210K（19456K），[Perm：2999K-＞<br />
2999K（21248K）]，0.0150007 secs][Times：user=0.01 sys=0.00，real=0.02 secs]<br />
最前面的数字&ldquo;33.125：&rdquo;和&ldquo;100.667：&rdquo;代表了GC发生的时间，这个数字的含义是从Java<br />
虚拟机启动以来经过的秒数。<br />
GC日志开头的&ldquo;[GC&rdquo;和&ldquo;[Full GC&rdquo;说明了这次垃圾收集的停顿类型，而不是用来区分新<br />
生代GC还是老年代GC的。 如果有&ldquo;Full&rdquo;，说明这次GC是发生了Stop-The-World的，例如下面<br />
这段新生代收集器ParNew的日志也会出现&ldquo;[Full GC&rdquo;（这一般是因为出现了分配担保失败之<br />
类的问题，所以才导致STW）。 如果是调用System.gc（）方法所触发的收集，那么在这里将<br />
显示&ldquo;[Full GC（System）&rdquo;。<br />
[Full GC 283.736：[ParNew：261599K-＞261599K（261952K），0.0000288 secs]<br />
接下来的&ldquo;[DefNew&rdquo;、 &ldquo;[Tenured&rdquo;、 &ldquo;[Perm&rdquo;表示GC发生的区域，这里显示的区域名称与<br />
使用的GC收集器是密切相关的，例如上面样例所使用的Serial收集器中的新生代名为&ldquo;Default<br />
New Generation&rdquo;，所以显示的是&ldquo;[DefNew&rdquo;。 如果是ParNew收集器，新生代名称就会变<br />
为&ldquo;[ParNew&rdquo;，意为&ldquo;Parallel New Generation&rdquo;。 如果采用Parallel Scavenge收集器，那它配套<br />
的新生代称为&ldquo;PSYoungGen&rdquo;，老年代和永久代同理，名称也是由收集器决定的。<br />
后面方括号内部的&ldquo;3324K-＞152K（3712K）&rdquo;含义是&ldquo;GC前该内存区域已使用容量-＞<br />
GC后该内存区域已使用容量（该内存区域总容量）&rdquo;。 而在方括号之外的&ldquo;3324K-＞<br />
152K（11904K）&rdquo;表示&ldquo;GC前Java堆已使用容量-＞GC后Java堆已使用容量（Java堆总容<br />
量）&rdquo;。<br />
再往后，&ldquo;0.0025925 secs&rdquo;表示该内存区域GC所占用的时间，单位是秒。 有的收集器会<br />
给出更具体的时间数据，如&ldquo;[Times：user=0.01 sys=0.00，real=0.02 secs]&rdquo;，这里面的user、<br />
sys和real与Linux的time命令所输出的时间含义一致，分别代表用户态消耗的CPU时间、 内核<br />
态消耗的CPU事件和操作从开始到结束所经过的墙钟时间（Wall Clock Time）。 CPU时间与<br />
墙钟时间的区别是，墙钟时间包括各种非运算的等待耗时，例如等待磁盘I/O、 等待线程阻<br />
塞，而CPU时间不包括这些耗时，但当系统有多CPU或者多核的话，多线程操作会叠加这些<br />
CPU时间，所以读者看到user或sys时间超过real时间是完全正常的。<br />
3.5.9 垃圾收集器参数总结<br />
JDK 1.7中的各种垃圾收集器到此已全部介绍完毕，在描述过程中提到了很多虚拟机非<br />
稳定的运行参数，在表3-2中整理了这些参数供读者实践时参考。</p>

<p>3.6 内存分配与回收策略<br />
Java技术体系中所提倡的自动内存管理最终可以归结为自动化地解决了两个问题：给对<br />
象分配内存以及回收分配给对象的内存。 关于回收内存这一点，我们已经使用了大量篇幅去<br />
介绍虚拟机中的垃圾收集器体系以及运作原理，现在我们再一起来探讨一下给对象分配内存<br />
的那点事儿。<br />
对象的内存分配，往大方向讲，就是在堆上分配（但也可能经过JIT编译后被拆散为标<br />
量类型并间接地栈上分配[1]），对象主要分配在新生代的Eden区上，如果启动了本地线程分<br />
配缓冲，将按线程优先在TLAB上分配。 少数情况下也可能会直接分配在老年代中，分配的<br />
规则并不是百分之百固定的，其细节取决于当前使用的是哪一种垃圾收集器组合，还有虚拟<br />
机中与内存相关的参数的设置。<br />
接下来我们将会讲解几条最普遍的内存分配规则，并通过代码去验证这些规则。 本节下<br />
面的代码在测试时使用Client模式虚拟机运行，没有手工指定收集器组合，换句话说，验证<br />
的是在使用Serial/Serial Old收集器下（ParNew/Serial Old收集器组合的规则也基本一致）的<br />
内存分配和回收的策略。 读者不妨根据自己项目中使用的收集器写一些程序去验证一下使用<br />
其他几种收集器的内存分配策略。<br />
3.6.1 对象优先在Eden分配<br />
大多数情况下，对象在新生代Eden区中分配。 当Eden区没有足够空间进行分配时，虚拟<br />
机将发起一次Minor GC。<br />
虚拟机提供了-XX：+PrintGCDetails这个收集器日志参数，告诉虚拟机在发生垃圾收集<br />
行为时打印内存回收日志，并且在进程退出的时候输出当前的内存各区域分配情况。 在实际<br />
应用中，内存回收日志一般是打印到文件后通过日志工具进行分析，不过本实验的日志并不<br />
多，直接阅读就能看得很清楚。<br />
代码清单3-5的testAllocation（）方法中，尝试分配3个2MB大小和1个4MB大小的对象，<br />
在运行时通过-Xms20M、 -Xmx20M、 -Xmn10M这3个参数限制了Java堆大小为20MB，不可扩<br />
展，其中10MB分配给新生代，剩下的10MB分配给老年代。 -XX：SurvivorRatio=8决定了新<br />
生代中Eden区与一个Survivor区的空间比例是8:1，从输出的结果也可以清晰地看到&ldquo;eden<br />
space 8192K、 from space 1024K、 to space 1024K&rdquo;的信息，新生代总可用空间为<br />
9216KB（Eden区+1个Survivor区的总容量）。<br />
执行testAllocation（）中分配allocation4对象的语句时会发生一次Minor GC，这次GC的<br />
结果是新生代6651KB变为148KB，而总内存占用量则几乎没有减少（因为allocation1、<br />
allocation2、 allocation3三个对象都是存活的，虚拟机几乎没有找到可回收的对象）。 这次<br />
GC发生的原因是给allocation4分配内存的时候，发现Eden已经被占用了6MB，剩余空间已不<br />
足以分配allocation4所需的4MB内存，因此发生Minor GC。 GC期间虚拟机又发现已有的3个<br />
2MB大小的对象全部无法放入Survivor空间（Survivor空间只有1MB大小），所以只好通过分<br />
配担保机制提前转移到老年代去。<br />
这次GC结束后，4MB的allocation4对象顺利分配在Eden中，因此程序执行完的结果是<br />
Eden占用4MB（被allocation4占用），Survivor空闲，老年代被占用6MB（被allocation1、<br />
allocation2、 allocation3占用）。 通过GC日志可以证实这一点。<br />
注意 作者多次提到的Minor GC和Full GC有什么不一样吗？<br />
新生代GC（Minor GC）：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝<br />
生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。<br />
老年代GC（Major GC/Full GC）：指发生在老年代的GC，出现了Major GC，经常会伴<br />
随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行<br />
Major GC的策略选择过程）。 Major GC的速度一般会比Minor GC慢10倍以上。<br />
代码清单3-5 新生代Minor GC<br />
private static final int_1MB=1024*1024；<br />
/**<br />
*VM参数：-verbose：gc-Xms20M-Xmx20M-Xmn10M-XX：+PrintGCDetails<br />
-XX：SurvivorRatio=8<br />
*/<br />
public static void testAllocation（）{<br />
byte[]allocation1，allocation2，allocation3，allocation4；<br />
allocation1=new byte[2*_1MB]；<br />
allocation2=new byte[2*_1MB]；<br />
allocation3=new byte[2*_1MB]；<br />
allocation4=new byte[4*_1MB]；//出现一次Minor GC<br />
} 运<br />
行结果：<br />
[GC[DefNew：6651K-＞148K（9216K），0.0070106 secs]6651K-＞6292K（19456K），<br />
0.0070426 secs][Times：user=0.00 sys=0.00，real=0.00 secs]<br />
Heap<br />
def new generation total 9216K,used 4326K[0x029d0000，0x033d0000，0x033d0000）<br />
eden space 8192K，51%used[0x029d0000，0x02de4828，0x031d0000）<br />
from space 1024K，14%used[0x032d0000，0x032f5370，0x033d0000）<br />
to space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）<br />
tenured generation total 10240K,used 6144K[0x033d0000，0x03dd0000，0x03dd0000）<br />
the space 10240K，60%used[0x033d0000，0x039d0030，0x039d0200，0x03dd0000）<br />
compacting perm gen total 12288K,used 2114K[0x03dd0000，0x049d0000，0x07dd0000）<br />
the space 12288K，17%used[0x03dd0000，0x03fe0998，0x03fe0a00，0x049d0000）<br />
No shared spaces configured.<br />
[1]JIT即时编译器相关优化可参见第11章。<br />
3.6.2 大对象直接进入老年代<br />
所谓的大对象是指，需要大量连续内存空间的Java对象，最典型的大对象就是那种很长<br />
的字符串以及数组（笔者列出的例子中的byte[]数组就是典型的大对象）。 大对象对虚拟机<br />
的内存分配来说就是一个坏消息（替Java虚拟机抱怨一句，比遇到一个大对象更加坏的消息<br />
就是遇到一群&ldquo;朝生夕灭&rdquo;的&ldquo;短命大对象&rdquo;，写程序的时候应当避免），经常出现大对象容易<br />
导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来&ldquo;安置&rdquo;它们。<br />
虚拟机提供了一个-XX：PretenureSizeThreshold参数，令大于这个设置值的对象直接在老<br />
年代分配。 这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存复制（复习<br />
一下：新生代采用复制算法收集内存）。<br />
执行代码清单3-6中的testPretenureSizeThreshold（）方法后，我们看到Eden空间几乎没有<br />
被使用，而老年代的10MB空间被使用了40%，也就是4MB的allocation对象直接就分配在老<br />
年代中，这是因为PretenureSizeThreshold被设置为3MB（就是3145728，这个参数不能像-Xmx<br />
之类的参数一样直接写3MB），因此超过3MB的对象都会直接在老年代进行分配。 注意<br />
PretenureSizeThreshold参数只对Serial和ParNew两款收集器有效，Parallel Scavenge收集器不<br />
认识这个参数，Parallel Scavenge收集器一般并不需要设置。 如果遇到必须使用此参数的场<br />
合，可以考虑ParNew加CMS的收集器组合。<br />
代码清单3-6 大对象直接进入老年代<br />
private static final int_1MB=1024*1024；<br />
/**<br />
*VM参数：-verbose：gc-Xms20M-Xmx20M-Xmn10M-XX：+PrintGCDetails-XX：SurvivorRatio=8<br />
*-XX：PretenureSizeThreshold=3145728<br />
*/<br />
public static void testPretenureSizeThreshold（）{<br />
byte[]allocation；<br />
allocation=new byte[4*_1MB]；//直接分配在老年代中<br />
} 运<br />
行结果：<br />
Heap<br />
def new generation total 9216K,used 671K[0x029d0000，0x033d0000，0x033d0000）<br />
eden space 8192K，8%used[0x029d0000，0x02a77e98，0x031d0000）<br />
from space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）<br />
to space 1024K，0%used[0x032d0000，0x032d0000，0x033d0000）<br />
tenured generation total 10240K,used 4096K[0x033d0000，0x03dd0000，0x03dd0000）<br />
the space 10240K，40%used[0x033d0000，0x037d0010，0x037d0200，0x03dd0000）<br />
compacting perm gen total 12288K,used 2107K[0x03dd0000，0x049d0000，0x07dd0000）<br />
the space 12288K，17%used[0x03dd0000，0x03fdefd0，0x03fdf000，0x049d0000）<br />
No shared spaces configured.<br />
3.6.3 长期存活的对象将进入老年代<br />
既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象<br />
应放在新生代，哪些对象应放在老年代中。 为了做到这点，虚拟机给每个对象定义了一个对<br />
象年龄（Age）计数器。 如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被<br />
Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。 对象在Survivor区中<br />
每&ldquo;熬过&rdquo;一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就<br />
将会被晋升到老年代中。 对象晋升老年代的年龄阈值，可以通过参数-XX：<br />
MaxTenuringThreshold设置。<br />
读者可以试试分别以-XX：MaxTenuringThreshold=1和-XX：MaxTenuringThreshold=15两<br />
种设置来执行代码清单3-7中的testTenuringThreshold（）方法，此方法中的allocation1对象需<br />
要256KB内存，Survivor空间可以容纳。 当MaxTenuringThreshold=1时，allocation1对象在第二<br />
次GC发生时进入老年代，新生代已使用的内存GC后非常干净地变成0KB。 而<br />
MaxTenuringThreshold=15时，第二次GC发生后，allocation1对象则还留在新生代Survivor空<br />
间，这时新生代仍然有404KB被占用。<br />
代码清单3-7 长期存活的对象进入老年代<br />
private static final int_1MB=1024*1024；<br />
/**<br />
*VM参数：-verbose：gc-Xms20M-Xmx20M-Xmn10M-XX：+PrintGCDetails-XX：SurvivorRatio=8-XX：MaxTenuringThreshold=1<br />
*-XX：+PrintTenuringDistribution<br />
*/<br />
@SuppressWarnings（&quot;unused&quot;）<br />
public static void testTenuringThreshold（）{<br />
byte[]allocation1，allocation2，allocation3；<br />
allocation1=new byte[_1MB/4]；<br />
//什么时候进入老年代取决于XX：MaxTenuringThreshold设置<br />
allocation2=new byte[4*_1MB]；<br />
allocation3=new byte[4*_1MB]；<br />
allocation3=null；<br />
allocation3=new byte[4*_1MB]；<br />
} 以<br />
MaxTenuringThreshold=1参数来运行的结果：<br />
[GC[DefNew<br />
Desired Survivor size 524288 bytes,new threshold 1（max 1）<br />
-age 1：414664 bytes，414664 total<br />
：4859K-＞404K（9216K），0.0065012 secs]4859K-＞4500K（19456K），0.0065283 secs][Times：user=0.02 sys=0.00，real=0.02 secs]<br />
[GC[DefNew<br />
Desired Survivor size 524288 bytes,new threshold 1（max 1）<br />
：4500K-＞0K（9216K），0.0009253 secs]8596K-＞4500K（19456K），0.0009458 secs][Times：user=0.00 sys=0.00，real=0.00 secs]<br />
Heap<br />
def new generation total 9216K,used 4178K[0x029d0000，0x033d0000，0x033d0000）<br />
eden space 8192K，51%used[0x029d0000，0x02de4828，0x031d0000）<br />
from space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）<br />
to space 1024K，0%used[0x032d0000，0x032d0000，0x033d0000）<br />
tenured generation total 10240K,used 4500K[0x033d0000，0x03dd0000，0x03dd0000）<br />
the space 10240K，43%used[0x033d0000，0x03835348，0x03835400，0x03dd0000）<br />
compacting perm gen total 12288K,used 2114K[0x03dd0000，0x049d0000，0x07dd0000）<br />
the space 12288K，17%used[0x03dd0000，0x03fe0998，0x03fe0a00，0x049d0000）<br />
No shared spaces configured.<br />
以MaxTenuringThreshold=15参数来运行的结果：<br />
[GC[DefNew<br />
Desired Survivor size 524288 bytes,new threshold 15（max 15）<br />
-age 1：414664 bytes，414664 total<br />
：4859K-＞404K（9216K），0.0049637 secs]4859K-＞4500K（19456K），0.0049932 secs][Times：user=0.00 sys=0.00，real=0.00 secs]<br />
[GC[DefNew<br />
Desired Survivor size 524288 bytes,new threshold 15（max 15）<br />
-age 2：414520 bytes，414520 total<br />
：4500K-＞404K（9216K），0.0008091 secs]8596K-＞4500K（19456K），0.0008305 secs][Times：user=0.00 sys=0.00，real=0.00 secs]<br />
Heap<br />
def new generation total 9216K,used 4582K[0x029d0000，0x033d0000，0x033d0000）<br />
eden space 8192K，51%used[0x029d0000，0x02de4828，0x031d0000）<br />
from space 1024K，39%used[0x031d0000，0x03235338，0x032d0000）<br />
to space 1024K，0%used[0x032d0000，0x032d0000，0x033d0000）<br />
tenured generation total 10240K,used 4096K[0x033d0000，0x03dd0000，0x03dd0000）<br />
the space 10240K，40%used[0x033d0000，0x037d0010，0x037d0200，0x03dd0000）<br />
compacting perm gen total 12288K,used 2114K[0x03dd0000，0x049d0000，0x07dd0000）<br />
the space 12288K，17%used[0x03dd0000，0x03fe0998，0x03fe0a00，0x049d0000）<br />
No shared spaces configured.<br />
3.6.4 动态对象年龄判定<br />
为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到<br />
了MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总<br />
和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等<br />
到MaxTenuringThreshold中要求的年龄。<br />
执行代码清单3-8中的testTenuringThreshold2（）方法，并设置-XX：<br />
MaxTenuringThreshold=15，会发现运行结果中Survivor的空间占用仍然为0%，而老年代比预<br />
期增加了6%，也就是说，allocation1、 allocation2对象都直接进入了老年代，而没有等到15<br />
岁的临界年龄。 因为这两个对象加起来已经到达了512KB，并且它们是同年的，满足同年对<br />
象达到Survivor空间的一半规则。 我们只要注释掉其中一个对象new操作，就会发现另外一个<br />
就不会晋升到老年代中去了。<br />
代码清单3-8 动态对象年龄判定<br />
private static final int_1MB=1024*1024；<br />
/**<br />
*VM参数：-verbose：gc-Xms20M-Xmx20M-Xmn10M-XX：+PrintGCDetails-XX：SurvivorRatio=8-XX：MaxTenuringThreshold=15<br />
*-XX：+PrintTenuringDistribution<br />
*/<br />
@SuppressWarnings（&quot;unused&quot;）<br />
public static void testTenuringThreshold2（）{<br />
byte[]allocation1，allocation2，allocation3，allocation4；<br />
allocation1=new byte[_1MB/4]；<br />
//allocation1+allocation2大于survivo空间一半<br />
allocation2=new byte[_1MB/4]；<br />
allocation3=new byte[4*_1MB]；<br />
allocation4=new byte[4*_1MB]；<br />
allocation4=null；<br />
allocation4=new byte[4*_1MB]；<br />
} 运<br />
行结果：<br />
[GC[DefNew<br />
Desired Survivor size 524288 bytes,new threshold 1（max 15）<br />
-age 1：676824 bytes，676824 total<br />
：5115K-＞660K（9216K），0.0050136 secs]5115K-＞4756K（19456K），0.0050443 secs][Times：user=0.00 sys=0.01，real=0.01 secs]<br />
[GC[DefNew<br />
Desired Survivor size 524288 bytes,new threshold 15（max 15）<br />
：4756K-＞0K（9216K），0.0010571 secs]8852K-＞4756K（19456K），0.0011009 secs][Times：user=0.00 sys=0.00，real=0.00 secs]<br />
Heap<br />
def new generation total 9216K,used 4178K[0x029d0000，0x033d0000，0x033d0000）<br />
eden space 8192K，51%used[0x029d0000，0x02de4828，0x031d0000）<br />
from space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）<br />
to space 1024K，0%used[0x032d0000，0x032d0000，0x033d0000）<br />
tenured generation total 10240K,used 4756K[0x033d0000，0x03dd0000，0x03dd0000）<br />
the space 10240K，46%used[0x033d0000，0x038753e8，0x03875400，0x03dd0000）<br />
compacting perm gen total 12288K,used 2114K[0x03dd0000，0x049d0000，0x07dd0000）<br />
the space 12288K，17%used[0x03dd0000，0x03fe09a0，0x03fe0a00，0x049d0000）<br />
No shared spaces configured.<br />
3.6.5 空间分配担保<br />
在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有<br />
对象总空间，如果这个条件成立，那么Minor GC可以确保是安全的。 如果不成立，则虚拟机<br />
会查看HandlePromotionFailure设置值是否允许担保失败。 如果允许，那么会继续检查老年代<br />
最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行<br />
一次Minor GC，尽管这次Minor GC是有风险的；如果小于，或者HandlePromotionFailure设置<br />
不允许冒险，那这时也要改为进行一次Full GC。<br />
下面解释一下&ldquo;冒险&rdquo;是冒了什么风险，前面提到过，新生代使用复制收集算法，但为了<br />
内存利用率，只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在Minor<br />
GC后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要<br />
老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代。 与生活中的贷款担保类<br />
似，老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，一共有多<br />
少对象会活下来在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋<br />
升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进<br />
行Full GC来让老年代腾出更多空间。<br />
取平均值进行比较其实仍然是一种动态概率的手段，也就是说，如果某次Minor GC存活<br />
后的对象突增，远远高于平均值的话，依然会导致担保失败（Handle Promotion Failure）。<br />
如果出现了HandlePromotionFailure失败，那就只好在失败后重新发起一次Full GC。 虽然担保<br />
失败时绕的圈子是最大的，但大部分情况下都还是会将HandlePromotionFailure开关打开，避<br />
免Full GC过于频繁，参见代码清单3-9，请读者在JDK 6 Update 24之前的版本中运行测试。<br />
代码清单3-9 空间分配担保<br />
private static final int_1MB=1024*1024；<br />
/**<br />
*VM参数：-Xms20M-Xmx20M-Xmn10M-XX：+PrintGCDetails-XX：SurvivorRatio=8-XX：-HandlePromotionFailure<br />
*/<br />
@SuppressWarnings（&quot;unused&quot;）<br />
public static void testHandlePromotion（）{<br />
byte[]allocation1，allocation2，allocation3，allocation4，allocation5，allocation6，allocation7；<br />
allocation1=new byte[2*_1MB]；<br />
allocation2=new byte[2*_1MB]；<br />
allocation3=new byte[2*_1MB]；<br />
allocation1=null；<br />
allocation4=new byte[2*_1MB]；<br />
allocation5=new byte[2*_1MB]；<br />
allocation6=new byte[2*_1MB]；<br />
allocation4=null；<br />
allocation5=null；<br />
allocation6=null；<br />
allocation7=new byte[2*_1MB]；<br />
} 以<br />
HandlePromotionFailure=false参数来运行的结果：<br />
[GC[DefNew：6651K-＞148K（9216K），0.0078936 secs]6651K-＞4244K（19456K），0.0079192 secs][Times：user=0.00 sys=0.02，real=0.02 secs]<br />
[G C[D e f N e w：6 3 7 8 K-＞6 3 7 8 K（9 2 1 6 K），0.0 0 0 0 2 0 6 s e c s][T e n u r e d：4096K-＞4244K（10240K），0.0042901 secs]10474K-＞<br />
4244K（19456K），[Perm：2104K-＞2104K（12288K）]，0.0043613 secs][Times：user=0.00 sys=0.00，real=0.00 secs]<br />
以HandlePromotionFailure=true参数来运行的结果：<br />
[GC[DefNew：6651K-＞148K（9216K），0.0054913 secs]6651K-＞4244K（19456K），0.0055327 secs][Times：user=0.00 sys=0.00，real=0.00 secs]<br />
[GC[DefNew：6378K-＞148K（9216K），0.0006584 secs]10474K-＞4244K（19456K），0.0006857 secs][Times：user=0.00 sys=0.00，real=0.00 secs]<br />
在JDK 6 Update 24之后，这个测试结果会有差异，HandlePromotionFailure参数不会再影<br />
响到虚拟机的空间分配担保策略，观察OpenJDK中的源码变化（见代码清单3-10），虽然源<br />
码中还定义了HandlePromotionFailure参数，但是在代码中已经不会再使用它。 JDK 6 Update<br />
24之后的规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小就<br />
会进行Minor GC，否则将进行Full GC。<br />
代码清单3-10 HotSpot中空间分配检查的代码片段<br />
bool TenuredGeneration：promotion_attempt_is_safe（size_t<br />
max_promotion_in_bytes）const{<br />
//老年代最大可用的连续空间<br />
size_t available=max_contiguous_available（）；<br />
//每次晋升到老年代的平均大小<br />
size_t av_promo=（size_t）gc_stats（）-＞avg_promoted（）-＞padded_average（）；<br />
//老年代可用空间是否大于平均晋升大小，或者老年代可用空间是否大于当此GC时新生代所有对象容量<br />
bool res=（available＞=av_promo）||（available＞=<br />
max_promotion_in_bytes）；<br />
return res；<br />
}<br />
3.7 本章小结<br />
本章介绍了垃圾收集的算法、 几款JDK 1.7中提供的垃圾收集器特点以及运作原理。 通<br />
过代码实例验证了Java虚拟机中自动内存分配及回收的主要规则。<br />
内存回收与垃圾收集器在很多时候都是影响系统性能、 并发能力的主要因素之一，虚拟<br />
机之所以提供多种不同的收集器以及提供大量的调节参数，是因为只有根据实际应用需求、<br />
实现方式选择最优的收集方式才能获取最高的性能。 没有固定收集器、 参数组合，也没有最<br />
优的调优方法，虚拟机也就没有什么必然的内存回收行为。 因此，学习虚拟机内存知识，如<br />
果要到实践调优阶段，那么必须了解每个具体收集器的行为、 优势和劣势、 调节参数。 在接<br />
下来的两章中，作者将会介绍内存分析的工具和调优的一些具体案例。</p>

<h2><br />
第4章 虚拟机性能监控与故障处理工具</h2>

<p><br />
Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的&ldquo;高墙&rdquo;，墙外面的人想<br />
进去，墙里面的人却想出来。<br />
4.1 概述<br />
经过前面两章对于虚拟机内存分配与回收技术各方面的介绍，相信读者已经建立了一套<br />
比较完整的理论基础。 理论总是作为指导实践的工具，能把这些知识应用到实际工作中才是<br />
我们的最终目的。 接下来的两章，我们将从实践的角度去了解虚拟机内存管理的世界。<br />
给一个系统定位问题的时候，知识、 经验是关键基础，数据是依据，工具是运用知识处<br />
理数据的手段。 这里说的数据包括：运行日志、 异常堆栈、 GC日志、 线程快照<br />
（threaddump/javacore文件）、 堆转储快照（heapdump/hprof文件）等。 经常使用适当的虚拟<br />
机监控和分析的工具可以加快我们分析数据、 定位解决问题的速度，但在学习工具前，也应<br />
当意识到工具永远都是知识技能的一层包装，没有什么工具是&ldquo;秘密武器&rdquo;，不可能学会了就<br />
能包治百病。<br />
4.2 JDK的命令行工具<br />
Java开发人员肯定都知道JDK的bin目录中有&ldquo;java.exe&rdquo;、 &ldquo;javac.exe&rdquo;这两个命令行工具，<br />
但并非所有程序员都了解过JDK的bin目录之中其他命令行程序的作用。 每逢JDK更新版本之<br />
时，bin目录下命令行工具的数量和功能总会不知不觉地增加和增强。 bin目录的内容如图4-1<br />
所示。<br />
在本章中，笔者将介绍这些工具的其中一部分，主要包括用于监视虚拟机和故障处理的<br />
工具。 这些故障处理工具被Sun公司作为&ldquo;礼物&rdquo;附赠给JDK的使用者，并在软件的使用说明中<br />
把它们声明为&ldquo;没有技术支持并且是实验性质的&rdquo;（unsupported and experimental）[1]的产品，但<br />
事实上，这些工具都非常稳定而且功能强大，能在处理应用程序性能问题、 定位故障时发挥<br />
很大的作用。<br />
图 4-1 Sun JDK中的工具目录<br />
说起JDK的工具，比较细心的读者，可能会注意到这些工具的程序体积都异常小巧。 假<br />
如以前没注意到，现在不妨再看看图4-1中的最后一列&ldquo;大小&rdquo;，几乎所有工具的体积基本上<br />
都稳定在27KB左右。 并非JDK开发团队刻意把它们制作得如此精炼来炫耀编程水平，而是因<br />
为这些命令行工具大多数是jdk/lib/tools.jar类库的一层薄包装而已，它们主要的功能代码是<br />
在tools类库中实现的。 读者把图4-1和图4-2两张图片对比一下就可以看得很清楚。<br />
假如读者使用的是Linux版本的JDK，还会发现这些工具中很多甚至就是由Shell脚本直接<br />
写成的，可以用vim直接打开它们。<br />
JDK开发团队选择采用Java代码来实现这些监控工具是有特别用意的：当应用程序部署<br />
到生产环境后，无论是直接接触物理服务器还是远程Telnet到服务器上都可能会受到限制。<br />
借助tools.jar类库里面的接口，我们可以直接在应用程序中实现功能强大的监控分析功能[2]。<br />
图 4-2 tools.jar包的内部状况<br />
需要特别说明的是，本章介绍的工具全部基于Windows平台下的JDK 1.6 Update 21，如<br />
果JDK版本、 操作系统不同，工具所支持的功能可能会有较大差别。 大部分工具在JDK 1.5中<br />
就已经提供，但为了避免运行环境带来的差异和兼容性问题，建议读者使用JDK 1.6来验证<br />
本章介绍的内容，因为JDK 1.6的工具可以正常兼容运行于JDK 1.5的虚拟机之上的程序，反<br />
之则不一定。 表4-1中说明了JDK主要命令行监控工具的用途。<br />
注意 如果读者在工作中需要监控运行于JDK 1.5的虚拟机之上的程序，在程序启动时<br />
请添加参数&ldquo;-Dcom.sun.management.jmxremote&rdquo;开启JMX管理功能，否则由于部分工具都是基<br />
于JMX（包括4.3节介绍的可视化工具），它们都将会无法使用，如果被监控程序运行于JDK<br />
1.6的虚拟机之上，那JMX管理默认是开启的，虚拟机启动时无须再添加任何参数。<br />
4.2.1 jps：虚拟机进程状况工具<br />
JDK的很多小工具的名字都参考了UNIX命令的命名方式，jps（JVM Process Status<br />
Tool）是其中的典型。 除了名字像UNIX的ps命令之外，它的功能也和ps命令类似：可以列出<br />
正在运行的虚拟机进程，并显示虚拟机执行主类（Main Class,main（）函数所在的类）名称<br />
以及这些进程的本地虚拟机唯一ID（Local Virtual Machine Identifier,LVMID）。 虽然功能比较<br />
单一，但它是使用频率最高的JDK命令行工具，因为其他的JDK工具大多需要输入它查询到<br />
的LVMID来确定要监控的是哪一个虚拟机进程。 对于本地虚拟机进程来说，LVMID与操作系<br />
统的进程ID（Process Identifier,PID）是一致的，使用Windows的任务管理器或者UNIX的ps命<br />
令也可以查询到虚拟机进程的LVMID，但如果同时启动了多个虚拟机进程，无法根据进程名<br />
称定位时，那就只能依赖jps命令显示主类的功能才能区分了。<br />
jsp命令格式：<br />
jps[options][hostid]<br />
jps执行样例：<br />
D：\Develop\Java\jdk1.6.0_21\bin＞jps-l<br />
2388 D：\Develop\glassfish\bin\..\modules\admin-cli.jar<br />
2764 com.sun.enterprise.glassfish.bootstrap.ASMain<br />
3788 sun.tools.jps.Jps<br />
jps可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态，hostid为RMI注册表中<br />
注册的主机名。 jps的其他常用选项见表4-2。<br />
[1]http://download.oracle.com/javase/6/docs/technotes/tools/index.html。<br />
[2]tools.jar中的类库不属于Java的标准API，如果引入这个类库，就意味着用户的程序只能运<br />
行于Sun Hotspot（或一些从Sun公司购买了JDK的源码License的虚拟机，如IBM J9、 BEA<br />
JRockit）上面，或者在部署程序时需要一起部署tools.jar。<br />
4.2.2 jstat：虚拟机统计信息监视工具<br />
jstat（JVM Statistics Monitoring Tool）是用于监视虚拟机各种运行状态信息的命令行工<br />
具。 它可以显示本地或者远程[1]虚拟机进程中的类装载、 内存、 垃圾收集、 JIT编译等运行数<br />
据，在没有GUI图形界面，只提供了纯文本控制台环境的服务器上，它将是运行期定位虚拟<br />
机性能问题的首选工具。<br />
jstat命令格式为：<br />
jstat[option vmid[interval[s|ms][count]]]<br />
对于命令格式中的VMID与LVMID需要特别说明一下：如果是本地虚拟机进程，VMID与<br />
LVMID是一致的，如果是远程虚拟机进程，那VMID的格式应当是：<br />
[protocol：][//]lvmid[@hostname[：port]/servername]<br />
参数interval和count代表查询间隔和次数，如果省略这两个参数，说明只查询一次。 假设<br />
需要每250毫秒查询一次进程2764垃圾收集状况，一共查询20次，那命令应当是：<br />
jstat-gc 2764 250 20<br />
选项option代表着用户希望查询的虚拟机信息，主要分为3类：类装载、 垃圾收集、 运行<br />
期编译状况，具体选项及作用请参考表4-3中的描述。<br />
jstat监视选项众多，囿于版面原因无法逐一演示，这里仅举监视一台刚刚启动的<br />
GlassFish v3服务器的内存状况的例子来演示如何查看监视结果。 监视参数与输出结果如代码<br />
清单4-1所示。<br />
代码清单4-1 jstat执行样例<br />
D：\Develop\Java\jdk1.6.0_21\bin＞jstat-gcutil 2764<br />
S0 S1 E O P YGC YGCT FGC FGCT GCT<br />
0.00 0.00 6.20 41.42 47.20 16 0.105 3 0.472 0.577<br />
查询结果表明：这台服务器的新生代Eden区（E，表示Eden）使用了6.2%的空间，两个<br />
Survivor区（S0、 S1，表示Survivor0、 Survivor1）里面都是空的，老年代（O，表示Old）和<br />
永久代（P，表示Permanent）则分别使用了41.42%和47.20%的空间。 程序运行以来共发生<br />
Minor GC（YGC，表示Young GC）16次，总耗时0.105秒，发生Full GC（FGC，表示Full<br />
GC）3次，Full GC总耗时（FGCT，表示Full GC Time）为0.472秒，所有GC总耗时（GCT，<br />
表示GC Time）为0.577秒。<br />
使用jstat工具在纯文本状态下监视虚拟机状态的变化，确实不如后面将会提到的<br />
VisualVM等可视化的监视工具直接以图表展现那样直观。 但许多服务器管理员都习惯了在文<br />
本控制台中工作，直接在控制台中使用jstat命令依然是一种常用的监控方式。<br />
[1]需要远程主机提供RMI支持，Sun提供的jstatd工具可以很方便地建立远程RMI服务器。<br />
4.2.3 jinfo：Java配置信息工具<br />
jinfo（Configuration Info for Java）的作用是实时地查看和调整虚拟机各项参数。 使用jps<br />
命令的-v参数可以查看虚拟机启动时显式指定的参数列表，但如果想知道未被显式指定的参<br />
数的系统默认值，除了去找资料外，就只能使用jinfo的-flag选项进行查询了（如果只限于<br />
JDK 1.6或以上版本的话，使用java-XX：+PrintFlagsFinal查看参数默认值也是一个很好的选<br />
择），jinfo还可以使用-sysprops选项把虚拟机进程的System.getProperties（）的内容打印出<br />
来。 这个命令在JDK 1.5时期已经随着Linux版的JDK发布，当时只提供了信息查询的功<br />
能，JDK 1.6之后，jinfo在Windows和Linux平台都有提供，并且加入了运行期修改参数的能<br />
力，可以使用-flag[+|-]name或者-flag name=value修改一部分运行期可写的虚拟机参数值。<br />
JDK 1.6中，jinfo对于Windows平台功能仍然有较大限制，只提供了最基本的-flag选项。<br />
jinfo命令格式：<br />
jinfo[option]pid<br />
执行样例：查询CMSInitiatingOccupancyFraction参数值。<br />
C：\＞jinfo-flag CMSInitiatingOccupancyFraction 1444<br />
-XX：CMSInitiatingOccupancyFraction=85<br />
4.2.4 jmap：Java内存映像工具<br />
jmap（Memory Map for Java）命令用于生成堆转储快照（一般称为heapdump或dump文<br />
件）。 如果不使用jmap命令，要想获取Java堆转储快照，还有一些比较&ldquo;暴力&rdquo;的手段：譬如<br />
在第2章中用过的-XX：+HeapDumpOnOutOfMemoryError参数，可以让虚拟机在OOM异常出<br />
现之后自动生成dump文件，通过-XX：+HeapDumpOnCtrlBreak参数则可以使用[Ctrl]+[Break]<br />
键让虚拟机生成dump文件，又或者在Linux系统下通过Kill-3命令发送进程退出信号&ldquo;吓唬&rdquo;一<br />
下虚拟机，也能拿到dump文件。<br />
jmap的作用并不仅仅是为了获取dump文件，它还可以查询finalize执行队列、 Java堆和永<br />
久代的详细信息，如空间使用率、 当前用的是哪种收集器等。<br />
和jinfo命令一样，jmap有不少功能在Windows平台下都是受限的，除了生成dump文件的-<br />
dump选项和用于查看每个类的实例、 空间占用统计的-histo选项在所有操作系统都提供之<br />
外，其余选项都只能在Linux/Solaris下使用。<br />
jmap命令格式：<br />
jmap[option]vmid<br />
option选项的合法值与具体含义见表4-4。<br />
代码清单4-2是使用jmap生成一个正在运行的Eclipse的dump快照文件的例子，例子中的<br />
3500是通过jps命令查询到的LVMID。<br />
代码清单4-2 使用jmap生成dump文件<br />
C：\Users\IcyFenix＞jmap-dump：format=b,file=eclipse.bin 3500<br />
Dumping heap to C：\Users\IcyFenix\eclipse.bin&hellip;&hellip;<br />
Heap dump file created<br />
4.2.5 jhat：虚拟机堆转储快照分析工具<br />
Sun JDK提供jhat（JVM Heap Analysis Tool）命令与jmap搭配使用，来分析jmap生成的堆<br />
转储快照。 jhat内置了一个微型的HTTP/HTML服务器，生成dump文件的分析结果后，可以在<br />
浏览器中查看。 不过实事求是地说，在实际工作中，除非笔者手上真的没有别的工具可用，<br />
否则一般都不会去直接使用jhat命令来分析dump文件，主要原因有二：一是一般不会在部署<br />
应用程序的服务器上直接分析dump文件，即使可以这样做，也会尽量将dump文件复制到其<br />
他机器[1]上进行分析，因为分析工作是一个耗时而且消耗硬件资源的过程，既然都要在其他<br />
机器进行，就没有必要受到命令行工具的限制了；另一个原因是jhat的分析功能相对来说比<br />
较简陋，后文将会介绍到的VisualVM，以及专业用于分析dump文件的Eclipse Memory<br />
Analyzer、 IBM HeapAnalyzer[2]等工具，都能实现比jhat更强大更专业的分析功能。 代码清单4-<br />
3演示了使用jhat分析4.2.4节中采用jmap生成的Eclipse IDE的内存快照文件。<br />
代码清单4-3 使用jhat分析dump文件<br />
C：\Users\IcyFenix＞jhat eclipse.bin<br />
Reading from eclipse.bin&hellip;&hellip;<br />
Dump file created Fri Nov 19 22：07：21 CST 2010<br />
Snapshot read,resolving&hellip;&hellip;<br />
Resolving 1225951 objects&hellip;&hellip;<br />
Chasing references,expect 245 dots&hellip;&hellip;<br />
Eliminating duplicate references&hellip;&hellip;<br />
Snapshot resolved.<br />
Started HTTP server on port 7000<br />
Server is ready.<br />
屏幕显示&ldquo;Server is ready.&rdquo;的提示后，用户在浏览器中键入http://localhost：7000/就可以<br />
看到分析结果，如图4-3所示。<br />
图 4-3 jhat的分析结果<br />
分析结果默认是以包为单位进行分组显示，分析内存泄漏问题主要会使用到其中<br />
的&ldquo;Heap Histogram&rdquo;（与jmap-histo功能一样）与OQL页签的功能，前者可以找到内存中总容<br />
量最大的对象，后者是标准的对象查询语言，使用类似SQL的语法对内存中的对象进行查询<br />
统计，读者若对OQL有兴趣的话，可以参考本书附录D的介绍。<br />
[1]用于分析的机器一般也是服务器，由于加载dump快照文件需要比生成dump更大的内存，<br />
所以一般在64位JDK、 大内存的服务器上进行。<br />
[2]IBM HeapAnalyzer用于分析IBM J9虚拟机生成的映像文件，各个虚拟机产生的映像文件格<br />
式并不一致，所以分析工具也不能通用。<br />
4.2.6 jstack：Java堆栈跟踪工具<br />
jstack（Stack Trace for Java）命令用于生成虚拟机当前时刻的线程快照（一般称为<br />
threaddump或者javacore文件）。 线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈<br />
的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、 死循<br />
环、 请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。 线程出现停顿<br />
的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做些<br />
什么事情，或者等待着什么资源。<br />
jstack命令格式：<br />
jstack[option]vmid<br />
option选项的合法值与具体含义见表4-5。<br />
代码清单4-4是使用jstack查看Eclipse线程堆栈的例子，例子中的3500是通过jps命令查询<br />
到的LVMID。<br />
代码清单4-4 使用jstack查看线程堆栈（部分结果）<br />
C：\Users\IcyFenix＞jstack-l 3500<br />
2010-11-19 23：11：26<br />
Full thread dump Java HotSpot（TM）64-Bit Server VM（17.1-b03 mixed mode）：<br />
&quot;[ThreadPool Manager]-Idle Thread&quot;daemon prio=6 tid=0x0000000039dd4000 nid=0xf50 in Object.wait（）[0x000000003c96f000]<br />
java.lang.Thread.State：WAITING（on object monitor）<br />
at java.lang.Object.wait（Native Method）<br />
-waiting on＜0x0000000016bdcc60＞（a org.eclipse.equinox.internal.util.impl.tpt.threadpool.Executor）<br />
at java.lang.Object.wait（Object.java：485）<br />
at org.eclipse.equinox.internal.util.impl.tpt.threadpool.Executor.run（Executor.java：106）<br />
-locked＜0x0000000016bdcc60＞（a org.eclipse.equinox.internal.util.impl.tpt.threadpool.Executor）<br />
Locked ownable synchronizers：<br />
-None<br />
在JDK 1.5中，java.lang.Thread类新增了一个getAllStackTraces（）方法用于获取虚拟机<br />
中所有线程的StackTraceElement对象。 使用这个方法可以通过简单的几行代码就完成jstack的<br />
大部分功能，在实际项目中不妨调用这个方法做个管理员页面，可以随时使用浏览器来查看<br />
线程堆栈，如代码清单4-5所示，这是笔者的一个小经验。<br />
代码清单4-5 查看线程状况的JSP页面<br />
＜%@page import=&quot;java.util.Map&quot;%＞<br />
＜html＞<br />
＜head＞<br />
＜title＞服务器线程信息＜/title＞<br />
＜/head＞<br />
＜body＞<br />
＜pre＞<br />
＜%<br />
for（Map.Entry＜Thread,StackTraceElement[]＞stackTrace：Thread.<br />
getAllStackTraces（）.entrySet（））{<br />
Thread thread=（Thread）stackTrace.getKey（）；<br />
StackTraceElement[]stack=（StackTraceElement[]）stackTrace.getValue（）；<br />
if（thread.equals（Thread.currentThread（）））{<br />
continue；<br />
}o<br />
ut.print（&quot;\n线程：&quot;+thread.getName（）+&quot;\n&quot;）；<br />
for（StackTraceElement element：stack）{<br />
out.print（&quot;\t&quot;+element+&quot;\n&quot;）；<br />
}}%<br />
＞<br />
＜/pre＞<br />
＜/body＞<br />
＜/html＞<br />
4.2.7 HSDIS：JIT生成代码反汇编<br />
在Java虚拟机规范中，详细描述了虚拟机指令集中每条指令的执行过程、 执行前后对操<br />
作数栈、 局部变量表的影响等细节。 这些细节描述与Sun的早期虚拟机（Sun Classic VM）高<br />
度吻合，但随着技术的发展，高性能虚拟机真正的细节实现方式已经渐渐与虚拟机规范所描<br />
述的内容产生了越来越大的差距，虚拟机规范中的描述逐渐成了虚拟机实现的&ldquo;概念模<br />
型&rdquo;&mdash;&mdash;即实现只能保证规范描述等效。 基于这个原因，我们分析程序的执行语义问题（虚<br />
拟机做了什么）时，在字节码层面上分析完全可行，但分析程序的执行行为问题（虚拟机是<br />
怎样做的、 性能如何）时，在字节码层面上分析就没有什么意义了，需要通过其他方式解<br />
决。<br />
分析程序如何执行，通过软件调试工具（GDB、 Windbg等）来断点调试是最常见的手<br />
段，但是这样的调试方式在Java虚拟机中会遇到很大困难，因为大量执行代码是通过JIT编译<br />
器动态生成到CodeBuffer中的，没有很简单的手段来处理这种混合模式的调试（不过相信虚<br />
拟机开发团队内部肯定是有内部工具的）。 因此，不得不通过一些特别的手段来解决问题，<br />
基于这种背景，本节的主角&mdash;&mdash;HSDIS插件就正式登场了。<br />
HSDIS是一个Sun官方推荐的HotSpot虚拟机JIT编译代码的反汇编插件，它包含在HotSpot<br />
虚拟机的源码之中，但没有提供编译后的程序。 在Project Kenai的网站[1]也可以下载到单独的<br />
源码。 它的作用是让HotSpot的-XX：+PrintAssembly指令调用它来把动态生成的本地代码还<br />
原为汇编代码输出，同时还生成了大量非常有价值的注释，这样我们就可以通过输出的代码<br />
来分析问题。 读者可以根据自己的操作系统和CPU类型从Project Kenai的网站上下载编译好<br />
的插件，直接放到JDK_HOME/jre/bin/client和JDK_HOME/jre/bin/server目录中即可。 如果没<br />
有找到所需操作系统（譬如Windows的就没有）的成品，那就得自己使用源码编译一下[2]。<br />
还需要注意的是，如果读者使用的是Debug或者FastDebug版的HotSpot，那可以直接通<br />
过-XX：+PrintAssembly指令使用插件；如果使用的是Product版的HotSpot，那还要额外加入<br />
一个-XX：+UnlockDiagnosticVMOptions参数。 笔者以代码清单4-6中的简单测试代码为例演<br />
示一下这个插件的使用。<br />
代码清单4-6 测试代码<br />
public class Bar{<br />
int a=1；<br />
static int b=2；<br />
public int sum（int c）{<br />
return a+b+c；<br />
}p<br />
ublic static void main（String[]args）{<br />
new Bar（）.sum（3）；<br />
}} 编<br />
译这段代码，并使用以下命令执行。<br />
java-XX：+PrintAssembly-Xcomp-XX：CompileCommand=dontinline，*Bar.sum-XX：Compi leCommand=compileonly，*Bar.sum test.Bar<br />
其中，参数-Xcomp是让虚拟机以编译模式执行代码，这样代码可以&ldquo;偷懒&rdquo;，不需要执行<br />
足够次数来预热就能触发JIT编译[3]。 两个-XX：CompileCommand意思是让编译器不要内联<br />
sum（）并且只编译sum（），-XX：+PrintAssembly就是输出反汇编内容。 如果一切顺利的<br />
话，那么屏幕上会出现类似下面代码清单4-7所示的内容。<br />
代码清单4-7 测试代码<br />
[Disassembling for mach=&#39;i386&#39;]<br />
[Entry Point]<br />
[Constants]<br />
#{method}&#39;sum&#39;&#39;（I）I&#39;in&#39;test/Bar&#39;<br />
#this：ecx=&#39;test/Bar&#39;<br />
#parm0：edx=int<br />
#[sp+0x20]（sp of caller）<br />
&hellip;&hellip;<br />
0x01cac407：cmp 0x4（%ecx），%eax<br />
0x01cac40a：jne 0x01c6b050；{runtime_call}<br />
[Verified Entry Point]<br />
0x01cac410：mov%eax，-0x8000（%esp）<br />
0x01cac417：push%ebp<br />
0x01cac418：sub$0x18，%esp；*aload_0<br />
；-test.Bar：sum@0（line 8）<br />
；block B0[0，10]<br />
0x01cac41b：mov 0x8（%ecx），%eax；*getfield a<br />
；-test.Bar：sum@1（line 8）<br />
0x01cac41e：mov$0x3d2fad8，%esi；{oop（a<br />
&#39;java/lang/Class&#39;=&#39;test/Bar&#39;）}<br />
0x01cac423：mov 0x68（%esi），%esi；*getstatic b<br />
；-test.Bar：sum@4（line 8）<br />
0x01cac426：add%esi，%eax<br />
0x01cac428：add%edx，%eax<br />
0x01cac42a：add$0x18，%esp<br />
0x01cac42d：pop%ebp<br />
0x01cac42e：test%eax，0x2b0100；{poll_return}<br />
0x01cac434：ret<br />
上段代码并不多，下面一句句进行说明。<br />
1）mov%eax，-0x8000（%esp）：检查栈溢。<br />
2）push%ebp：保存上一栈帧基址。<br />
3）sub$0x18，%esp：给新帧分配空间。<br />
4）mov 0x8（%ecx），%eax：取实例变量a，这里0x8（%ecx）就是ecx+0x8的意思，前<br />
面&ldquo;[Constants]&rdquo;节中提示了&ldquo;this：ecx=&#39;test/Bar&#39;&rdquo;，即ecx寄存器中放的就是this对象的地址。 偏<br />
移0x8是越过this对象的对象头，之后就是实例变量a的内存位置。 这次是访问&ldquo;Java堆&rdquo;中的数<br />
据。<br />
5）mov$0x3d2fad8，%esi：取test.Bar在方法区的指针。<br />
6）mov 0x68（%esi），%esi：取类变量b，这次是访问&ldquo;方法区&rdquo;中的数据。<br />
7）add%esi，%eax和add%edx，%eax：做两次加法，求a+b+c的值，前面的代码把a放在<br />
eax中，把b放在esi中，而c在[Constants]中提示了，&ldquo;parm0：edx=int&rdquo;，说明c在edx中。<br />
8）add$0x18，%esp：撤销栈帧。<br />
9）pop%ebp：恢复上一栈帧。<br />
10）test%eax，0x2b0100：轮询方法返回处的SafePoint。<br />
11）ret：方法返回。<br />
[1]Project Kenai：http://kenai.com/projects/base-hsdis。<br />
[2]HLLVM圈子中有已编译好的：http://hllvm.group.iteye.com/。<br />
[3]-Xcomp在较新的HotSpot中被移除了，如果读者的虚拟机无法使用这个参数，请加个循环<br />
预热代码，触发JIT编译。<br />
4.3 JDK的可视化工具<br />
JDK中除了提供大量的命令行工具外，还有两个功能强大的可视化工具：JConsole和<br />
VisualVM，这两个工具是JDK的正式成员，没有被贴上&ldquo;unsupported and experimental&rdquo;的标<br />
签。<br />
其中JConsole是在JDK 1.5时期就已经提供的虚拟机监控工具，而VisualVM在JDK 1.6<br />
Update7中才首次发布，现在已经成为Sun（Oracle）主力推动的多合一故障处理工具[1]，并且<br />
已经从JDK中分离出来成为可以独立发展的开源项目。<br />
为了避免本节的讲解成为对软件说明文档的简单翻译，笔者准备了一些代码样例，都是<br />
笔者特意编写的&ldquo;反面教材&rdquo;。 后面将会使用这两款工具去监控、 分析这几段代码存在的问<br />
题，算是本节简单的实战分析。 读者可以把在可视化工具观察到的数据、 现象，与前面两章<br />
中讲解的理论知识互相印证。<br />
4.3.1 JConsole：Java监视与管理控制台<br />
JConsole（Java Monitoring and Management Console）是一种基于JMX的可视化监视、 管<br />
理工具。 它管理部分的功能是针对JMX MBean进行管理，由于MBean可以使用代码、 中间件<br />
服务器的管理控制台或者所有符合JMX规范的软件进行访问，所以本节将会着重介绍<br />
JConsole监视部分的功能。<br />
1.启动JConsole<br />
通过JDK/bin目录下的&ldquo;jconsole.exe&rdquo;启动JConsole后，将自动搜索出本机运行的所有虚拟<br />
机进程，不需要用户自己再使用jps来查询了，如图4-4所示。 双击选择其中一个进程即可开<br />
始监控，也可以使用下面的&ldquo;远程进程&rdquo;功能来连接远程服务器，对远程虚拟机进行监控。<br />
图 4-4 JConsole连接页面<br />
从图4-4可以看出，笔者的机器现在运行了Eclipse、 JConsole和MonitoringTest三个本地虚<br />
拟机进程，其中MonitoringTest就是笔者准备的&ldquo;反面教材&rdquo;代码之一。 双击它进入JConsole主<br />
界面，可以看到主界面里共包括&ldquo;概述&rdquo;、 &ldquo;内存&rdquo;、 &ldquo;线程&rdquo;、 &ldquo;类&rdquo;、 &ldquo;VM摘要&rdquo;、 &ldquo;MBean&rdquo;6个<br />
页签，如图4-5所示。<br />
图 4-5 JConsole主界面<br />
&ldquo;概述&rdquo;页签显示的是整个虚拟机主要运行数据的概览，其中包括&ldquo;堆内存使用情况&rdquo;、<br />
&ldquo;线程&rdquo;、 &ldquo;类&rdquo;、 &ldquo;CPU使用情况&rdquo;4种信息的曲线图，这些曲线图是后面&ldquo;内存&rdquo;、 &ldquo;线程&rdquo;、<br />
&ldquo;类&rdquo;页签的信息汇总，具体内容将在后面介绍。<br />
2.内存监控<br />
&ldquo;内存&rdquo;页签相当于可视化的jstat命令，用于监视受收集器管理的虚拟机内存（Java堆和<br />
永久代）的变化趋势。 我们通过运行代码清单4-8中的代码来体验一下它的监视功能。 运行<br />
时设置的虚拟机参数为：-Xms100m-Xmx100m-XX：+UseSerialGC，这段代码的作用是以<br />
64KB/50毫秒的速度往Java堆中填充数据，一共填充1000次，使用JConsole的&ldquo;内存&rdquo;页签进行<br />
监视，观察曲线和柱状指示图的变化。<br />
代码清单4-8 JConsole监视代码<br />
/**<br />
*内存占位符对象，一个OOMObject大约占64KB<br />
*/<br />
static class OOMObject{<br />
public byte[]placeholder=new byte[64*1024]；<br />
}p<br />
ublic static void fillHeap（int num）throws InterruptedException{<br />
List＜OOMObject＞list=new ArrayList＜OOMObject＞（）；<br />
for（int i=0；i＜num；i++）{<br />
//稍作延时，令监视曲线的变化更加明显<br />
Thread.sleep（50）；<br />
list.add（new OOMObject（））；<br />
}S<br />
ystem.gc（）；<br />
}p<br />
ublic static void main（String[]args）throws Exception{<br />
fillHeap（1000）；<br />
} 程<br />
序运行后，在&ldquo;内存&rdquo;页签中可以看到内存池Eden区的运行趋势呈现折线状，如图4-6<br />
所示。 而监视范围扩大至整个堆后，会发现曲线是一条向上增长的平滑曲线。 并且从柱状图<br />
可以看出，在1000次循环执行结束，运行了System.gc（）后，虽然整个新生代Eden和<br />
Survivor区都基本被清空了，但是代表老年代的柱状图仍然保持峰值状态，说明被填充进堆<br />
中的数据在System.gc（）方法执行之后仍然存活。 笔者的分析到此为止，现提两个小问题供<br />
读者思考一下，答案稍后给出。<br />
1）虚拟机启动参数只限制了Java堆为100MB，没有指定-Xmn参数，能否从监控图中估<br />
计出新生代有多大？<br />
2）为何执行了System.gc（）之后，图4-6中代表老年代的柱状图仍然显示峰值状态，代<br />
码需要如何调整才能让System.gc（）回收掉填充到堆中的对象？<br />
图 4-6 Eden区内存变化状况<br />
问题1答案：图4-6显示Eden空间为27 328KB，因为没有设置-XX：SurvivorRadio参数，<br />
所以Eden与Survivor空间比例为默认值8:1，整个新生代空间大约为27 328KB&times;125%=34<br />
160KB。<br />
问题2答案：执行完System.gc（）之后，空间未能回收是因为List＜OOMObject＞list对象<br />
仍然存活，fillHeap（）方法仍然没有退出，因此list对象在System.gc（）执行时仍然处于作<br />
用域之内[2]。 如果把System.gc（）移动到fillHeap（）方法外调用就可以回收掉全部内存。<br />
3.线程监控<br />
如果上面的&ldquo;内存&rdquo;页签相当于可视化的jstat命令的话，&ldquo;线程&rdquo;页签的功能相当于可视化<br />
的jstack命令，遇到线程停顿时可以使用这个页签进行监控分析。 前面讲解jstack命令的时候<br />
提到过线程长时间停顿的主要原因主要有：等待外部资源（数据库连接、 网络资源、 设备资<br />
源等）、 死循环、 锁等待（活锁和死锁）。 通过代码清单4-9分别演示一下这几种情况。<br />
代码清单4-9 线程等待演示代码<br />
/**<br />
*线程死循环演示<br />
*/<br />
public static void createBusyThread（）{<br />
Thread thread=new Thread（new Runnable（）{<br />
@Override<br />
public void run（）{<br />
while（true）//第41行<br />
；}}<br />
，&quot;testBusyThread&quot;）；<br />
thread.start（）；<br />
}/<br />
**<br />
*线程锁等待演示<br />
*/<br />
public static void createLockThread（final Object lock）{<br />
Thread thread=new Thread（new Runnable（）{<br />
@Override<br />
public void run（）{<br />
synchronized（lock）{<br />
try{<br />
lock.wait（）；<br />
}catch（InterruptedException e）{<br />
e.printStackTrace（）；<br />
}}}}<br />
，&quot;testLockThread&quot;）；<br />
thread.start（）；<br />
}p<br />
ublic static void main（String[]args）throws Exception{<br />
BufferedReader br=new BufferedReader（new InputStreamReader（System.in））；<br />
br.readLine（）；<br />
createBusyThread（）；<br />
br.readLine（）；<br />
Object obj=new Object（）；<br />
createLockThread（obj）；<br />
} 程<br />
序运行后，首先在&ldquo;线程&rdquo;页签中选择main线程，如图4-7所示。 堆栈追踪显示<br />
BufferedReader在readBytes方法中等待System.in的键盘输入，这时线程为Runnable状<br />
态，Runnable状态的线程会被分配运行时间，但readBytes方法检查到流没有更新时会立刻归<br />
还执行令牌，这种等待只消耗很小的CPU资源。<br />
图 4-7 main线程<br />
接着监控testBusyThread线程，如图4-8所示，testBusyThread线程一直在执行空循环，从<br />
堆栈追踪中看到一直在MonitoringTest.java代码的41行停留，41行为：while（true）。 这时候<br />
线程为Runnable状态，而且没有归还线程执行令牌的动作，会在空循环上用尽全部执行时间<br />
直到线程切换，这种等待会消耗较多的CPU资源。<br />
图 4-8 testBusyThread线程<br />
图4-9显示testLockThread线程在等待着lock对象的notify或notifyAll方法的出现，线程这时<br />
候处于WAITING状态，在被唤醒前不会被分配执行时间。<br />
图 4-9 testLockThread线程<br />
testLockThread线程正在处于正常的活锁等待，只要lock对象的notify（）或notifyAll（）<br />
方法被调用，这个线程便能激活以继续执行。 代码清单4-10演示了一个无法再被激活的死锁<br />
等待。<br />
代码清单4-10 死锁代码样例<br />
/**<br />
*线程死锁等待演示<br />
*/<br />
static class SynAddRunalbe implements Runnable{<br />
int a,b；<br />
public SynAddRunalbe（int a,int b）{<br />
this.a=a；<br />
this.b=b；<br />
}@<br />
Override<br />
public void run（）{<br />
synchronized（Integer.valueOf（a））{<br />
synchronized（Integer.valueOf（b））{<br />
System.out.println（a+b）；<br />
}}}}p<br />
ublic static void main（String[]args）{<br />
for（int i=0；i＜100；i++）{<br />
new Thread（new SynAddRunalbe（1，2））.start（）；<br />
new Thread（new SynAddRunalbe（2，1））.start（）；<br />
}} 这<br />
段代码开了200个线程去分别计算1+2以及2+1的值，其实for循环是可省略的，两个线<br />
程也可能会导致死锁，不过那样概率太小，需要尝试运行很多次才能看到效果。 一般的话，<br />
带for循环的版本最多运行2～3次就会遇到线程死锁，程序无法结束。 造成死锁的原因是<br />
Integer.valueOf（）方法基于减少对象创建次数和节省内存的考虑，[-128，127]之间的数字会<br />
被缓存[3]，当valueOf（）方法传入参数在这个范围之内，将直接返回缓存中的对象。 也就是<br />
说，代码中调用了200次Integer.valueOf（）方法一共就只返回了两个不同的对象。 假如在某<br />
个线程的两个synchronized块之间发生了一次线程切换，那就会出现线程A等着被线程B持有<br />
的Integer.valueOf（1），线程B又等着被线程A持有的Integer.valueOf（2），结果出现大家都<br />
跑不下去的情景。<br />
出现线程死锁之后，点击JConsole线程面板的&ldquo;检测到死锁&rdquo;按钮，将出现一个新的&ldquo;死<br />
锁&rdquo;页签，如图4-10所示。<br />
图 4-10 线程死锁<br />
图4-10中很清晰地显示了线程Thread-43在等待一个被线程Thread-12持有Integer对象，而<br />
点击线程Thread-12则显示它也在等待一个Integer对象，被线程Thread-43持有，这样两个线程<br />
就互相卡住，都不存在等到锁释放的希望了。<br />
[1]VisualVM官方站点：https://visualvm.dev.java.net/。<br />
[2]准确地说，只有在虚拟机使用解释器执行的时候，&ldquo;在作用域之内&rdquo;才能保证它不会被回<br />
收，因为这里的回收还涉及局部变量表Slot复用、 即时编译器介入时机等问题，具体读者可<br />
参考第8章中关于局部变量表内存回收的例子。<br />
[3]默认值，实际值取决于java.lang.Integer.IntegerCache.high参数的设置。<br />
4.3.2 VisualVM：多合一故障处理工具<br />
VisualVM（All-in-One Java Troubleshooting Tool）是到目前为止随JDK发布的功能最强大<br />
的运行监视和故障处理程序，并且可以预见在未来一段时间内都是官方主力发展的虚拟机故<br />
障处理工具。 官方在VisualVM的软件说明中写上了&ldquo;All-in-One&rdquo;的描述字样，预示着它除了<br />
运行监视、 故障处理外，还提供了很多其他方面的功能。 如性能分析<br />
（Profiling），VisualVM的性能分析功能甚至比起JProfiler、 YourKit等专业且收费的Profiling<br />
工具都不会逊色多少，而且VisualVM的还有一个很大的优点：不需要被监视的程序基于特殊<br />
Agent运行，因此它对应用程序的实际性能的影响很小，使得它可以直接应用在生产环境<br />
中。 这个优点是JProfiler、 YourKit等工具无法与之媲美的。<br />
1.VisualVM兼容范围与插件安装<br />
VisualVM基于NetBeans平台开发，因此它一开始就具备了插件扩展功能的特性，通过插<br />
件扩展支持，VisualVM可以做到：<br />
显示虚拟机进程以及进程的配置、 环境信息（jps、 jinfo）。<br />
监视应用程序的CPU、 GC、 堆、 方法区以及线程的信息（jstat、 jstack）。<br />
dump以及分析堆转储快照（jmap、 jhat）。<br />
方法级的程序运行性能分析，找出被调用最多、 运行时间最长的方法。<br />
离线程序快照：收集程序的运行时配置、 线程dump、 内存dump等信息建立一个快照，<br />
可以将快照发送开发者处进行Bug反馈。<br />
其他plugins的无限的可能性&hellip;&hellip;<br />
VisualVM在JDK 1.6 update 7中才首次出现，但并不意味着它只能监控运行于JDK 1.6上<br />
的程序，它具备很强的向下兼容能力，甚至能向下兼容至近10年前发布的JDK 1.4.2平台[1]，<br />
这对无数已经处于实施、 维护的项目很有意义。 当然，并非所有功能都能完美地向下兼容，<br />
主要特性的兼容性见表4-6。<br />
首次启动VisualVM后，读者先不必着急找应用程序进行监测，因为现在VisualVM还没有<br />
加载任何插件，虽然基本的监视、 线程面板的功能主程序都以默认插件的形式提供了，但是<br />
不给VisualVM装任何扩展插件，就相当于放弃了它最精华的功能，和没有安装任何应用软件<br />
操作系统差不多。<br />
插件可以进行手工安装，在相关网站[2]上下载*.nbm包后，点击&ldquo;工具&rdquo;&rarr;&ldquo;插件&rdquo;&rarr;&ldquo;已下<br />
载&rdquo;菜单，然后在弹出的对话框中指定nbm包路径便可进行安装，插件安装后存放在<br />
JDK_HOME/lib/visualvm/visualvm中。 不过手工安装并不常用，使用VisualVM的自动安装功<br />
能已经可以找到大多数所需的插件，在有网络连接的环境下，点击&ldquo;工具&rdquo;&rarr;&ldquo;插件菜单&rdquo;，弹<br />
出如图4-11所示的插件页签，在页签的&ldquo;可用插件&rdquo;中列举了当前版本VisualVM可以使用的插<br />
件，选中插件后在右边窗口将显示这个插件的基本信息，如开发者、 版本、 功能描述等。<br />
图 4-11 VisualVM插件页签<br />
大家可以根据自己的工作需要和兴趣选择合适的插件，然后点击安装按钮，弹出如图4-<br />
12所示的下载进度窗口，跟着提示操作即可完成安装。<br />
图 4-12 VisualVM插件安装过程<br />
安装完插件，选择一个需要监视的程序就进入程序的主界面了，如图4-13所示。 根据读<br />
者选择安装插件数量的不同，看到的页签可能和图4-13中的有所不同。<br />
图 4-13 VisualVM主界面<br />
VisualVM中&ldquo;概述&rdquo;、 &ldquo;监视&rdquo;、 &ldquo;线程&rdquo;、 &ldquo;MBeans&rdquo;的功能与前面介绍的JConsole差别不<br />
大，读者根据上文内容类比使用即可，下面挑选几个特色功能、 插件进行介绍。<br />
2.生成、 浏览堆转储快照<br />
在VisualVM中生成dump文件有两种方式，可以执行下列任一操作：<br />
在&ldquo;应用程序&rdquo;窗口中右键单击应用程序节点，然后选择&ldquo;堆Dump&rdquo;。<br />
在&ldquo;应用程序&rdquo;窗口中双击应用程序节点以打开应用程序标签，然后在&ldquo;监视&rdquo;标签中单<br />
击&ldquo;堆Dump&rdquo;。<br />
生成了dump文件之后，应用程序页签将在该堆的应用程序下增加一个以[heapdump]开头<br />
的子节点，并且在主页签中打开了该转储快照，如图4-14所示。 如果需要把dump文件保存或<br />
发送出去，要在heapdump节点上右键选择&ldquo;另存为&rdquo;菜单，否则当VisualVM关闭时，生成的<br />
dump文件会被当做临时文件删除掉。 要打开一个已经存在的dump文件，通过文件菜单中<br />
的&ldquo;装入&rdquo;功能，选择硬盘上的dump文件即可。<br />
图 4-14 浏览dump文件<br />
从堆页签中的&ldquo;摘要&rdquo;面板可以看到应用程序dump时的运行时参数、<br />
System.getProperties（）的内容、 线程堆栈等信息，&ldquo;类&rdquo;面板则是以类为统计口径统计类的实<br />
例数量、 容量信息，&ldquo;实例&rdquo;面板不能直接使用，因为不能确定用户想查看哪个类的实例，所<br />
以需要通过&ldquo;类&rdquo;面板进入，在&ldquo;类&rdquo;中选择一个关心的类后双击鼠标，即可在&ldquo;实例&rdquo;里面看见<br />
此类中500个实例的具体属性信息。 &ldquo;OQL控制台&rdquo;面板中就是运行OQL查询语句的，同jhat中<br />
介绍的OQL功能一样。 如果需要了解具体OQL语法和使用，可参见本书附录D的内容。<br />
3.分析程序性能<br />
在Profiler页签中，VisualVM提供了程序运行期间方法级的CPU执行时间分析以及内存分<br />
析，做Profiling分析肯定会对程序运行性能有比较大的影响，所以一般不在生产环境中使用<br />
这项功能。<br />
要开始分析，先选择&ldquo;CPU&rdquo;和&ldquo;内存&rdquo;按钮中的一个，然后切换到应用程序中对程序进行<br />
操作，VisualVM会记录到这段时间中应用程序执行过的方法。 如果是CPU分析，将会统计每<br />
个方法的执行次数、 执行耗时；如果是内存分析，则会统计每个方法关联的对象数以及这些<br />
对象所占的空间。 分析结束后，点击&ldquo;停止&rdquo;按钮结束监控过程，如图4-15所示。<br />
图 4-15 对应用程序进行CPU执行时间分析<br />
注意 在JDK 1.5之后，在Client模式下的虚拟机加入并且自动开启了类共享&mdash;&mdash;这是一<br />
个在多虚拟机进程中共享rt.jar中类数据以提高加载速度和节省内存的优化，而根据相关Bug<br />
报告的反映，VisualVM的Profiler功能可能会因为类共享而导致被监视的应用程序崩溃，所以<br />
读者进行Profiling前，最好在被监视程序中使用-Xshare：off参数来关闭类共享优化。<br />
图4-15中是对Eclipse IDE一段操作的录制和分析结果，读者分析自己的应用程序时，可<br />
以根据实际业务的复杂程度与方法的时间、 调用次数做比较，找到最有优化价值的方法。<br />
4.BTrace动态日志跟踪<br />
BTrace[3]是一个很&ldquo;有趣&rdquo;的VisualVM插件，本身也是可以独立运行的程序。 它的作用是<br />
在不停止目标程序运行的前提下，通过HotSpot虚拟机的HotSwap技术[4]动态加入原本并不存<br />
在的调试代码。 这项功能对实际生产中的程序很有意义：经常遇到程序出现问题，但排查错<br />
误的一些必要信息，譬如方法参数、 返回值等，在开发时并没有打印到日志之中，以至于不<br />
得不停掉服务，通过调试增量来加入日志代码以解决问题。 当遇到生产环境服务无法随便停<br />
止时，缺一两句日志导致排错进行不下去是一件非常郁闷的事情。<br />
在VisualVM中安装了BTrace插件后，在应用程序面板中右键点击要调试的程序，会出<br />
现&ldquo;Trace Application&hellip;&hellip;&rdquo;菜单，点击将进入BTrace面板。 这个面板里面看起来就像一个简单<br />
的Java程序开发环境，里面还有一小段Java代码，如图4-16所示。<br />
图 4-16 BTrace动态跟踪<br />
笔者准备了一段很简单的Java代码来演示BTrace的功能：产生两个1000以内的随机整<br />
数，输出这两个数字相加的结果，如代码清单4-11所示。<br />
代码清单4-11 BTrace跟踪演示<br />
public class BTraceTest{<br />
public int add（int a,int b）{<br />
return a+b；<br />
}p<br />
ublic static void main（String[]args）throws IOException{<br />
BTraceTest test=new BTraceTest（）；<br />
BufferedReader reader=new BufferedReader（new InputStreamReader（System.in））；<br />
for（int i=0；i＜10；i++）{<br />
reader.readLine（）；<br />
int a=（int）Math.round（Math.random（）*1000）；<br />
int b=（int）Math.round（Math.random（）*1000）；<br />
System.out.println（test.add（a,b））；<br />
}}} 程<br />
序运行后，在VisualVM中打开该程序的监视，在BTrace页签填充TracingScript的内<br />
容，输入的调试代码如代码清单4-12所示。<br />
代码清单4-12 BTrace调试代码<br />
/*BTrace Script Template*/<br />
import com.sun.btrace.annotations.*；<br />
import static com.sun.btrace.BTraceUtils.*；<br />
@BTrace<br />
public class TracingScript{<br />
@OnMethod（<br />
clazz=&quot;org.fenixsoft.monitoring.BTraceTest&quot;，<br />
method=&quot;add&quot;，<br />
location=@Location（Kind.RETURN）<br />
）p<br />
ublic static void func（@Self org.fenixsoft.monitoring.BTraceTest instance,int a,int b，@Return int result）{<br />
println（&quot;调用堆栈：&quot;）；<br />
jstack（）；<br />
println（strcat（&quot;方法参数A：&quot;，str（a）））；<br />
println（strcat（&quot;方法参数B：&quot;，str（b）））；<br />
println（strcat（&quot;方法结果：&quot;，str（result）））；<br />
}} 点<br />
击&ldquo;Start&rdquo;按钮后稍等片刻，编译完成后，可见Output面板中出现&ldquo;BTrace code<br />
successfuly deployed&rdquo;的字样。 程序运行的时候在Output面板将会输出如图4-17所示的调试信<br />
息。<br />
图 4-17 BTrace跟踪结果<br />
BTrace的用法还有许多，打印调用堆栈、 参数、 返回值只是最基本的应用，在它的网站<br />
上有使用BTrace进行性能监视、 定位连接泄漏和内存泄漏、 解决多线程竞争问题等例子，有<br />
兴趣的读者可以去相关网站了解一下。<br />
[1]早于JDK1.6的平台，需要打开-Dcom.sun.management.jmxremote参数才能被VisualVM管理。<br />
[2]插件中心地址：http://Visualvm java.net/pluginscenters.html。<br />
[3]官方主页：http://kenai.com/projects/btrace/。<br />
[4]HotSwap技术：代码热替换技术，HotSpot虚拟机允许在不停止运行的情况下，更新已经加<br />
载的类的代码。<br />
4.4 本章小结<br />
本章介绍了随JDK发布的6个命令行工具及两个可视化的故障处理工具，灵活使用这些<br />
工具可以给问题处理带来很大的便利。<br />
除了JDK自带的工具之外，常用的故障处理工具还有很多，如果读者使用的是非Sun系<br />
列的JDK、 非HotSpot的虚拟机，就需要使用对应的工具进行分析，如：<br />
IBM的Support Assistant[1]、 Heap Analyzer [2]、 Javacore Analyzer [3]、 Garbage Collector<br />
Analyzer[4]适用于IBM J9 VM。<br />
HP的HPjmeter[5]、 HPjtune适用于HP-UX、 SAP、 HotSpot VM。<br />
Eclipse的Memory Analyzer Tool [6]（MAT）适用于HP-UX、 SAP、 HotSpot VM，安装IBM<br />
DTFJ插件后可支持IBM J9 VM。<br />
BEA的JRockit Mission Control[7]适用于JRockit VM。<br />
[1]http://www.alphaworks.ibm.com/tech/heapanalyzer/download。<br />
[2]http://www.alphaworks.ibm.com/tech/jca/download。<br />
[3]http://www.alphaworks.ibm.com/tech/pmat/download。<br />
[4]https://h20392.www2.hp.com/portal/swdepot/displayProductInfo.do?<br />
productNumber=HPJMETER。<br />
[5]http://www.eclipse.org/mat/。<br />
[6]http://www.ibm.com/developerworks/java/jdk/tools/dtfj.html。<br />
[7]http://download.oracle.com/docs/cd/E13150_01/jrockit_jvm/jrockit/tools/index.html。</p>

<h2><br />
第5章 调优案例分析与实战</h2>

<p><br />
Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的&ldquo;高墙&rdquo;，墙外面的人想<br />
进去，墙里面的人却想出来。<br />
5.1 概述<br />
上文介绍了处理Java虚拟机内存问题的知识与工具，在处理实际项目的问题时，除了知<br />
识与工具外，经验同样是一个很重要的因素。 因此本章将与读者分享几个比较有代表性的实<br />
际案例。 考虑到虚拟机故障处理和调优主要面向各类服务端应用，而大部分Java程序员较少<br />
有机会直接接触生产环境的服务器，因此本章还准备了一个所有开发人员都能够进行&ldquo;亲身<br />
实战&rdquo;的练习，希望通过实践使读者获得故障处理和调优的经验。<br />
5.2 案例分析<br />
本章中的案例大部分来源于笔者处理过的一些问题，还有一小部分来源于网络上比较有<br />
特色和代表性的案例总结。 出于对客户商业信息保护的目的，在不影响前后逻辑的前提下，<br />
笔者对实际环境和用户业务做了一些屏蔽和精简。<br />
5.2.1 高性能硬件上的程序部署策略<br />
例如，一个15万PV/天左右的在线文档类型网站最近更换了硬件系统，新的硬件为4个<br />
CPU、 16GB物理内存，操作系统为64位CentOS 5.4，Resin作为Web服务器。 整个服务器暂时<br />
没有部署别的应用，所有硬件资源都可以提供给这访问量并不算太大的网站使用。 管理员为<br />
了尽量利用硬件资源选用了64位的JDK 1.5，并通过-Xmx和-Xms参数将Java堆固定在12GB。<br />
使用一段时间后发现使用效果并不理想，网站经常不定期出现长时间失去响应的情况。<br />
监控服务器运行状况后发现网站失去响应是由GC停顿导致的，虚拟机运行在Server模<br />
式，默认使用吞吐量优先收集器，回收12GB的堆，一次Full GC的停顿时间高达14秒。 并且<br />
由于程序设计的关系，访问文档时要把文档从磁盘提取到内存中，导致内存中出现很多由文<br />
档序列化产生的大对象，这些大对象很多都进入了老年代，没有在Minor GC中清理掉。 这种<br />
情况下即使有12GB的堆，内存也很快被消耗殆尽，由此导致每隔十几分钟出现十几秒的停<br />
顿，令网站开发人员和管理员感到很沮丧。<br />
这里先不延伸讨论程序代码问题，程序部署上的主要问题显然是过大的堆内存进行回收<br />
时带来的长时间的停顿。 硬件升级前使用32位系统1.5GB的堆，用户只感觉到使用网站比较<br />
缓慢，但不会发生十分明显的停顿，因此才考虑升级硬件以提升程序效能，如果重新缩小给<br />
Java堆分配的内存，那么硬件上的投资就显得很浪费。<br />
在高性能硬件上部署程序，目前主要有两种方式：<br />
通过64位JDK来使用大内存。<br />
使用若干个32位虚拟机建立逻辑集群来利用硬件资源。<br />
此案例中的管理员采用了第一种部署方式。 对于用户交互性强、 对停顿时间敏感的系<br />
统，可以给Java虚拟机分配超大堆的前提是有把握把应用程序的Full GC频率控制得足够低，<br />
至少要低到不会影响用户使用，譬如十几个小时乃至一天才出现一次Full GC，这样可以通过<br />
在深夜执行定时任务的方式触发Full GC甚至自动重启应用服务器来保持内存可用空间在一个<br />
稳定的水平。<br />
控制Full GC频率的关键是看应用中绝大多数对象能否符合&ldquo;朝生夕灭&rdquo;的原则，即大多数<br />
对象的生存时间不应太长，尤其是不能有成批量的、 长生存时间的大对象产生，这样才能保<br />
障老年代空间的稳定。<br />
在大多数网站形式的应用里，主要对象的生存周期都应该是请求级或者页面级的，会话<br />
级和全局级的长生命对象相对很少。 只要代码写得合理，应当都能实现在超大堆中正常使用<br />
而没有Full GC，这样的话，使用超大堆内存时，网站响应速度才会比较有保证。 除此之外，<br />
如果读者计划使用64位JDK来管理大内存，还需要考虑下面可能面临的问题：<br />
内存回收导致的长时间停顿。<br />
现阶段，64位JDK的性能测试结果普遍低于32位JDK。<br />
需要保证程序足够稳定，因为这种应用要是产生堆溢出几乎就无法产生堆转储快照（因<br />
为要产生十几GB乃至更大的Dump文件），哪怕产生了快照也几乎无法进行分析。<br />
相同程序在64位JDK消耗的内存一般比32位JDK大，这是由于指针膨胀，以及数据类型<br />
对齐补白等因素导致的。<br />
上面的问题听起来有点吓人，所以现阶段不少管理员还是选择第二种方式：使用若干个<br />
32位虚拟机建立逻辑集群来利用硬件资源。 具体做法是在一台物理机器上启动多个应用服务<br />
器进程，每个服务器进程分配不同端口，然后在前端搭建一个负载均衡器，以反向代理的方<br />
式来分配访问请求。 读者不需要太过在意均衡器转发所消耗的性能，即使使用64位JDK，许<br />
多应用也不止有一台服务器，因此在许多应用中前端的均衡器总是要存在的。<br />
考虑到在一台物理机器上建立逻辑集群的目的仅仅是为了尽可能利用硬件资源，并不需<br />
要关心状态保留、 热转移之类的高可用性需求，也不需要保证每个虚拟机进程有绝对准确的<br />
均衡负载，因此使用无Session复制的亲合式集群是一个相当不错的选择。 我们仅仅需要保障<br />
集群具备亲合性，也就是均衡器按一定的规则算法（一般根据SessionID分配）将一个固定的<br />
用户请求永远分配到固定的一个集群节点进行处理即可，这样程序开发阶段就基本不用为集<br />
群环境做什么特别的考虑了。<br />
当然，很少有没有缺点的方案，如果读者计划使用逻辑集群的方式来部署程序，可能会<br />
遇到下面一些问题：<br />
尽量避免节点竞争全局的资源，最典型的就是磁盘竞争，各个节点如果同时访问某个磁<br />
盘文件的话（尤其是并发写操作容易出现问题），很容易导致IO异常。<br />
很难最高效率地利用某些资源池，譬如连接池，一般都是在各个节点建立自己独立的连<br />
接池，这样有可能导致一些节点池满了而另外一些节点仍有较多空余。 尽管可以使用集中式<br />
的JNDI，但这个有一定复杂性并且可能带来额外的性能开销。<br />
各个节点仍然不可避免地受到32位的内存限制，在32位Windows平台中每个进程只能使<br />
用2GB的内存，考虑到堆以外的内存开销，堆一般最多只能开到1.5GB。 在某些Linux或UNIX<br />
系统（如Solaris）中，可以提升到3GB乃至接近4GB的内存，但32位中仍然受最高<br />
4GB（232）内存的限制。<br />
大量使用本地缓存（如大量使用HashMap作为K/V缓存）的应用，在逻辑集群中会造成<br />
较大的内存浪费，因为每个逻辑节点上都有一份缓存，这时候可以考虑把本地缓存改为集中<br />
式缓存。<br />
介绍完这两种部署方式，再重新回到这个案例之中，最后的部署方案调整为建立5个32<br />
位JDK的逻辑集群，每个进程按2GB内存计算（其中堆固定为1.5GB），占用了10GB内存。<br />
另外建立一个Apache服务作为前端均衡代理访问门户。 考虑到用户对响应速度比较关心，并<br />
且文档服务的主要压力集中在磁盘和内存访问，CPU资源敏感度较低，因此改为CMS收集器<br />
进行垃圾回收。 部署方式调整后，服务再没有出现长时间停顿，速度比硬件升级前有较大提<br />
升。<br />
5.2.2 集群间同步导致的内存溢出<br />
例如，有一个基于B/S的MIS系统，硬件为两台2个CPU、 8GB内存的HP小型机，服务器<br />
是WebLogic 9.2，每台机器启动了3个WebLogic实例，构成一个6个节点的亲合式集群。 由于<br />
是亲合式集群，节点之间没有进行Session同步，但是有一些需求要实现部分数据在各个节点<br />
间共享。 开始这些数据存放在数据库中，但由于读写频繁竞争很激烈，性能影响较大，后面<br />
使用JBossCache构建了一个全局缓存。 全局缓存启用后，服务正常使用了一段较长的时间，<br />
但最近却不定期地出现了多次的内存溢出问题。<br />
在内存溢出异常不出现的时候，服务内存回收状况一直正常，每次内存回收后都能恢复<br />
到一个稳定的可用空间，开始怀疑是程序某些不常用的代码路径中存在内存泄漏，但管理员<br />
反映最近程序并未更新、 升级过，也没有进行什么特别操作。 只好让服务带着-XX：<br />
+HeapDumpOnOutOfMemoryError参数运行了一段时间。 在最近一次溢出之后，管理员发回了<br />
heapdump文件，发现里面存在着大量的org.jgroups.protocols.pbcast.NAKACK对象。<br />
JBossCache是基于自家的JGroups进行集群间的数据通信，JGroups使用协议栈的方式来<br />
实现收发数据包的各种所需特性自由组合，数据包接收和发送时要经过每层协议栈的up（）<br />
和down（）方法，其中的NAKACK栈用于保障各个包的有效顺序及重发。 JBossCache协议栈<br />
如图5-1所示。<br />
图 5-1 JBossCache协议栈<br />
由于信息有传输失败需要重发的可能性，在确认所有注册在GMS（Group Membership<br />
Service）的节点都收到正确的信息前，发送的信息必须在内存中保留。 而此MIS的服务端中<br />
有一个负责安全校验的全局Filter，每当接收到请求时，均会更新一次最后操作时间，并且将<br />
这个时间同步到所有的节点去，使得一个用户在一段时间内不能在多台机器上登录。 在服务<br />
使用过程中，往往一个页面会产生数次乃至数十次的请求，因此这个过滤器导致集群各个节<br />
点之间网络交互非常频繁。 当网络情况不能满足传输要求时，重发数据在内存中不断堆积，<br />
很快就产生了内存溢出。<br />
这个案例中的问题，既有JBossCache的缺陷，也有MIS系统实现方式上缺陷。<br />
JBossCache官方的maillist中讨论过很多次类似的内存溢出异常问题，据说后续版本也有了改<br />
进。 而更重要的缺陷是这一类被集群共享的数据要使用类似JBossCache这种集群缓存来同步<br />
的话，可以允许读操作频繁，因为数据在本地内存有一份副本，读取的动作不会耗费多少资<br />
源，但不应当有过于频繁的写操作，那样会带来很大的网络同步的开销。<br />
5.2.3 堆外内存导致的溢出错误<br />
例如，一个学校的小型项目：基于B/S的电子考试系统，为了实现客户端能实时地从服<br />
务器端接收考试数据，系统使用了逆向AJAX技术（也称为Comet或者Server Side Push），选<br />
用CometD 1.1.1作为服务端推送框架，服务器是Jetty 7.1.4，硬件为一台普通PC机，Core i5<br />
CPU，4GB内存，运行32位Windows操作系统。<br />
测试期间发现服务端不定时抛出内存溢出异常，服务器不一定每次都会出现异常，但假<br />
如正式考试时崩溃一次，那估计整场电子考试都会乱套，网站管理员尝试过把堆开到最大，<br />
而32位系统最多到1.6GB就基本无法再加大了，而且开大了基本没效果，抛出内存溢出异常<br />
好像还更加频繁了。 加入-XX：+HeapDumpOnOutOfMemoryError，居然也没有任何反应，抛<br />
出内存溢出异常时什么文件都没有产生。 无奈之下只好挂着jstat并一直紧盯屏幕，发现GC并<br />
不频繁，Eden区、 Survivor区、 老年代以及永久代内存全部都表示&ldquo;情绪稳定，压力不大&rdquo;，<br />
但就是照样不停地抛出内存溢出异常，管理员压力很大。 最后，在内存溢出后从系统日志中<br />
找到异常堆栈，如代码清单5-1所示。<br />
代码清单5-1 异常堆栈<br />
[org.eclipse.jetty.util.log]handle failed java.lang.OutOfMemoryError：null<br />
at sun.misc.Unsafe.allocateMemory（Native Method）<br />
at java.nio.DirectByteBuffer.＜init＞（DirectByteBuffer.java：99）<br />
at java.nio.ByteBuffer.allocateDirect（ByteBuffer.java：288）<br />
at org.eclipse.jetty.io.nio.DirectNIOBuffer.＜init＞<br />
&hellip;&hellip;<br />
如果认真阅读过本书的第2章，看到异常堆栈就应该清楚这个抛出内存溢出异常是怎么<br />
回事了。 大家知道操作系统对每个进程能管理的内存是有限制的，这台服务器使用的32位<br />
Windows平台的限制是2GB，其中划了1.6GB给Java堆，而Direct Memory内存并不算入1.6GB<br />
的堆之内，因此它最大也只能在剩余的0.4GB空间中分出一部分。 在此应用中导致溢出的关<br />
键是：垃圾收集进行时，虚拟机虽然会对Direct Memory进行回收，但是Direct Memory却不能<br />
像新生代、 老年代那样，发现空间不足了就通知收集器进行垃圾回收，它只能等待老年代满<br />
了后Full GC，然后&ldquo;顺便地&rdquo;帮它清理掉内存的废弃对象。 否则它只能一直等到抛出内存溢出<br />
异常时，先catch掉，再在catch块里面&ldquo;大喊&rdquo;一声：&ldquo;System.gc（）！&rdquo;。 要是虚拟机还是不听<br />
（譬如打开了-XX：+DisableExplicitGC开关），那就只能眼睁睁地看着堆中还有许多空闲内<br />
存，自己却不得不抛出内存溢出异常了。 而本案例中使用的CometD 1.1.1框架，正好有大量<br />
的NIO操作需要使用到Direct Memory内存。<br />
从实践经验的角度出发，除了Java堆和永久代之外，我们注意到下面这些区域还会占用<br />
较多的内存，这里所有的内存总和受到操作系统进程最大内存的限制。<br />
Direct Memory：可通过-XX：MaxDirectMemorySize调整大小，内存不足时抛出<br />
OutOfMemoryError或者OutOfMemoryError：Direct buffer memory。<br />
线程堆栈：可通过-Xss调整大小，内存不足时抛出StackOverflowError（纵向无法分配，<br />
即无法分配新的栈帧）或者OutOfMemoryError：unable to create new native thread（横向无法<br />
分配，即无法建立新的线程）。<br />
Socket缓存区：每个Socket连接都Receive和Send两个缓存区，分别占大约37KB和25KB内<br />
存，连接多的话这块内存占用也比较可观。 如果无法分配，则可能会抛出IOException：Too<br />
many open files异常。<br />
JNI代码：如果代码中使用JNI调用本地库，那本地库使用的内存也不在堆中。<br />
虚拟机和GC：虚拟机、 GC的代码执行也要消耗一定的内存。<br />
5.2.4 外部命令导致系统缓慢<br />
这是一个来自网络的案例：一个数字校园应用系统，运行在一台4个CPU的Solaris 10操<br />
作系统上，中间件为GlassFish服务器。 系统在做大并发压力测试的时候，发现请求响应时间<br />
比较慢，通过操作系统的mpstat工具发现CPU使用率很高，并且系统占用绝大多数的CPU资<br />
源的程序并不是应用系统本身。 这是个不正常的现象，通常情况下用户应用的CPU占用率应<br />
该占主要地位，才能说明系统是正常工作的。<br />
通过Solaris 10的Dtrace脚本可以查看当前情况下哪些系统调用花费了最多的CPU资<br />
源，Dtrace运行后发现最消耗CPU资源的竟然是&ldquo;fork&rdquo;系统调用。 众所周知，&ldquo;fork&rdquo;系统调用<br />
是Linux用来产生新进程的，在Java虚拟机中，用户编写的Java代码最多只有线程的概念，不<br />
应当有进程的产生。<br />
这是个非常异常的现象。 通过本系统的开发人员，最终找到了答案：每个用户请求的处<br />
理都需要执行一个外部shell脚本来获得系统的一些信息。 执行这个shell脚本是通过Java的<br />
Runtime.getRuntime（）.exec（）方法来调用的。 这种调用方式可以达到目的，但是它在Java<br />
虚拟机中是非常消耗资源的操作，即使外部命令本身能很快执行完毕，频繁调用时创建进程<br />
的开销也非常可观。 Java虚拟机执行这个命令的过程是：首先克隆一个和当前虚拟机拥有一<br />
样环境变量的进程，再用这个新的进程去执行外部命令，最后再退出这个进程。 如果频繁执<br />
行这个操作，系统的消耗会很大，不仅是CPU，内存负担也很重。<br />
用户根据建议去掉这个Shell脚本执行的语句，改为使用Java的API去获取这些信息后，<br />
系统很快恢复了正常。<br />
5.2.5 服务器JVM进程崩溃<br />
例如，一个基于B/S的MIS系统，硬件为两台2个CPU、 8GB内存的HP系统，服务器是<br />
WebLogic 9.2（就是5.2.2节中的那套系统）。 正常运行一段时间后，最近发现在运行期间频<br />
繁出现集群节点的虚拟机进程自动关闭的现象，留下了一个hs_err_pid###.log文件后，进程<br />
就消失了，两台物理机器里的每个节点都出现过进程崩溃的现象。 从系统日志中可以看出，<br />
每个节点的虚拟机进程在崩溃前不久，都发生过大量相同的异常，见代码清单5-2。<br />
代码清单5-2 异常堆栈2<br />
java.net.SocketException：Connection reset<br />
at java.net.SocketInputStream.read（SocketInputStream.java：168）<br />
at java.io.BufferedInputStream.fill（BufferedInputStream.java：218）<br />
at java.io.BufferedInputStream.read（BufferedInputStream.java：235）<br />
at org.apache.axis.transport.http.HTTPSender.readHeadersFromSocket（HTTPSender.java：583）<br />
at org.apache.axis.transport.http.HTTPSender.invoke（HTTPSender.java：143）&hellip;&hellip;99 more<br />
这是一个远端断开连接的异常，通过系统管理员了解到系统最近与一个OA门户做了集<br />
成，在MIS系统工作流的待办事项变化时，要通过Web服务通知OA门户系统，把待办事项的<br />
变化同步到OA门户之中。 通过SoapUI测试了一下同步待办事项的几个Web服务，发现调用后<br />
竟然需要长达3分钟才能返回，并且返回结果都是连接中断。<br />
由于MIS系统的用户多，待办事项变化很快，为了不被OA系统速度拖累，使用了异步的<br />
方式调用Web服务，但由于两边服务速度的完全不对等，时间越长就累积了越多Web服务没<br />
有调用完成，导致在等待的线程和Socket连接越来越多，最终在超过虚拟机的承受能力后使<br />
得虚拟机进程崩溃。 解决方法：通知OA门户方修复无法使用的集成接口，并将异步调用改<br />
为生产者/消费者模式的消息队列实现后，系统恢复正常。<br />
5.2.6 不恰当数据结构导致内存占用过大<br />
例如，有一个后台RPC服务器，使用64位虚拟机，内存配置为-Xms4g-Xmx8g-Xmn1g，<br />
使用ParNew+CMS的收集器组合。 平时对外服务的Minor GC时间约在30毫秒以内，完全可以<br />
接受。 但业务上需要每10分钟加载一个约80MB的数据文件到内存进行数据分析，这些数据<br />
会在内存中形成超过100万个HashMap＜Long,Long＞Entry，在这段时间里面Minor GC就会造<br />
成超过500毫秒的停顿，对于这个停顿时间就接受不了了，具体情况如下面GC日志所示。<br />
{Heap before GC invocations=95（full 4）：<br />
par new generation total 903168K,used 803142K[0x00002aaaae770000，0x00002aaaebb70000，0x00002aaaebb70000）<br />
eden space 802816K，100%used[0x00002aaaae770000，0x00002aaadf770000，0x00002aaadf770000）<br />
from space 100352K，0%used[0x00002aaae5970000，0x00002aaae59c1910，0x00002aaaebb70000）<br />
to space 100352K，0%used[0x00002aaadf770000，0x00002aaadf770000，0x00002aaae5970000）<br />
concurrent mark-sweep generation total 5845540K,used 3898978K[0x00002aaaebb70000，0x00002aac507f9000，0x00002aacae770000）<br />
concurrent-mark-sweep perm gen total 65536K,used 40333K[0x00002aacae770000，0x00002aacb2770000，0x00002aacb2770000）<br />
2 0 1 1-1 0-2 8 T 1 1：4 0：4 5.1 6 2+0 8 0 0：2 2 6.5 0 4：[G C 2 2 6.5 0 4：[P a r N e w：803142K-＞100352K（903168K），0.5995670 secs]4702120K-＞<br />
4056332K（6748708K），0.5997560<br />
secs][Times：user=1.46 sys=0.04，real=0.60 secs]<br />
Heap after GC invocations=96（full 4）：<br />
par new generation total 903168K,used 100352K[0x00002aaaae770000，0x00002aaaebb70000，0x00002aaaebb70000）<br />
eden space 802816K，0%used[0x00002aaaae770000，0x00002aaaae770000，0x00002aaadf770000）<br />
from space 100352K，100%used[0x00002aaadf770000，0x00002aaae5970000，<br />
0x00002aaae5970000）<br />
to space 100352K，0x00002aaaebb70000）0%used[0x00002aaae5970000，0x00002aaae5970000，<br />
concurrent mark-sweep generation total 5845540K,used 3955980K[0x00002aaaebb70000，0x00002aac507f9000，0x00002aacae770000）<br />
concurrent-mark-sweep perm gen total 65536K,used 40333K[0x00002aacae770000，0x00002aacb2770000，0x00002aacb2770000）<br />
}T<br />
otal time for which application threads were stopped：0.6070570 seconds<br />
观察这个案例，发现平时的Minor GC时间很短，原因是新生代的绝大部分对象都是可清<br />
除的，在Minor GC之后Eden和Survivor基本上处于完全空闲的状态。 而在分析数据文件期<br />
间，800MB的Eden空间很快被填满从而引发GC，但Minor GC之后，新生代中绝大部分对象<br />
依然是存活的。 我们知道ParNew收集器使用的是复制算法，这个算法的高效是建立在大部<br />
分对象都&ldquo;朝生夕灭&rdquo;的特性上的，如果存活对象过多，把这些对象复制到Survivor并维持这<br />
些对象引用的正确就成为一个沉重的负担，因此导致GC暂停时间明显变长。<br />
如果不修改程序，仅从GC调优的角度去解决这个问题，可以考虑将Survivor空间去掉<br />
（加入参数-XX：SurvivorRatio=65536、 -XX：MaxTenuringThreshold=0或者-XX：<br />
+AlwaysTenure），让新生代中存活的对象在第一次Minor GC后立即进入老年代，等到Major<br />
GC的时候再清理它们。 这种措施可以治标，但也有很大副作用，治本的方案需要修改程<br />
序，因为这里的问题产生的根本原因是用HashMap＜Long,Long＞结构来存储数据文件空间效<br />
率太低。<br />
下面具体分析一下空间效率。 在HashMap＜Long,Long＞结构中，只有Key和Value所存放<br />
的两个长整型数据是有效数据，共16B（2&times;8B）。 这两个长整型数据包装成java.lang.Long对<br />
象之后，就分别具有8B的MarkWord、 8B的Klass指针，在加8B存储数据的long值。 在这两个<br />
Long对象组成Map.Entry之后，又多了16B的对象头，然后一个8B的next字段和4B的int型的<br />
hash字段，为了对齐，还必须添加4B的空白填充，最后还有HashMap中对这个Entry的8B的引<br />
用，这样增加两个长整型数字，实际耗费的内存为<br />
（Long（24B）&times;2）+Entry（32B）+HashMap Ref（8B）=88B，空间效率为16B/88B=18%，<br />
实在太低了。<br />
5.2.7 由Windows虚拟内存导致的长时间停顿[1]<br />
例如，有一个带心跳检测功能的GUI桌面程序，每15秒会发送一次心跳检测信号，如果<br />
对方30秒以内都没有信号返回，那就认为和对方程序的连接已经断开。 程序上线后发现心跳<br />
检测有误报的概率，查询日志发现误报的原因是程序会偶尔出现间隔约一分钟左右的时间完<br />
全无日志输出，处于停顿状态。<br />
因为是桌面程序，所需的内存并不大（-Xmx256m），所以开始并没有想到是GC导致的<br />
程序停顿，但是加入参数-XX：+PrintGCApplicationStoppedTime-XX：+PrintGCDateStampsXloggc：gclog.log后，从GC日志文件中确认了停顿确实是由GC导致的，大部分GC时间都控<br />
制在100毫秒以内，但偶尔就会出现一次接近1分钟的GC。<br />
Total time for which application threads were stopped：0.0112389 seconds<br />
Total time for which application threads were stopped：0.0001335 seconds<br />
Total time for which application threads were stopped：0.0003246 seconds<br />
Total time for which application threads were stopped：41.4731411 seconds<br />
Total time for which application threads were stopped：0.0489481 seconds<br />
Total time for which application threads were stopped：0.1110761 seconds<br />
Total time for which application threads were stopped：0.0007286 seconds<br />
Total time for which application threads were stopped：0.0001268 seconds<br />
从GC日志中找到长时间停顿的具体日志信息（添加了-XX：+PrintReferenceGC参数），<br />
找到的日志片段如下所示。 从日志中可以看出，真正执行GC动作的时间不是很长，但从准<br />
备开始GC，到真正开始GC之间所消耗的时间却占了绝大部分。<br />
2012-08-29T19：14：30.968+0800：10069.800：[GC10099.225：[SoftReference，0 refs，0.0000109 secs]10099.226：[WeakReference，4072 refs，0.0012099<br />
secs]10099.227：[FinalReference，984 refs，1.5822450 secs]10100.809：[PhantomReference，251 refs，0.0001394 secs]10100.809：[JNI Weak Reference，0.0994015 secs]<br />
[PSYoungGen：175672K-＞8528K（167360K）]251523K-＞100182K（353152K），31.1580402 secs][Times：user=0.61 sys=0.52，real=31.16 secs]<br />
除GC日志之外，还观察到这个GUI程序内存变化的一个特点，当它最小化的时候，资源<br />
管理中显示的占用内存大幅度减小，但是虚拟内存则没有变化，因此怀疑程序在最小化时它<br />
的工作内存被自动交换到磁盘的页面文件之中了，这样发生GC时就有可能因为恢复页面文<br />
件的操作而导致不正常的GC停顿。<br />
在MSDN上查证[2]后确认了这种猜想，因此，在Java的GUI程序中要避免这种现象，可以<br />
加入参数&ldquo;-Dsun.awt.keepWorkingSetOnMinimize=true&rdquo;来解决。 这个参数在许多AWT的程序上<br />
都有应用，例如JDK自带的Visual VM，用于保证程序在恢复最小化时能够立即响应。 在这个<br />
案例中加入该参数后，问题得到解决。<br />
[1]本案例来源于HLLVM组群的讨论：http://hllvm.group.iteye.com/group/topic/28745。<br />
[2]http://support.microsoft.com/default.aspx?scid=kb；en-us；293215。<br />
5.3 实战：Eclipse运行速度调优<br />
很多Java开发人员都有这样一种观念：系统调优的工作都是针对服务端应用而言，规模<br />
越大的系统，就越需要专业的调优运维团队参与。 这个观点不能说不对，5.2节中笔者所列<br />
举的案例确实都是服务端运维、 调优的例子，但服务端应用需要调优，并不说明其他应用就<br />
不需要了，作为一个普通的Java开发人员，前面讲的各种虚拟机的原理和最佳实践方法距离<br />
我们并不遥远，开发者身边很多场景都可以使用上面这些知识。 下面通过一个普通程序员日<br />
常工作中可以随时接触到的开发工具开始这次实战。<br />
5.3.1 调优前的程序运行状态<br />
笔者使用Eclipse作为日常工作中的主要IDE工具，由于安装的插件比较大（如<br />
Klocwork、 ClearCase LT等）、 代码也很多，启动Eclipse直到所有项目编译完成需要四五分<br />
钟。 一直对开发环境的速度感觉不满意，趁着编写这本书的机会，决定对Eclipse进行&ldquo;动<br />
刀&rdquo;调优。<br />
笔者机器的Eclipse运行平台是32位Windows 7系统，虚拟机为HotSpot VM 1.5 b64。 硬件<br />
为ThinkPad X201，Intel i5 CPU，4GB物理内存。 在初始的配置文件eclipse.ini中，除了指定<br />
JDK的路径、 设置最大堆为512MB以及开启了JMX管理（需要在VisualVM中收集原始数据）<br />
外，未做其他任何改动，原始配置内容如代码清单5-3所示。<br />
代码清单5-3 Eclipse 3.5初始配置<br />
-vm<br />
D：/_DevSpace/jdk1.5.0/bin/javaw.exe<br />
-startup<br />
plugins/org.eclipse.equinox.launcher_1.0.201.R35x_v20090715.jar<br />
--launcher.library<br />
plugins/org.eclipse.equinox.launcher.win32.win32.x86_1.0.200.v20090519<br />
-product<br />
org.eclipse.epp.package.jee.product<br />
--launcher.XXMaxPermSize<br />
256M<br />
-showsplash<br />
org.eclipse.platform<br />
-vmargs<br />
-Dosgi.requiredJavaVersion=1.5<br />
-Xmx512m<br />
-Dcom.sun.management.jmxremote<br />
为了要与调优后的结果进行量化对比，调优开始前笔者先做了一次初始数据测试。 测试<br />
用例很简单，就是收集从Eclipse启动开始，直到所有插件加载完成为止的总耗时以及运行状<br />
态数据，虚拟机的运行数据通过VisualVM及其扩展插件VisualGC进行采集。 测试过程中反复<br />
启动数次Eclipse直到测试结果稳定后，取最后一次运行的结果作为数据样本（为了避免操作<br />
系统未能及时进行磁盘缓存而产生的影响），数据样本如图5-2所示。<br />
图 5-2 Eclipse原始运行数据<br />
Eclipse启动的总耗时没有办法从监控工具中直接获得，因为VisualVM不可能知道Eclipse<br />
运行到什么阶段算是启动完成。 为了测试的准确性，笔者写了一个简单的Eclipse插件，用于<br />
统计Eclipse的启动耗时。 由于代码很简单，并且本书不是Eclipse RCP开发的教程，所以只列<br />
出代码清单5-4供读者参考，不再延伸讲解。 如果读者需要这个插件，可以使用下面代码自<br />
行编译或者发电子邮件向笔者索取。<br />
代码清单5-4 Eclipse启动耗时统计插件<br />
ShowTime.java代码：<br />
import org.eclipse.jface.dialogs.MessageDialog；<br />
import org.eclipse.swt.widgets.Display；<br />
import org.eclipse.swt.widgets.Shell；<br />
import org.eclipse.ui.IStartup；<br />
/**<br />
*统计Eclipse启动耗时<br />
*@author zzm<br />
*/<br />
public class ShowTime implements IStartup{<br />
public void earlyStartup（）{<br />
Display.getDefault（）.syncExec（new Runnable（）{<br />
public void run（）{<br />
long eclipseStartTime=Long.parseLong（System.getProperty（&quot;eclipse.startTime&quot;））；<br />
long costTime=System.currentTimeMillis（）-eclipseStartTime；<br />
Shell shell=Display.getDefault（）.getActiveShell（）；<br />
String message=&quot;Eclipse启动耗时：&quot;+costTime+&quot;ms&quot;；<br />
MessageDialog.openInformation（shell，&quot;Information&quot;，message）；<br />
}}<br />
）；<br />
}}p<br />
lugin.xml代码：<br />
＜?xml version=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?＞<br />
＜?eclipse version=&quot;3.4&quot;?＞<br />
＜plugin＞<br />
＜extension<br />
point=&quot;org.eclipse.ui.startup&quot;＞<br />
＜startup class=&quot;eclipsestarttime.actions.ShowTime&quot;/＞<br />
＜/extension＞<br />
＜/plugin＞<br />
上述代码打包成jar后放到Eclipse的plugins目录，反复启动几次后，插件显示的平均时间<br />
稳定在15秒左右，如图5-3所示。<br />
图 5-3 耗时统计插件运行效果<br />
根据VisualGC和Eclipse插件收集到的信息，总结原始配置下的测试结果如下。<br />
整个启动过程平均耗时约15秒。<br />
最后一次启动的数据样本中，垃圾收集总耗时4.149秒，其中：<br />
●Full GC被触发了19次，共耗时3.166秒。<br />
●Minor GC被触发了378次，共耗时0.983秒。<br />
加载类9115个，耗时4.114秒。<br />
JIT编译时间为1.999秒。<br />
虚拟机512MB的堆内存被分配为40MB的新生代（31.5的Eden空间和两个4MB的Surviver<br />
空间）以及472MB的老年代。<br />
客观地说，由于机器硬件还不错（请读者以2010年普通PC机的标准来衡量），15秒的启<br />
动时间其实还在可接受范围以内，但是从VisualGC中反映的数据来看，主要问题是非用户程<br />
序时间（图5-2中的Compile Time、 Class Load Time、 GC Time）非常之高，占了整个启动过<br />
程耗时的一半以上（这里存在少许夸张成分，因为如JIT编译等动作是在后台线程完成的，<br />
用户程序在此期间也正常执行，所以并没有占用了一半以上的绝对时间）。 虚拟机后台占用<br />
太多时间也直接导致Eclipse在启动后的使用过程中经常有不时停顿的感觉，所以进行调优有<br />
较大的价值。<br />
5.3.2 升级JDK 1.6的性能变化及兼容问题<br />
对Eclipse进行调优的第一步就是先把虚拟机的版本进行升级，希望能先从虚拟机版本身<br />
上得到一些&ldquo;免费的&rdquo;性能提升。<br />
每次JDK的大版本发布时，开发商肯定都会宣称虚拟机的运行速度比上一版本有了很大<br />
的提高，这虽然是个广告性质的宣言，经常被人从升级列表或者技术白皮书中直接忽略过<br />
去，但从国内外的第三方评测数据来看，版本升级至少某些方面确实带来了一定的性能改<br />
善[1]，以下是一个第三方网站对JDK 1.5、 1.6、 1.7三个版本做的性能评测，分别测试了以下4<br />
个用例[2]：<br />
生成500万个的字符串。<br />
500万次ArrayList＜String＞数据插入，使用第一点生成的数据。<br />
生成500万个HashMap＜String,Integer＞，每个键-值对通过并发线程计算，测试并发能<br />
力。<br />
打印500万个ArrayList＜String＞中的值到文件，并重读回内存。<br />
三个版本的JDK分别运行这3个用例的测试程序，测试结果如图5-4所示。<br />
图 5-4 JDK横向性能对比<br />
从这4个用例的测试结果来看，JDK 1.6比JDK 1.5有大约15%的性能提升，尽管对JDK仅<br />
测试这4个用例并不能说明什么问题，需要通过测试数据来量化描述一个JDK比旧版提升了<br />
多少是很难做到非常科学和准确的（要做稍微靠谱一点的测试，可以使用SPECjvm2008[3]来<br />
完成，或者把相应版本的TCK[4]中数万个测试用例的性能数据对比一下可能更有说服力），<br />
但我还是选择相信这次&ldquo;软广告&rdquo;性质的测试，把JDK版本升级到1.6 Update 21。<br />
与所有小说作者设计的故事情节一样，获得最后的胜利之前总是要经历各种各样的挫<br />
折，这次升级到JDK 1.6之后，性能有什么变化先暂且不谈，在使用几分钟之后，笔者的<br />
Eclipse就和前面几个服务端的案例一样非常&ldquo;不负众望&rdquo;地发生了内存溢出，如图5-5所示。<br />
图 5-5 Eclipse OutOfMemoryError<br />
这次内存溢出完全出乎笔者的意料之外：决定对Eclipse做调优是因为速度慢，但开发环<br />
境一直都很稳定，至少没有出现过内存溢出的问题，而这次升级除了eclipse.ini中的JVM路径<br />
改变了之外，还未进行任何运行参数的调整，进到Eclipse主界面之后随便打开了几个文件就<br />
抛出内存溢出异常了，难道JDK 1.6 Update 21有哪个API出现了严重的泄漏问题吗？<br />
事实上，并不是JDK 1.6出现了什么问题，根据前面章节中介绍的相关原理和工具，我<br />
们要查明这个异常的原因并且解决它一点也不困难。 打开VisualVM，监视页签中的内存曲线<br />
部分如图5-6和图5-7所示。<br />
图 5-6 Java堆监视曲线<br />
图 5-7 永久代监视曲线<br />
在Java堆中监视曲线中，&ldquo;堆大小&rdquo;的曲线与&ldquo;使用的堆&rdquo;的曲线一直都有很大的间隔距<br />
离，每当两条曲线开始有互相靠近的趋势时，&ldquo;最大堆&rdquo;的曲线就会快速向上转向，而&ldquo;使用<br />
的堆&rdquo;的曲线会向下转向。 &ldquo;最大堆&rdquo;的曲线向上是虚拟机内部在进行堆扩容，运行参数中并<br />
没有指定最小堆（-Xms）的值与最大堆（-Xmx）相等，所以堆容量一开始并没有扩展到最<br />
大值，而是根据使用情况进行伸缩扩展。 &ldquo;使用的堆&rdquo;的曲线向下是因为虚拟机内部触发了一<br />
次垃圾收集，一些废弃对象的空间被回收后，内存用量相应减少，从图形上看，Java堆运作<br />
是完全正常的。 但永久代的监视曲线就有问题了，&ldquo;PermGen大小&rdquo;的曲线与&ldquo;使用的<br />
PermGen&rdquo;的曲线几乎完全重合在一起，这说明永久代中没有可回收的资源，所以&ldquo;使用的<br />
PermGen&rdquo;的曲线不会向下发展，永久代中也没有空间可以扩展，所以&ldquo;PermGen大小&rdquo;的曲线<br />
不能向上扩展。 这次内存溢出很明显是永久代导致的内存溢出。<br />
再注意到图5-7中永久代的最大容量：&ldquo;67，108，864个字节&rdquo;，也就是64MB，这恰好是<br />
JDK在未使用-XX：MaxPermSize参数明确指定永久代最大容量时的默认值，无论JDK 1.5还<br />
是JDK 1.6，这个默认值都是64MB。 对于Eclipse这种规模的Java程序来说，64MB的永久代内<br />
存空间显然是不够的，溢出很正常，那为何在JDK 1.5中没有发生过溢出呢？<br />
在VisualVM的&ldquo;概述-JVM参数&rdquo;页签中，分别检查使用JDK 1.5和JDK 1.6运行Eclipse时的<br />
JVM参数，发现使用JDK 1.6时，只有以下3个JVM参数，如代码清单5-5所示。<br />
代码清单5-5 JDK 1.6的Eclipse运行期参数<br />
-Dcom.sun.management.jmxremote<br />
-Dosgi.requiredJavaVersion=1.5<br />
-Xmx512m<br />
而使用JDK 1.5运行时，就有4条JVM参数，其中多出来的一条正好就是设置永久代最大<br />
容量的-XX：MaxPermSize=256M，如代码清单5-6所示。<br />
代码清单5-6 JDK 1.5的Eclipse运行期参数<br />
-Dcom.sun.management.jmxremote<br />
-Dosgi.requiredJavaVersion=1.5<br />
-Xmx512m<br />
-XX：MaxPermSize=256M<br />
为什么会这样呢？笔者从Eclipse的Bug List网站[5]上找到了答案：使用JDK 1.5时之所以有<br />
永久代容量这个参数，是因为在eclipse.ini中存在&ldquo;--launcher.XXMaxPermSize 256M&rdquo;这项设<br />
置，当launcher&mdash;&mdash;也就是Windows下的可执行程序eclipse.exe，检测到假如是Eclipse运行在<br />
Sun公司的虚拟机上的话，就会把参数值转化为-XX：MaxPermSize传递给虚拟机进程，因为<br />
三大商用虚拟机中只有Sun系列的虚拟机才有永久代的概念，也就是只有HotSpot虚拟机需要<br />
设置这个参数，JRockit虚拟机和IBM J9虚拟机都不需要设置。<br />
在2009年4月20日，Oracle公司正式完成了对Sun公司的收购，此后无论是网页还是具体<br />
程序产品，提供商都从Sun变为了Oracle，而eclipse.exe就是根据程序提供商判断是否为Sun的<br />
虚拟机，当JDK 1.6 Update 21中java.exe、 javaw.exe的&ldquo;Company&rdquo;属性从&ldquo;Sun Microsystems<br />
Inc.&rdquo;变为&ldquo;Oracle Corporation&rdquo;之后，Eclipse就完全不认识这个虚拟机了，因此没有把最大永<br />
久代的参数传递过去。<br />
了解原因之后，解决方法就简单了，launcher不认识就只好由人来告诉它，即在<br />
eclipse.ini中明确指定-XX：MaxPermSize=256M这个参数就可以了。<br />
[1]版本升级也有不少性能倒退的案例，受程序、 第三方包兼容性以及中间件限制，在企业应<br />
用中升级JDK版本是一件需要慎重考虑的事情。<br />
[2]测试用例、 数据及图片来自：http://geeknizer.com/java-7-whats-new-performance-benchmark-<br />
1-5-1-6-1-7<br />
[3]官方网站：http://www.spec.org/jvm2008/docs/UserGuide.html。<br />
[4]TCK（Technology Compatibility Kit）是一套由一组测试用例和相应的测试工具组成的工具<br />
包，用于保证一个使用Java技术的实现能够完全遵守其适用的Java平台规范，并且符合相应<br />
的参考实现。<br />
[5]https://bugs.eclipse.org/bugs/show_bug.cgi?id=319514。<br />
5.3.3 编译时间和类加载时间的优化<br />
从Eclipse启动时间上来看，升级到JDK 1.6所带来的性能提升是&hellip;&hellip;嗯？基本上没有提<br />
升？多次测试的平均值与JDK 1.5的差距完全在实验误差范围之内。<br />
各位读者不必失望，Sun JDK 1.6性能白皮书[1]描述的众多相对于JDK 1.5的提升不至于全<br />
部是广告，虽然总启动时间没有减少，但在查看运行细节的时候，却发现了一件很值得注意<br />
的事情：在JDK 1.6中启动完Eclipse所消耗的类加载时间比JDK 1.5长了接近一倍，不要看反<br />
了，这里写的是JDK 1.6的类加载比JDK 1.5慢一倍，测试结果如代码清单5-7所示，反复测试<br />
多次仍然是相似的结果。<br />
代码清单5-7 JDK 1.5和JDK 1.6中的类加载时间对比<br />
使用JDK 1.6的类加载时间：<br />
C：\Users\IcyFenix＞jps<br />
3552<br />
6372 org.eclipse.equinox.launcher_1.0.201.R35x_v20090715.jar<br />
6900 Jps<br />
C：\Users\IcyFenix＞jstat-class 6372<br />
Loaded Bytes Unloaded Bytes Time<br />
7917 10190.3 0 0.0 8.18<br />
使用JDK 1.5的类加载时间：<br />
C：\Users\IcyFenix＞jps<br />
3552<br />
7272 Jps<br />
7216 org.eclipse.equinox.launcher_1.0.201.R35x_v20090715.jar<br />
C：\Users\IcyFenix＞jstat-class 7216<br />
Loaded Bytes Unloaded Bytes Time<br />
7902 9691.2 3 2.6 4.34<br />
在本例中，类加载时间上的差距并不能作为一个具有普遍性的测试结果去说明JDK 1.6<br />
的类加载必然比JDK 1.5慢，笔者测试了自己机器上的Tomcat和GlassFish启动过程，并未没有<br />
出现类似的差距。 在国内最大的Java社区中，笔者发起过关于此问题的讨论[2]，从参与者反<br />
馈的测试结果来看，此问题只在一部分机器上存在，而且JDK 1.6的各个Update版之间也存在<br />
很大差异。<br />
多次试验后，笔者发现在机器上两个JDK进行类加载时，字节码验证部分耗时差距尤其<br />
严重。 考虑到实际情况：Eclipse使用者甚多，它的编译代码我们可以认为是可靠的，不需要<br />
在加载的时候再进行字节码验证，因此通过参数-Xverify：none禁止掉字节码验证过程也可<br />
作为一项优化措施。 加入这个参数后，两个版本的JDK类加载速度都有所提高，JDK 1.6的类<br />
加载速度仍然比JDK 1.5慢，但是两者的耗时已经接近了许多，测试数据如代码清单5-8所<br />
示。 关于类与类加载的话题，譬如刚刚提到的字节码验证是怎么回事，本书专门规划了两个<br />
章节进行详细讲解，在此不再延伸讨论。<br />
代码清单5-8 JDK 1.5和JDK 1.6中取消字节码验证后的类加载时间对比<br />
使用JDK 1.6的类加载时间：<br />
C：\Users\IcyFenix＞jps<br />
5512 org.eclipse.equinox.launcher_1.0.201.R35x_v20090715.jar<br />
5596 Jps<br />
C：\Users\IcyFenix＞jstat-class 5512<br />
Loaded Bytes Unloaded Bytes Time<br />
6749 8837.0 0 0.0 3.94<br />
使用JDK 1.5的类加载时间：<br />
C：\Users\IcyFenix＞jps<br />
4724 org.eclipse.equinox.launcher_1.0.201.R35x_v20090715.jar<br />
5412 Jps<br />
C：\Users\IcyFenix＞jstat-class 4724<br />
Loaded Bytes Unloaded Bytes Time<br />
6885 9109.7 3 2.6 3.10<br />
在取消字节码验证之后，JDK 1.5的平均启动下降到了13秒，而JDK 1.6的测试数据平均<br />
比JDK 1.5快1秒，下降到平均12秒左右，如图5-8所示。 在类加载时间仍然落后的情况下，依<br />
然可以看到JDK 1.6在性能上比JDK 1.5稍有优势，说明至少在Eclipse启动这个测试用例上，<br />
升级JDK版本确实能带来一些&ldquo;免费的&rdquo;性能提升。<br />
图 5-8 运行在JDK 1.6下取消字节码验证的启动时间<br />
前面说过，除了类加载时间以外，在VisualGC的监视曲线中显示了两项很大的非用户程<br />
序耗时：编译时间（Compile Time）和垃圾收集时间（GC Time）。 垃圾收集时间读者应该<br />
非常清楚了，而编译时间是什么呢？程序在运行之前不是已经编译了吗？虚拟机的JIT编译<br />
与垃圾收集一样，是本书的一个重要部分，后面有专门章节讲解，这里先简单介绍一下：编<br />
译时间是指虚拟机的JIT编译器（Just In Time Compiler）编译热点代码（Hot Spot Code）的耗<br />
时。 我们知道Java语言为了实现跨平台的特性，Java代码编译出来后形成的Class文件中存储<br />
的是字节码（ByteCode），虚拟机通过解释方式执行字节码命令，比起C/C++编译成本地二<br />
进制代码来说，速度要慢不少。 为了解决程序解释执行的速度问题，JDK 1.2以后，虚拟机<br />
内置了两个运行时编译器[3]，如果一段Java方法被调用次数达到一定程度，就会被判定为热<br />
代码交给JIT编译器即时编译为本地代码，提高运行速度（这就是HotSpot虚拟机名字的由<br />
来）。 甚至有可能在运行期动态编译比C/C++的编译期静态译编出来的代码更优秀，因为运<br />
行期可以收集很多编译器无法知道的信息，甚至可以采用一些很激进的优化手段，在优化条<br />
件不成立的时候再逆优化退回来。 所以Java程序只要代码没有问题（主要是泄漏问题，如内<br />
存泄漏、 连接泄漏），随着代码被编译得越来越彻底，运行速度应当是越运行越快的。 Java<br />
的运行期编译最大的缺点就是它进行编译需要消耗程序正常的运行时间，这也就是上面所说<br />
的&ldquo;编译时间&rdquo;。<br />
虚拟机提供了一个参数-Xint禁止编译器运作，强制虚拟机对字节码采用纯解释方式执<br />
行。 如果读者想使用这个参数省下Eclipse启动中那2秒的编译时间获得一个&ldquo;更好看&rdquo;的成绩<br />
的话，那恐怕要失望了，加上这个参数之后，虽然编译时间确实下降到0，但Eclipse启动的<br />
总时间剧增到27秒。 看来这个参数现在最大的作用似乎就是让用户怀念一下JDK 1.2之前那<br />
令人心酸和心碎的运行速度。<br />
与解释执行相对应的另一方面，虚拟机还有力度更强的编译器：当虚拟机运行在-client<br />
模式的时候，使用的是一个代号为C1的轻量级编译器，另外还有一个代号为C2的相对重量<br />
级的编译器能提供更多的优化措施，如果使用-server模式的虚拟机启动Eclipse将会使用到C2<br />
编译器，这时从VisualGC可以看到启动过程中虚拟机使用了超过15秒的时间去进行代码编<br />
译。 如果读者的工作习惯是长时间不关闭Eclipse的话，C2编译器所消耗的额外编译时间最终<br />
还是会在运行速度的提升之中赚回来，这样使用-server模式也是一个不错的选择。 不过至少<br />
在本次实战中，我们还是继续选用-client虚拟机来运行Eclipse。<br />
[1]http://www.oracle.com/technetwork/java/6-performance-137236.html。<br />
[2]关于JDK 1.6与JDK 1.5在Eclipse启动时类加载速度差异的讨论：<br />
http://www.iteye.com/topic/826542。<br />
[3]JDK 1.2之前也可以使用外挂JIT编译器进行本地编译，但只能与解释器二选其一，不能同<br />
时工作。<br />
5.3.4 调整内存设置控制垃圾收集频率<br />
三大块非用户程序时间中，还剩下GC时间没有调整，而GC时间却又是其中最重要的一<br />
块，并不只是因为它是耗时最长的一块，更因为它是一个稳定持续的过程。 由于我们做的测<br />
试是在测程序的启动时间，所以类加载和编译时间在这项测试中的影响力被大幅度放大了。<br />
在绝大多数的应用中，不可能出现持续不断的类被加载和卸载。 在程序运行一段时间后，热<br />
点方法被不断编译，新的热点方法数量也总会下降，但是垃圾收集则是随着程序运行而不断<br />
运作的，所以它对性能的影响才显得尤为重要。<br />
在Eclipse启动的原始数据样本中，短短15秒，类共发生了19次Full GC和378次Minor<br />
GC，一共397次GC共造成了超过4秒的停顿，也就是超过1/4的时间都是在做垃圾收集，这个<br />
运行数据看起来实在太糟糕了。<br />
首先来解决新生代中的Minor GC，虽然GC的总时间只有不到1秒，但却发生了378次之<br />
多。 从VisualGC的线程监视中看到，Eclipse启动期间一共发起了超过70条线程，同时在运行<br />
的线程数超过25条，每当发生一次垃圾收集动作，所有用户线程[1]都必须跑到最近的一个安<br />
全点（SafePoint）然后挂起线程等待垃圾回收。 这样过于频繁的GC就会导致很多没有必要的<br />
安全点检测、 线程挂起及恢复操作。<br />
新生代GC频繁发生，很明显是由于虚拟机分配给新生代的空间太小而导致的，Eden区<br />
加上一个Survivor区还不到35MB。 因此很有必要使用-Xmn参数调整新生代的大小。<br />
再来看一看那19次Full GC，看起来19次并&ldquo;不多&rdquo;（相对于378次Minor GC来说），但总<br />
耗时为3.166秒，占了GC时间的绝大部分，降低GC时间的主要目标就要降低这部分时间。 从<br />
VisualGC的曲线图上可能看得不够精确，这次直接从GC日志[2]中分析一下这些Full GC是如何<br />
产生的，代码清单5-9中是启动最开始的2.5秒内发生的10次Full GC记录。<br />
代码清单5-9 Full GC记录<br />
0.278：[GC 0.278：[DefNew：574K-＞33K（576K），0.0012562 secs]0.279：[Tenured：1467K-＞997K（1536K），0.0181775 secs]1920K-＞997K（2112K），0.0195257 secs]<br />
0.312：[GC 0.312：[DefNew：575K-＞64K（576K），0.0004974 secs]0.312：[Tenured：1544K-＞1608K（1664K），0.0191592 secs]1980K-＞1608K（2240K），0.0197396 secs]<br />
0.590：[GC 0.590：[DefNew：576K-＞64K（576K），0.0006360 secs]0.590：[Tenured：2675K-＞2219K（2684K），0.0256020 secs]3090K-＞2219K（3260K），0.0263501 secs]<br />
0.958：[GC 0.958：[DefNew：551K-＞64K（576K），0.0011433 secs]0.959：[Tenured：3979K-＞3470K（4084K），0.0419335 secs]4222K-＞3470K（4660K），0.0431992 secs]<br />
1.575：[Full GC 1.575：[Tenured：4800K-＞5046K（5784K），0.0543136 secs]5189K-＞5046K（6360K），[Perm：12287K-＞12287K（12288K）]，0.0544163 secs]<br />
1.703：[GC 1.703：[DefNew：703K-＞63K（704K），0.0012609 secs]1.705：[Tenured：8441K-＞8505K（8540K），0.0607638 secs]8691K-＞8505K（9244K），0.0621470 secs]<br />
1.837：[GC 1.837：[DefNew：1151K-＞64K（1152K），0.0020698 secs]1.839：[Tenured：14616K-＞14680K（14688K），0.0708748 secs]15035K-＞14680K（15840K），0.0730947<br />
secs]<br />
2.144：[GC 2.144：[DefNew：1856K-＞191K（1856K），0.0026810 secs]2.147：[Tenured：25092K-＞24656K（25108K），0.1112429 secs]26172K-＞<br />
24656K（26964K），0.1141099 secs]<br />
2.337：[GC 2.337：[DefNew：1914K-＞0K（3136K），0.0009697 secs]2.338：[Tenured：41779K-＞27347K（42056K），0.0954341 secs]42733K-＞27347K（45192K），0.0965513<br />
secs]<br />
2.465：[GC 2.465：[DefNew：2490K-＞0K（3456K），0.0011044 secs]2.466：[Tenured：46379K-＞27635K（46828K），0.0956937 secs]47621K-＞27635K（50284K），0.0969918<br />
secs]<br />
括号中加粗的数字代表老年代的容量，这组GC日志显示了10次Full GC发生的原因全部<br />
都是老年代空间耗尽，每发生一次Full GC都伴随着一次老年代空间扩容：1536KB-＞<br />
1664KB-＞2684KB&hellip;&hellip;42056KB-＞46828KB，10次GC以后老年代容量从起始的1536KB扩大<br />
到46828KB，当15秒后Eclipse启动完成时，老年代容量扩大到了103428KB，代码编译开始<br />
后，老年代容量到达顶峰473MB，整个Java堆到达最大容量512MB。<br />
日志还显示有些时候内存回收状况很不理想，空间扩容成为获取可用内存的最主要手<br />
段，譬如语句&ldquo;Tenured：25092K-＞24656K（25108K），0.1112429 secs&rdquo;，代表老年代当前<br />
容量为25108KB，内存使用到25092KB的时候发生Full GC，花费0.11秒把内存使用降低到<br />
24656KB，只回收了不到500KB的内存，这次GC基本没有什么回收效果，仅仅做了扩容，扩<br />
容过程相比起回收过程可以看做是基本不需要花费时间的，所以说这0.11秒几乎是白白浪费<br />
了。<br />
由上述分析可以得出结论：Eclipse启动时，Full GC大多数是由于老年代容量扩展而导致<br />
的，由永久代空间扩展而导致的也有一部分。 为了避免这些扩展所带来的性能浪费，我们可<br />
以把-Xms和-XX：PermSize参数值设置为-Xmx和-XX：MaxPermSize参数值一样，这样就强制<br />
虚拟机在启动的时候就把老年代和永久代的容量固定下来，避免运行时自动扩展[3]。<br />
根据分析，优化计划确定为：把新生代容量提升到128MB，避免新生代频繁GC；把Java<br />
堆、 永久代的容量分别固定为512MB和96MB[4]，避免内存扩展。 这几个数值都是根据机器硬<br />
件、 Eclipse插件和工程数量来决定的，读者实践的时候应根据VisualGC中收集到的实际数据<br />
进行设置。 改动后的eclipse.ini配置如代码清单5-10所示。<br />
代码清单5-10 内存调整后的Eclipse配置文件<br />
-vm<br />
D：/_DevSpace/jdk1.6.0_21/bin/javaw.exe<br />
-startup<br />
plugins/org.eclipse.equinox.launcher_1.0.201.R35x_v20090715.jar<br />
--launcher.library<br />
plugins/org.eclipse.equinox.launcher.win32.win32.x86_1.0.200.v20090519<br />
-product<br />
org.eclipse.epp.package.jee.product<br />
-showsplash<br />
org.eclipse.platform<br />
-vmargs<br />
-Dosgi.requiredJavaVersion=1.5<br />
-Xverify：none<br />
-Xmx512m<br />
-Xms512m<br />
-Xmn128m<br />
-XX：PermSize=96m<br />
-XX：MaxPermSize=96m<br />
现在这个配置之下，GC次数已经大幅度降低，图5-9是Eclipse启动后1分钟的监视曲线，<br />
只发生了8次Minor GC和4次Full GC，总耗时为1.928秒。<br />
图 5-9 GC调整后的运行数据<br />
这个结果已经算是基本正常，但是还存在一点瑕疵：从Old Gen的曲线上看，老年代直<br />
接固定在384MB，而内存使用量只有66MB，并且一直很平滑，完全不应该发生Full GC才<br />
对，那4次Full GC是怎么来的？使用jstat-gccause查询一下最近一次GC的原因，见代码清单5-<br />
11。<br />
代码清单5-11 查询GC原因<br />
C：\Users\IcyFenix＞jps<br />
9772 Jps<br />
4068 org.eclipse.equinox.launcher_1.0.201.R35x_v20090715.jar<br />
C：\Users\IcyFenix＞jstat-gccause 4068<br />
S0 S1 E O P YGC YGCT FGC FGCT GCT LGCC GCC<br />
0.00 0.00 1.00 14.81 39.29 6 0.422 20 5.992 6.414<br />
System.gc（）No GC<br />
从LGCC（Last GC Cause）中看到，原来是代码调用System.gc（）显式触发的GC，在内<br />
存设置调整后，这种显式GC已不符合我们的期望，因此在eclipse.ini中加入参数-XX：<br />
+DisableExplicitGC屏蔽掉System.gc（）。 再次测试发现启动期间的Full GC已经完全没有<br />
了，只有6次Minor GC，耗时417毫秒，与调优前4.149秒的测试样本相比，正好是十分之<br />
一。 进行GC调优后Eclipse的启动时间下降非常明显，比整个GC时间降低的绝对值还大，现<br />
在启动只需要7秒多，如图5-10所示。<br />
图 5-10 Eclipse启动时间<br />
[1]严格来说，不包括正在执行native代码的用户线程，因为native代码一般不会改变Java对象<br />
的引用关系，所以没有必要挂起它们来等待垃圾回收。<br />
[2]可以通过以下几个参数要求虚拟机生成GC日志：-XX：+PrintGCTimeStamps（打印GC停<br />
顿时间）、 -XX：+PrintGCDetails（打印GC详细信息）、 -verbose：gc（打印GC信息，输出<br />
内容已被前一个参数包括，可以不写）、 -Xloggc：gc.log。<br />
[3]需要说明一点，虚拟机启动的时候就会把参数中所设定的内存全部划为私有，即使扩容前<br />
有一部分内存不会被用户代码用到，这部分内存也不会交给其他进程使用。 这部分内存在虚<br />
拟机中被标识为&ldquo;Virtual&rdquo;内存。<br />
[4]512MB和96MB两个数值对于笔者的应用情况来说依然偏少，但由于笔者需要同时开启<br />
VMWare工作，所以需要预留较多内存，读者在实际调优时不妨再设置大一些。<br />
5.3.5 选择收集器降低延迟<br />
现在Eclipse启动已经比较迅速了，但我们的调优实战还没有结束，毕竟Eclipse是拿来写<br />
程序的，不是拿来测试启动速度的。 我们不妨再在Eclipse中测试一个非常常用但又比较耗时<br />
的操作：代码编译。 图5-11是当前配置下Eclipse进行代码编译时的运行数据，从图中可以看<br />
出，新生代每次回收耗时约65毫秒，老年代每次回收耗时约725毫秒。 对于用户来说，新生<br />
代GC的耗时还好，65毫秒在使用中无法察觉到，而老年代每次GC停顿接近1秒钟，虽然比较<br />
长时间才会出现一次，但停顿还是显得太长了一些。<br />
图 5-11 编译期间运行数据<br />
再注意看一下编译期间的CPU资源使用状况。 图5-12是Eclipse在编译期间的CPU使用率<br />
曲线图，整个编译过程中平均只使用了不到30%的CPU资源，垃圾收集的CPU使用率曲线更<br />
是几乎与坐标横轴紧贴在一起，这说明CPU资源还有很多可利用的余地。<br />
图 5-12 编译期间CPU曲线<br />
列举GC停顿时间、 CPU资源富余的目的，都是为了接下来替换掉Client模式的虚拟机中<br />
默认的新生代、 老年代串行收集器做铺垫。<br />
Eclipse应当算是与使用者交互非常频繁的应用程序，由于代码太多，笔者习惯在做全量<br />
编译或者清理动作的时候，使用&ldquo;Run in Backgroup&rdquo;功能一边编译一边继续工作。 回顾一下在<br />
第3章提到的几种收集器，很容易想到CMS是最符合这类场景的收集器。 因此尝试在<br />
eclipse.ini中再加入这两个参数-XX：+UseConcMarkSweepGC、 -XX：<br />
+UseParNewGC（ParNew收集器是使用CMS收集器后的默认新生代收集器，写上仅是为了配<br />
置更加清晰），要求虚拟机在新生代和老年代分别使用ParNew和CMS收集器进行垃圾回<br />
收。 指定收集器之后，再次测试的结果如图5-13所示，与原来使用串行收集器对比，新生代<br />
停顿从每次65毫秒下降到了每次53毫秒，而老年代的停顿时间更是从725毫秒大幅下降到了<br />
36毫秒。<br />
图 5-13 指定ParNew和CMS收集器后的GC数据<br />
当然，CMS的停顿阶段只是收集过程中的一小部分，并不是真的把垃圾收集时间从725<br />
毫秒变成36毫秒了。 在GC日志中可以看到CMS与程序并发的时间约为400毫秒，这样收集器<br />
的运作结果就比较令人满意了。<br />
到此，对于虚拟机内存的调优基本就结束了，这次实战可以看做是一次简化的服务端调<br />
优过程，因为服务端调优有可能还会存在于更多方面，如数据库、 资源池、 磁盘I/O等，但<br />
对于虚拟机内存部分的优化，与这次实战中的思路没有什么太大差别。 即使读者实际工作中<br />
接触不到服务器，根据自己工作环境做一些试验，总结几个参数让自己日常工作环境速度有<br />
较大幅度提升也是很划算的。 最终eclipse.ini的配置如代码清单5-12所示。<br />
代码清单5-12 修改收集器配置后的Eclipse配置<br />
-vm<br />
D：/_DevSpace/jdk1.6.0_21/bin/javaw.exe<br />
-startup<br />
plugins/org.eclipse.equinox.launcher_1.0.201.R35x_v20090715.jar<br />
--launcher.library<br />
plugins/org.eclipse.equinox.launcher.win32.win32.x86_1.0.200.v20090519<br />
-product<br />
org.eclipse.epp.package.jee.product<br />
-showsplash<br />
org.eclipse.platform<br />
-vmargs<br />
-Dcom.sun.management.jmxremote<br />
-Dosgi.requiredJavaVersion=1.5<br />
-Xverify：none<br />
-Xmx512m<br />
-Xms512m<br />
-Xmn128m<br />
-XX：PermSize=96m<br />
-XX：MaxPermSize=96m<br />
-XX：+DisableExplicitGC<br />
-Xnoclassgc<br />
-XX：+UseParNewGC<br />
-XX：+UseConcMarkSweepGC<br />
-XX：CMSInitiatingOccupancyFraction=85<br />
5.4 本章小结<br />
Java虚拟机的内存管理与垃圾收集是虚拟机结构体系中最重要的组成部分，对程序的性<br />
能和稳定性有非常大的影响，在本书的第2～5章中，笔者从理论知识、 异常现象、 代码、 工<br />
具、 案例、 实战等几个方面对其进行了讲解，希望读者有所收获。<br />
本书关于虚拟机内存管理部分到此为止就结束了，后面将开始介绍Class文件与虚拟机执<br />
行子系统方面的知识。<br />
&nbsp;</p>
